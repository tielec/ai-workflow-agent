# テストシナリオフェーズ - 実行プロンプト

## タスク概要
要件定義書と設計書から、詳細なテストシナリオを作成してください。**Phase 2で決定されたテスト戦略に基づいて**、適切なテスト種別のシナリオを作成します。

## 入力情報

### Planning Phase成果物
- Planning Document: @.ai-workflow/issue-174/00_planning/output/planning.md

**注意**: Planning Phaseが実行されている場合、開発計画（実装戦略、テスト戦略、リスク、スケジュール）を必ず確認してください。

### 要件定義書
@.ai-workflow/issue-174/01_requirements/output/requirements.md

### 設計書
@.ai-workflow/issue-174/02_design/output/design.md

### テスト戦略（Phase 2で決定）
**UNIT_INTEGRATION**

### GitHub Issue情報（参考）
## Issue概要

- **Issue番号**: #174
- **タイトル**: FOLLOW-UP Issue生成をエージェントベースに拡張する
- **状態**: open
- **URL**: https://github.com/tielec/ai-workflow-agent/issues/174
- **ラベル**: enhancement, ai-workflow-follow-up

### 本文

## 概要

Evaluation Phase (Phase 9) で残タスクがある場合に作成される FOLLOW-UP Issue の本文とタイトルを、エージェント（Codex/Claude Agent）に生成させる機能を追加する。

## 背景

現在の FOLLOW-UP Issue 生成には以下の問題がある：

1. **内容がわかりにくい**: 現在の `IssueAIGenerator` は OpenAI API / Anthropic API をベースにしており、生成されるIssue本文が形式的で、具体的なアクションが不明確
2. **コンテキスト不足**: 残タスクのリストだけでは、なぜそのタスクが必要なのか、どのように実装すべきかの詳細が欠けている
3. **auto-issue機能との一貫性がない**: auto-issue (Issue #121〜#128) ではエージェントベースの生成を採用しており、より詳細で実用的なIssue本文を生成している

## 現状の実装

- `src/core/github/issue-ai-generator.ts`: OpenAI/Claude **API** ベースの生成（テンプレート＋LLM）
- `src/core/github/issue-client.ts`: `createIssueFromEvaluation()` で上記を呼び出し
- `src/phases/evaluation.ts`: 残タスク検出時に FOLLOW-UP Issue 作成

## 提案する改善

### 1. エージェントベースの FOLLOW-UP Issue 生成

auto-issue 機能と同様に、Codex/Claude Agent を使用して Issue 本文を生成する：

- 新規プロンプト: `src/prompts/followup/generate-followup-issue.txt`
- ファイルベース出力方式（`{output_file_path}` プレースホルダー）
- 残タスク情報、元Issue情報、Evaluation Report を入力として提供

### 2. 生成内容の改善

生成するIssue本文に以下を含める：

- **背景**: 元Issueの概要と、なぜ残タスクが発生したか
- **目的**: 各残タスクの目的と期待される成果
- **実行内容**: 具体的な実装手順、対象ファイル、テスト方法
- **受け入れ基準**: タスク完了の判断基準
- **参考情報**: 元Issue、Evaluation Report、関連ドキュメントへのリンク

### 3. CLI オプション拡張

既存の `--followup-llm-mode` オプションに `agent` モードを追加：

```bash
# エージェントベースで生成（推奨）
node dist/index.js execute --issue 123 --phase evaluation --followup-llm-mode agent

# 既存のAPIベース（互換性維持）
node dist/index.js execute --issue 123 --phase evaluation --followup-llm-mode openai
```

## 実装タスク

- [ ] `src/prompts/followup/generate-followup-issue.txt` プロンプト作成
- [ ] `src/core/github/issue-agent-generator.ts` 新規作成（エージェントベース生成）
- [ ] `src/core/github/issue-client.ts` に `generateFollowUpWithAgent()` メソッド追加
- [ ] CLI オプション `--followup-llm-mode agent` 対応
- [ ] `src/phases/evaluation.ts` からエージェント生成を呼び出し
- [ ] フォールバック機構（エージェント失敗時は既存テンプレートを使用）
- [ ] ユニットテスト追加

## 関連ファイル

- `src/core/github/issue-client.ts`
- `src/core/github/issue-ai-generator.ts`
- `src/phases/evaluation.ts`
- `src/core/issue-generator.ts`（auto-issue 参考実装）
- `src/core/repository-analyzer.ts`（auto-issue 参考実装）

## 関連Issue

- Issue #119: フォローアップIssue生成オプション（LLMモード追加）
- Issue #121: 自動Issue作成コマンド基盤

## テスト戦略別の対応

Phase 2で決定されたテスト戦略に応じて、以下のテストシナリオを作成してください：

### UNIT_ONLY: Unitテストのみ
- 各関数・メソッド単位のテストケース
- 正常系・異常系・境界値テスト
- モック/スタブを使用した単体テスト

### INTEGRATION_ONLY: Integrationテストのみ
- コンポーネント間の連携テスト
- 外部システムとの統合テスト
- データフローの検証

### BDD_ONLY: BDDテストのみ
- ユーザーストーリーベースのシナリオ
- Given-When-Then形式
- ビジネス要件との対応

### UNIT_INTEGRATION: Unit + Integration
- Unitテストシナリオ（上記）
- Integrationテストシナリオ（上記）

### UNIT_BDD: Unit + BDD
- Unitテストシナリオ（上記）
- BDDシナリオ（上記）

### INTEGRATION_BDD: Integration + BDD
- Integrationテストシナリオ（上記）
- BDDシナリオ（上記）

### ALL: すべて
- Unitテストシナリオ（上記）
- Integrationテストシナリオ（上記）
- BDDシナリオ（上記）

## テストシナリオの構成

### 1. テスト戦略サマリー
- 選択されたテスト戦略（Phase 2から引用）
- テスト対象の範囲
- テストの目的

### 2. Unitテストシナリオ（該当する場合）

各関数・メソッドについて：

**テストケース名**: （関数名_正常系/異常系/境界値）

- **目的**: このテストで検証すること
- **前提条件**: テスト実行前の状態
- **入力**: 関数への入力パラメータ
- **期待結果**: 期待される出力・状態変化
- **テストデータ**: 使用するテストデータ

**例**:
```
テストケース名: calculate_total_正常系
目的: 合計金額が正しく計算されることを検証
前提条件: 商品リストが存在する
入力: items = [{price: 100, quantity: 2}, {price: 200, quantity: 1}]
期待結果: 400が返される
テストデータ: 上記items
```

### 3. Integrationテストシナリオ（該当する場合）

各統合ポイントについて：

**シナリオ名**: （統合する2つのコンポーネント名）

- **目的**: この統合で検証すること
- **前提条件**: 統合テスト実行前の状態
- **テスト手順**: ステップバイステップの手順
- **期待結果**: 統合後の期待される動作
- **確認項目**: 確認すべきポイントのチェックリスト

### 4. BDDシナリオ（該当する場合）

ユーザーストーリーごとに：

**Feature**: （機能名）

**Scenario**: （シナリオ名）

- **Given** (前提条件): システムの初期状態
- **When** (操作): ユーザーが実行するアクション
- **Then** (結果): 期待される結果

**例**:
```gherkin
Feature: ユーザー登録機能

Scenario: 新規ユーザーが正常に登録できる
  Given ユーザーがログインしていない
  When ユーザーが有効なメールアドレスとパスワードで登録フォームを送信する
  Then ユーザーアカウントが作成される
  And 確認メールが送信される
  And ユーザーがログイン画面にリダイレクトされる
```

### 5. テストデータ
- 各テストシナリオで使用するテストデータ
- 正常データ、異常データ、境界値データ

### 6. テスト環境要件
- 必要なテスト環境（ローカル、CI/CD等）
- 必要な外部サービス・データベース
- モック/スタブの必要性

## 品質ゲート（Phase 3）

テストシナリオは以下の品質ゲートを満たす必要があります：

- [ ] **Phase 2の戦略に沿ったテストシナリオである**
- [ ] **主要な正常系がカバーされている**
- [ ] **主要な異常系がカバーされている**
- [ ] **期待結果が明確である**

これらの品質ゲートは**必須要件**です。作成後、クリティカルシンキングレビューが実施され、品質ゲートを満たさない場合は修正が必要になります。

## 注意事項

1. **戦略準拠**: Phase 2のテスト戦略を厳守してください
   - 戦略に含まれないテスト種別は作成不要
   - 例: UNIT_ONLYの場合、Integration/BDDシナリオは不要

2. **要件との対応**: 要件定義書の各要件がテストでカバーされていることを確認
   - 受け入れ基準がテストシナリオに反映されているか
   - 機能要件がすべてテスト対象に含まれているか

3. **実行可能性**: 実際に実行可能なテストシナリオを記述
   - 曖昧な表現を避ける
   - 具体的な入力・出力を記載
   - 検証可能な期待結果

4. **優先度**: すべてのエッジケースではなく、主要なケースに注目
   - 80点で十分（完璧を目指さない）
   - クリティカルパス優先
   - 高リスク領域を優先的にカバー

5. **レビューされることを意識**: テストシナリオはクリティカルシンキングレビューが実施されます
   - 品質ゲート（4つの必須要件）を最優先で満たすこと
   - ブロッカー（次フェーズに進めない問題）がないように注意

## 出力形式

テストシナリオを `.ai-workflow/issue-174/03_test_scenario/output/test-scenario.md` として保存してください。

Markdown形式で、見出しを適切に使用し、可読性の高いドキュメントを作成してください。

## 実装開始

上記を踏まえ、テストシナリオを作成してください。
