# 詳細設計フェーズ - レビュープロンプト

## レビュー対象
設計書をクリティカルシンキングの観点からレビューしてください。

### 設計書
@.ai-workflow/issue-174/02_design/output/design.md

### 要件定義書（参考）
@.ai-workflow/issue-174/01_requirements/output/requirements.md

### GitHub Issue情報（参考）
## Issue概要

- **Issue番号**: #174
- **タイトル**: FOLLOW-UP Issue生成をエージェントベースに拡張する
- **状態**: open
- **URL**: https://github.com/tielec/ai-workflow-agent/issues/174
- **ラベル**: enhancement, ai-workflow-follow-up

### 本文

## 概要

Evaluation Phase (Phase 9) で残タスクがある場合に作成される FOLLOW-UP Issue の本文とタイトルを、エージェント（Codex/Claude Agent）に生成させる機能を追加する。

## 背景

現在の FOLLOW-UP Issue 生成には以下の問題がある：

1. **内容がわかりにくい**: 現在の `IssueAIGenerator` は OpenAI API / Anthropic API をベースにしており、生成されるIssue本文が形式的で、具体的なアクションが不明確
2. **コンテキスト不足**: 残タスクのリストだけでは、なぜそのタスクが必要なのか、どのように実装すべきかの詳細が欠けている
3. **auto-issue機能との一貫性がない**: auto-issue (Issue #121〜#128) ではエージェントベースの生成を採用しており、より詳細で実用的なIssue本文を生成している

## 現状の実装

- `src/core/github/issue-ai-generator.ts`: OpenAI/Claude **API** ベースの生成（テンプレート＋LLM）
- `src/core/github/issue-client.ts`: `createIssueFromEvaluation()` で上記を呼び出し
- `src/phases/evaluation.ts`: 残タスク検出時に FOLLOW-UP Issue 作成

## 提案する改善

### 1. エージェントベースの FOLLOW-UP Issue 生成

auto-issue 機能と同様に、Codex/Claude Agent を使用して Issue 本文を生成する：

- 新規プロンプト: `src/prompts/followup/generate-followup-issue.txt`
- ファイルベース出力方式（`{output_file_path}` プレースホルダー）
- 残タスク情報、元Issue情報、Evaluation Report を入力として提供

### 2. 生成内容の改善

生成するIssue本文に以下を含める：

- **背景**: 元Issueの概要と、なぜ残タスクが発生したか
- **目的**: 各残タスクの目的と期待される成果
- **実行内容**: 具体的な実装手順、対象ファイル、テスト方法
- **受け入れ基準**: タスク完了の判断基準
- **参考情報**: 元Issue、Evaluation Report、関連ドキュメントへのリンク

### 3. CLI オプション拡張

既存の `--followup-llm-mode` オプションに `agent` モードを追加：

```bash
# エージェントベースで生成（推奨）
node dist/index.js execute --issue 123 --phase evaluation --followup-llm-mode agent

# 既存のAPIベース（互換性維持）
node dist/index.js execute --issue 123 --phase evaluation --followup-llm-mode openai
```

## 実装タスク

- [ ] `src/prompts/followup/generate-followup-issue.txt` プロンプト作成
- [ ] `src/core/github/issue-agent-generator.ts` 新規作成（エージェントベース生成）
- [ ] `src/core/github/issue-client.ts` に `generateFollowUpWithAgent()` メソッド追加
- [ ] CLI オプション `--followup-llm-mode agent` 対応
- [ ] `src/phases/evaluation.ts` からエージェント生成を呼び出し
- [ ] フォールバック機構（エージェント失敗時は既存テンプレートを使用）
- [ ] ユニットテスト追加

## 関連ファイル

- `src/core/github/issue-client.ts`
- `src/core/github/issue-ai-generator.ts`
- `src/phases/evaluation.ts`
- `src/core/issue-generator.ts`（auto-issue 参考実装）
- `src/core/repository-analyzer.ts`（auto-issue 参考実装）

## 関連Issue

- Issue #119: フォローアップIssue生成オプション（LLMモード追加）
- Issue #121: 自動Issue作成コマンド基盤

## 品質ゲート（Phase 2）

設計書は以下の品質ゲートをクリアする必要があります：

- [ ] **実装戦略の判断根拠が明記されている**
- [ ] **テスト戦略の判断根拠が明記されている**
- [ ] **既存コードへの影響範囲が分析されている**
- [ ] **変更が必要なファイルがリストアップされている**
- [ ] **設計が実装可能である**

## ⚠️ 重要: Planning Phaseチェックリストとの照合（必須）

### 1. Planning.mdの読み込み

以下のファイルを読み込んでください：
- @.ai-workflow/issue-174/00_planning/output/planning.md

### 2. 該当フェーズのチェックリストを抽出

Planning.mdから、現在のフェーズ（"### Phase 2:" または "## Phase 2:"）のセクションを見つけ、タスクチェックリストを抽出してください。

**注意**: チェックリストが見つからない場合は、このチェックをスキップしてください。

### 3. 設計内容との照合

設計書（design.md）と照合し、各タスクが完了しているかチェックしてください。

**完了の判定基準**:
- Task記載の設計項目が記述されているか
- Task記載の戦略判断が明記されているか
- サブタスクがすべて完了しているか

### 4. Planning.mdの更新

照合結果に基づき、planning.mdのチェックボックスを更新してください：

- 完了したタスク: `- [ ]` → `- [x]`
- 未完了のタスク: `- [ ]` のまま

**Editツールを使用**して、該当フェーズのセクションを更新してください。

### 5. レビュー判定への反映

- **すべてのタスクが完了**（全て `[x]`）: PASS または PASS_WITH_SUGGESTIONS
- **未完了タスクがある**（`[ ]` が残っている）: FAIL
  - レビューフィードバックに未完了タスクをリストアップ
  - 具体的に何が不足しているか説明

**例（FAIL時のフィードバック）**:
```
## Planning Phaseチェックリスト照合結果: FAIL

以下のタスクが未完了です：

- [ ] Task 2-2: テスト戦略の決定
  - 不足: テスト戦略の判断根拠が記載されていません
- [ ] Task 2-3: 影響範囲分析
  - 不足: 既存コードへの影響範囲が分析されていません

これらのタスクを完了してから再提出してください。
```

### ⚠️ 重要: Planning.mdの内容はレビュー結果に含めない

Planning.mdの読み込みと照合作業は必要ですが、**planning.mdの全文やPlanning Phaseのレビュー内容をレビュー結果に含めないでください**。

レビュー結果には以下のみを含めること:
- 設計書（design.md）に対する評価
- Planning.mdとの照合で発見した未完了タスク（FAIL時のみ）
- 設計書固有の改善提案

Planning Phaseのレビュー詳細やplanning.mdの内容全体は出力しないこと。

## レビュー姿勢

このレビューは「**80点で十分**」の原則に基づいて実施してください：

1. **完璧ではなく、十分を目指す**
   - 設計書が次フェーズ（テストシナリオ作成）に進める状態であれば合格
   - 細かい表現の改善は改善提案として記載（ブロッカーにしない）

2. **ブロッカーと改善提案を明確に区別**
   - ブロッカー: 次フェーズ（テストシナリオ）に進めない重大な問題
   - 改善提案: 次フェーズに進めるが、改善が望ましい事項

3. **実用的でバランスの取れた判断**
   - プロジェクトを前に進めることを最優先
   - 実装フェーズで対応可能な問題はブロッカーにしない

4. **建設的なフィードバック**
   - 「ダメ」ではなく「こうすればより良い」という表現
   - 具体的な改善案を提示

## レビュー観点

### 1. 戦略判断の妥当性（最重要）

**実装戦略（CREATE/EXTEND/REFACTOR）**:
- 判断根拠が具体的かつ論理的に記載されているか
- 要件定義書の内容と整合しているか
- 既存コードへの影響が適切に評価されているか

**テスト戦略（UNIT_ONLY/INTEGRATION_ONLY/BDD_ONLY/UNIT_INTEGRATION/UNIT_BDD/INTEGRATION_BDD/ALL）**:
- 判断根拠が具体的かつ論理的に記載されているか
- 機能の複雑度に見合ったテスト戦略か
- 要件定義の受け入れ基準と整合しているか

**テストコード戦略（EXTEND_TEST/CREATE_TEST/BOTH_TEST）**:
- 判断根拠が具体的かつ論理的に記載されているか
- 既存テストとの関係が明確か

### 2. 影響範囲分析の適切性

- 既存コードへの影響が網羅的に分析されているか
- 依存関係が正しく把握されているか
- マイグレーションの必要性が評価されているか

### 3. ファイルリストの完全性

- 新規作成ファイルがリストアップされているか
- 修正が必要な既存ファイルがリストアップされているか
- パスが具体的で実装可能か

### 4. 設計の実装可能性

- 設計が具体的で実装者が迷わないか
- 技術的に実装可能な設計か
- 既存プロジェクトの規約・パターンに準拠しているか

### 5. 要件との対応（トレーサビリティ）

- 要件定義書の各要件に対応する設計があるか
- 要件の漏れがないか

### 6. セキュリティ考慮

- セキュリティリスクが識別されているか
- 対策が具体的か

### 7. 非機能要件への対応

- パフォーマンス考慮があるか
- スケーラビリティ考慮があるか
- 保守性考慮があるか

## ⚠️ 最重要: 品質ゲートは絶対条件

**品質ゲート（5項目）は必須要件です。1つでも満たされていない場合、判定は自動的にFAILになります。**

- 品質ゲートは「最低限クリアすべき基準」であり、交渉の余地はありません
- 「80点で十分」の原則は、品質ゲートを満たした上での改善提案に適用されます
- 品質ゲートを満たさない状態で次フェーズに進むことは許されません

## ブロッカー（BLOCKER）と改善提案（SUGGESTION）の区別

### ブロッカー（BLOCKER）: 次フェーズに進めない重大な問題

**ブロッカーの例**:
- 3つの戦略判断（実装・テスト・テストコード）のいずれかが欠落
- 判断根拠が記載されていない、または論理的に破綻している
- 変更ファイルリストが未記載
- 設計が実装不可能（技術的制約に違反）
- 既存システムを破壊する設計
- 重大なセキュリティリスクが未対策
- 要件との対応が不明確

### 改善提案（SUGGESTION）: 次フェーズに進めるが、改善が望ましい事項

**改善提案の例**:
- より良い設計パターンの提案
- パフォーマンス最適化の余地
- ドキュメントの充実（例: 図表追加）
- エッジケースの追加考慮
- より詳細な影響範囲分析
- セキュリティ対策の強化

### 判定ルール

#### PASS（合格）

以下の**すべて**を満たす場合のみPASS：
- ✅ **5つの品質ゲートすべてが満たされている**（1つでも×があればFAIL）
- ✅ ブロッカーが存在しない
- ✅ 軽微な改善提案のみ（または改善提案なし）

#### PASS_WITH_SUGGESTIONS（条件付き合格）

以下の**すべて**を満たす場合のみPASS_WITH_SUGGESTIONS：
- ✅ **5つの品質ゲートすべてが満たされている**（1つでも×があればFAIL）
- ✅ ブロッカーは存在しない
- ✅ 次フェーズに進めるが、検討すべき改善点がある

#### FAIL（不合格）

以下の**いずれか1つでも**該当すればFAIL：
- ❌ **品質ゲート（5項目）のうち1つでも満たされていない**
- ❌ ブロッカーが1つ以上存在する

**重要: 品質ゲートは絶対条件であり、1つでも満たされていなければ自動的にFAILです。**

## 出力フォーマット

以下の形式で出力してください：

```markdown
## 品質ゲート評価

**⚠️ 重要: 各項目に対して明示的にPASS/FAILを判定してください。1つでもFAILがあれば最終判定は自動的にFAILです。**

- [x/  ] **実装戦略の判断根拠が明記されている**: **PASS / FAIL** - （判定理由）
- [x/  ] **テスト戦略の判断根拠が明記されている**: **PASS / FAIL** - （判定理由）
- [x/  ] **既存コードへの影響範囲が分析されている**: **PASS / FAIL** - （判定理由）
- [x/  ] **変更が必要なファイルがリストアップされている**: **PASS / FAIL** - （判定理由）
- [x/  ] **設計が実装可能である**: **PASS / FAIL** - （判定理由）

**品質ゲート総合判定: PASS / FAIL**
- PASS: 上記5項目すべてがPASS
- FAIL: 上記5項目のうち1つでもFAIL

**品質ゲート判定がFAILの場合、最終判定は自動的にFAILになります。**

## 詳細レビュー

### 1. 戦略判断の妥当性

**良好な点**:
- （具体的な良い点）

**懸念点**:
- （懸念があれば記載）

### 2. 影響範囲分析の適切性

**良好な点**:
- （具体的な良い点）

**懸念点**:
- （懸念があれば記載）

### 3. ファイルリストの完全性

**良好な点**:
- （具体的な良い点）

**懸念点**:
- （懸念があれば記載）

### 4. 設計の実装可能性

**良好な点**:
- （具体的な良い点）

**懸念点**:
- （懸念があれば記載）

### 5. 要件との対応

**良好な点**:
- （具体的な良い点）

**懸念点**:
- （懸念があれば記載）

### 6. セキュリティ考慮

**良好な点**:
- （具体的な良い点）

**改善の余地**:
- （改善提案があれば記載）

### 7. 非機能要件への対応

**良好な点**:
- （具体的な良い点）

**改善の余地**:
- （改善提案があれば記載）

## ブロッカー（BLOCKER）

**次フェーズに進めない重大な問題**

（ブロッカーがある場合のみ記載）
1. **（ブロッカー1のタイトル）**
   - 問題: （具体的な問題）
   - 影響: （次フェーズにどう影響するか）
   - 対策: （どう修正すべきか）

## 改善提案（SUGGESTION）

**次フェーズに進めるが、改善が望ましい事項**

（改善提案がある場合のみ記載）
1. **（提案1のタイトル）**
   - 現状: （現在の状態）
   - 提案: （こうすればより良い）
   - 効果: （改善による効果）

## 総合評価

（設計書全体の総合的な評価）

**主な強み**:
- （良い点をまとめる）

**主な改善提案**:
- （改善提案をまとめる）

（総括コメント）

---
**判定: PASS / PASS_WITH_SUGGESTIONS / FAIL**
```

**重要**: 最終行に必ず上記フォーマットで判定を明記してください。
