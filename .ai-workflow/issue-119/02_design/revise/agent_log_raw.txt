{"type":"thread.started","thread_id":"019a47ab-1625-78a0-bf33-dbcd28d0317e"}
{"type":"turn.started"}
{"type":"item.started","item":{"id":"item_0","type":"command_execution","command":"bash -lc 'cat .ai-workflow/issue-119/02_design/output/design.md'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_0","type":"command_execution","command":"bash -lc 'cat .ai-workflow/issue-119/02_design/output/design.md'","aggregated_output":"cat: .ai-workflow/issue-119/02_design/output/design.md: No such file or directory\n","exit_code":1,"status":"failed"}}
{"type":"item.started","item":{"id":"item_1","type":"command_execution","command":"bash -lc ls","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_1","type":"command_execution","command":"bash -lc ls","aggregated_output":"execute\noutput\nreview\nrevise\n","exit_code":0,"status":"completed"}}
{"type":"item.started","item":{"id":"item_2","type":"command_execution","command":"bash -lc ls","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_2","type":"command_execution","command":"bash -lc ls","aggregated_output":"design.md\n","exit_code":0,"status":"completed"}}
{"type":"item.started","item":{"id":"item_3","type":"command_execution","command":"bash -lc 'cat design.md'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_3","type":"command_execution","command":"bash -lc 'cat design.md'","aggregated_output":"# 詳細設計書 - Issue #119 フォローアップIssue生成品質の改善（LLM活用）\n\n**Issue番号**: #119  \n**タイトル**: フォローアップIssue生成品質の改善（LLM活用）  \n**バージョン**: 1.1 (Design)\n\n---\n\n## 1. アーキテクチャ設計\n\n### 1.1 システム全体フロー\n\n```\nEvaluationPhase (Phase 9)\n    │ RemainingTask[], IssueContext, evaluation report path, generation options\n    ▼\nGitHubClient.createIssueFromEvaluation(...)\n    │ delegates\n    ▼\nIssueClient (LLM-aware)\n    ├─ IssueAIGenerator.generate(...)\n    │     └─ LLM Provider Adapter (OpenAI / Anthropic)\n    └─ Legacy builders (generateFollowUpTitle + buildLegacyBody)\n    ▼\nOctokit.issues.create(...) → GitHub Issue\n```\n\n### 1.2 コンポーネント責務\n\n| コンポーネント | 役割 | 主な入出力 |\n| --- | --- | --- |\n| `EvaluationPhase` | Phase 9 の処理。残タスク検出後に GitHubClient へフォローアップ生成を依頼 | 入力: Evaluation結果 / 出力: IssueGenerationOptions 付き呼び出し |\n| `GitHubClient` | GitHub API ファサード。IssueClient へ委譲し設定を束ねる | 入力: issue番号, tasks, options / 出力: IssueCreationResult |\n| `IssueClient` | フォローアップIssue生成の集約。LLM生成→フォールバック制御→Octokit呼び出し | 入力: tasks, context, options / 出力: タイトル・本文・ログ |\n| `IssueAIGenerator` (新規) | LLMプロンプト生成、API呼び出し、レスポンス検証 | 入力: tasks, context, options / 出力: { title, body, metadata } |\n| `LlmProviderAdapter` (OpenAI / Anthropic) | 各APIのラッパー。タイムアウト・再試行を実装 | 入出力: prompt, call options, completion JSON |\n| `config` / CLI | 環境変数・CLIから LLM 設定を収集し PhaseContextへ渡す | 入出力: Follow-up LLM 設定値 |\n| `SecretMasker` (既存) | 機密情報のマスキング | 入力: プロンプトPayload / 出力: SanitizedPayload |\n\n### 1.3 データフロー\n\n1. ユーザーが `ai-workflow execute ...` を実行し、CLI が Follow-up LLM オプションを解析 (デフォルトは無効)。\n2. `commands/execute` が `PhaseContext.issueGenerationOptions` を組み立て、`PhaseFactory` 経由で `EvaluationPhase` へ受け渡す。\n3. EvaluationPhase で残タスクが存在すると `GitHubClient.createIssueFromEvaluation(issueNumber, tasks, reportPath, context, options)` を呼び出す。\n4. `GitHubClient` は `IssueAIGenerator` をコンストラクタインジェクション済みの `IssueClient` に委譲。\n5. `IssueClient` が `options.enabled` と `IssueAIGenerator.isAvailable()` を確認し、利用可能なら `generate(tasks, context, options)` を試行。\n6. `IssueAIGenerator` は payload をサニタイズ→プロンプト生成→LLM呼び出し→検証し、成功時にタイトル・本文を返却。\n7. LLM 失敗または無効時、`IssueClient` は既存の `generateFollowUpTitle` と新設の `buildLegacyBody` でフォールバック本文を生成。\n8. 生成結果と `## 参考` セクション (＋オプションで LLM metadata) を結合し、Octokit で Issue を作成。ログへ成否とメタ情報を出力。\n\n### 1.4 主なシーケンスと失敗時動作\n\n- LLM 成功: `IssueAIGenerator` → validated result → `IssueClient` が LLM 出力を採用 → `options.appendMetadata` が true の場合にメタデータ節を付加。\n- LLM タイムアウト / レート制限: Providerアダプタが指数バックオフで再試行。全失敗で `IssueAIError` を返し IssueClient が WARN を記録しフォールバック。\n- プロンプト検証失敗: `IssueAIGenerator` が `IssueAIValidationError` を送出し、同様にフォールバック。\n- Octokit 失敗: 既存処理と同様に ERROR ログを出力し `IssueCreationResult` で失敗を返却。\n\n---\n\n## 2. 実装戦略判断: EXTEND\n\n**判断根拠**:\n- 既存 `IssueClient` / `GitHubClient` / CLI フローを維持したまま責務を拡張する必要があるため。\n- フォールバックとして既存テンプレートを保持しつつ LLM 生成を追加する形で後方互換を守る。\n- Planning Document の戦略 (新規モジュール追加 + 既存コード拡張) と整合。\n\n---\n\n## 3. テスト戦略判断: UNIT_INTEGRATION\n\n**判断根拠**:\n- プロンプト生成・レスポンス検証・リトライといったロジックはモック化が容易であり、ユニットテストで網羅できる。\n- GitHub 連携や Phase からのオプション伝搬、フォールバック全体の動作は統合テストで確認する必要がある。\n\n---\n\n## 4. テストコード戦略判断: BOTH_TEST\n\n**判断根拠**:\n- 既存 `issue-client` テストに LLM 成功/失敗パスを追加する必要がある (既存テストの拡張)。\n- `IssueAIGenerator` 用の専用ユニットテストが新規に必要となる (新規テスト作成)。\n\n---\n\n## 5. 影響範囲分析\n\n### 5.1 既存コードへの影響\n- `src/core/github/issue-client.ts`: 依存注入、LLM 分岐、本文生成をメソッド化、WARN/DEBUG ログ拡張。\n- `src/core/github-client.ts`: `IssueAIGenerator` の初期化と委譲。`createIssueFromEvaluation` にオプションパラメータ追加。\n- `src/phases/evaluation.ts`: `GitHubClient.createIssueFromEvaluation` 呼び出しに LLM オプションを渡す。\n- `src/commands/execute.ts` / `src/commands/execute/options-parser.ts`: CLI オプション解析に Follow-up LLM 設定を追加し `PhaseContext` へ渡す。\n- `src/types.ts`: `IssueGenerationOptions` や LLM 結果の型を追加。\n- `src/types/commands.ts`: `PhaseContext` に `issueGenerationOptions` プロパティを追加。\n- `src/core/config.ts`: LLM 設定用ゲッターを実装。\n- 既存テスト (`tests/unit/github/issue-client*.ts`, `tests/integration/github-client-facade.test.ts`) を LLM 統合ケースで更新。\n\n### 5.2 依存関係の変更\n- 追加パッケージは想定なし。既存 `openai`, `@anthropic-ai/claude-agent-sdk` を再利用。\n- Jest モックは既存 `jest-mock-extended` や手動モックを活用。\n\n### 5.3 マイグレーション要否\n- データマイグレーションは不要。\n- `.env.example` が存在する場合は Follow-up LLM 用環境変数を追加。\n- `ARCHITECTURE.md`, `CLAUDE.md`, `README.md` を更新して設定手順とフォールバック説明を追記。\n\n---\n\n## 6. 変更・追加ファイルリスト\n\n- **新規作成**\n  - `src/core/github/issue-ai-generator.ts`\n  - `tests/unit/github/issue-ai-generator.test.ts`\n  - `tests/integration/followup-issue-llm.test.ts` (Octokit モック中心)\n- **既存修正**\n  - `src/core/github/issue-client.ts`\n  - `src/core/github-client.ts`\n  - `src/phases/evaluation.ts`\n  - `src/commands/execute.ts`\n  - `src/commands/execute/options-parser.ts`\n  - `src/types.ts`\n  - `src/types/commands.ts`\n  - `src/core/config.ts`\n  - `tests/unit/github/issue-client.test.ts`\n  - `tests/unit/github/issue-client-followup.test.ts`\n  - `tests/integration/github-client-facade.test.ts`\n  - ドキュメント (`ARCHITECTURE.md`, `CLAUDE.md`, `README.md`, `.env.example`)\n- **削除予定**: なし\n\n---\n\n## 7. 詳細設計\n\n### 7.1 IssueGenerationOptions / IssueAIGenerationResult\n\n```ts\nexport interface IssueGenerationOptions {\n  enabled: boolean;\n  provider: 'auto' | 'openai' | 'claude';\n  model?: string;\n  temperature?: number;          // default 0.2\n  maxOutputTokens?: number;      // default 1500\n  timeoutMs?: number;            // default 25000\n  maxRetries?: number;           // default 3\n  maxTasks?: number;             // default 5\n  appendMetadata?: boolean;      // default false\n}\n\nexport interface IssueAIGenerationResult {\n  title: string;\n  body: string;\n  metadata: {\n    provider: 'openai' | 'claude';\n    model: string;\n    durationMs: number;\n    retryCount: number;\n    inputTokens?: number;\n    outputTokens?: number;\n    omittedTasks?: number;\n  };\n}\n```\n\n- `config` でデフォルトを構築し、CLI/環境変数で上書き可能にする。\n- `PhaseContext` に `issueGenerationOptions` を追加し、省略時は `{ enabled: false, provider: 'auto' }` を適用。\n\n### 7.2 IssueAIGenerator クラス (新規)\n\n- コンストラクタ: `(providers: Record<'openai' | 'claude', LlmProviderAdapter>, secretMasker = new SecretMasker())`。\n- 補助的なエラー型:\n  - `IssueAIUnavailableError` (credentials 不足など)\n  - `IssueAIValidationError` (出力検証失敗)\n- 公開メソッド:\n  - `isAvailable(options: IssueGenerationOptions): boolean`  \n    - `options.enabled` が true かつ選択された provider（`auto` の場合は利用可能なもの）が `hasCredentials()` を満たす。\n  - `generate(tasks, context, issueNumber, options): Promise<IssueAIGenerationResult>`  \n    1. `sanitizePayload(tasks, context, options.maxTasks ?? 5)`  \n       - `RemainingTask` を優先度順 (High→Medium→Low) に並べ、上位 `maxTasks` を採用。超過分は `omittedTasks` としてメタに記録。  \n       - 各文字列フィールドは 512 文字にトリム。`targetFiles` は 10 件、`steps` / `acceptanceCriteria` は各 8 件まで。  \n       - `SecretMasker.maskObject` で既知のシークレット値・トークン・メールアドレスを `[REDACTED_x]` に置換。\n    2. `buildPrompt(issueNumber, sanitizedPayload, context, options)`  \n       - JSON 文字列化し、テンプレートへ埋め込む。\n    3. `invokeProvider(prompt, options)`  \n       - 選択された provider の `complete()` を呼び出す。  \n       - レート制限時は指数バックオフ (2000ms, 4000ms, 8000ms) とし、回数は `options.maxRetries`。\n    4. `parseAndValidate(responseText)`  \n       - JSON パース → タイトル長 50〜80 文字 → 必須セクションを順番に確認 → `実行内容` セクションが番号付きリスト (`1.` 形式) とテスト手順 (`テスト` or `検証`) を含むか検証 → HTML タグを禁止。  \n       - 失敗時は `IssueAIValidationError`。\n    5. 成功時に metadata (provider, model, duration, retryCount, input/output tokens, omittedTasks) 付きで返却。\n\n### 7.3 LlmProviderAdapter\n\n```ts\ninterface LlmProviderAdapter {\n  name: 'openai' | 'claude';\n  hasCredentials(): boolean;\n  complete(prompt: string, options: IssueGenerationOptions): Promise<LlmProviderResponse>;\n}\n\ninterface LlmProviderResponse {\n  text: string;\n  inputTokens?: number;\n  outputTokens?: number;\n  retryCount: number;\n  durationMs: number;\n}\n```\n\n- **OpenAIAdapter**\n  - `openai.chat.completions.create()` を呼び出し、`response_format: { type: 'json_object' }` を指定。\n  - `AbortController` で `timeoutMs` を強制。\n  - HTTP 429/5xx 時は指数バックオフで再試行。最終的に失敗ならエラーをスロー。\n- **AnthropicAdapter**\n  - `@anthropic-ai/claude-agent-sdk` の `messages.create()` を利用。\n  - `options.model` が無ければ `claude-3-sonnet-20240229` を使用。\n  - 応答の `content` を結合し JSON テキストを取得。\n- `provider: 'auto'` の場合は OpenAI キーが存在すれば OpenAIAdapter、それ以外は ClaudeAdapter を選択。\n\n### 7.4 プロンプト生成とバリデーション\n\nテンプレート例 (コード内定数として保持):\n\n````markdown\nあなたはソフトウェア開発プロジェクトのIssue作成アシスタントです。\n以下のJSONを読み取り、フォローアップIssueを構築してください。\n\n入力:\n{{payload}}\n\n要件:\n1. タイトルは50〜80文字。対象コンポーネントや目的のキーワードを含めること。\n2. 本文は以下の見出し順序とします。\n   ## 背景\n   ## 目的\n   ## 実行内容\n   ## 受け入れ基準\n   ## 関連リソース\n3. 実行内容には対象ファイル・手順・テスト方法を含めること。\n4. JSON 形式で回答してください。\n\n出力形式:\n{\n  \"title\": \"...\",\n  \"body\": \"...\"\n}\n````\n\n- `parseAndValidate` 検証ルール:\n  - JSON パース失敗 → `IssueAIValidationError`。\n  - タイトル文字数 (全角半角問わず) が 50 未満または 80 超過で失敗。\n  - 本文に必須5セクションが順番に存在するか正規表現で確認。\n  - `## 実行内容` 内に番号付きリスト (`^\\d+\\. `) があり、いずれかの行に `テスト`/`検証` を含むことを確認。\n  - HTML/スクリプトタグを検出したら失敗。\n  - 余分な末尾空行は `trimEnd()` で整理。\n\n### 7.5 IssueClient 拡張\n\n- コンストラクタに `IssueAIGenerator | null` を追加 (`new IssueClient(octokit, owner, repo, issueAIGenerator)`).\n- 新規ヘルパー:\n  - `private buildLegacyBody(...)`: 現行ロジックを抽出し、フォールバック時に再利用。\n  - `private appendMetadata(body, metadata, options)`: `options.appendMetadata` が true の場合に以下を追加。\n    ```\n    ## 生成メタデータ\n    - モデル: ${metadata.model} (${metadata.provider})\n    - 所要時間: ${metadata.durationMs}ms / 再試行: ${metadata.retryCount}\n    - トークン: in ${metadata.inputTokens ?? '-'} / out ${metadata.outputTokens ?? '-'}\n    - 省略したタスク数: ${metadata.omittedTasks ?? 0}\n    ```\n  - `private async tryGenerateWithLLM(...)`: LLM が利用可能か判定し、失敗時は WARN ログで理由を記録して `null` を返す。\n- `createIssueFromEvaluation` の流れ:\n  1. `const aiResult = await this.tryGenerateWithLLM(...);`\n  2. `const title = aiResult?.title ?? this.generateFollowUpTitle(...);`\n  3. `const baseBody = aiResult?.body ?? this.buildLegacyBody(...);`\n  4. `const body = aiResult ? this.appendMetadata(baseBody, aiResult.metadata, options) : baseBody;`\n  5. 既存どおり Octokit で Issue を作成。\n- ログ出力:\n  - 成功 (`logger.debug`): `FOLLOWUP_LLM_SUCCESS { provider, model, durationMs, retryCount }`\n  - フォールバック (`logger.warn`): `FOLLOWUP_LLM_FALLBACK { reason, fallback: 'legacy_template' }`\n  - ログにはプロンプト本文を含めない。\n\n### 7.6 GitHubClient / Phase 連携\n\n- `GitHubClient` コンストラクタで `IssueAIGenerator` を生成し `IssueClient` に渡す。\n- `createIssueFromEvaluation` の署名を `(..., issueContext?: IssueContext, options?: IssueGenerationOptions)` に拡張。`options` が無い場合は `config` から取得する。\n- `EvaluationPhase`:\n  ```ts\n  const options = this.context.issueGenerationOptions ?? { enabled: false, provider: 'auto' };\n  const result = await this.github.createIssueFromEvaluation(\n    issueNumber,\n    remainingTasks,\n    relativeReportPath,\n    issueContext,\n    options,\n  );\n  ```\n- `PhaseFactory` / `BasePhase` で `PhaseContext.issueGenerationOptions` を新たに受け渡す。\n\n### 7.7 CLI / Config 拡張\n\n- `ExecuteCommandOptions` に以下フィールドを追加:\n  - `followupLlmMode?: 'auto' | 'openai' | 'claude' | 'off'`\n  - `followupLlmModel?: string`\n  - `followupLlmTimeout?: number`\n  - `followupLlmMaxRetries?: number`\n  - `followupLlmAppendMetadata?: boolean`\n- `options-parser.ts` でバリデーション:\n  - `off` → `enabled` false。\n  - timeout/retries は正の整数 (0 許容)。\n  - provider 指定が `openai` なのに OpenAI APIキー不在の場合は警告ログを出して `enabled=false`。\n- `config.ts` で環境変数ゲッターを追加 (`FOLLOWUP_LLM_MODE`, `FOLLOWUP_LLM_MODEL`, `FOLLOWUP_LLM_TIMEOUT_MS`, `FOLLOWUP_LLM_MAX_RETRIES`, `FOLLOWUP_LLM_APPEND_METADATA`)。\n- CLI 例:  \n  `ai-workflow execute --issue 119 --phase evaluation --followup-llm-mode auto --followup-llm-model claude-3-sonnet-20240229`.\n\n### 7.8 ロギング・モニタリング\n\n- LLM 成功時は DEBUG ログ、再試行数 > 0 の場合は WARN と INFO の両方に出力して追跡可能にする。\n- フォールバック発生時は WARN ログを構造化文字列 (JSON 互換) で出力。`event=FOLLOWUP_LLM_FALLBACK`, `fallback_mode=legacy_template`, `reason=...`。\n- `IssueAIGenerator.generate` 内で `performance.now()` を使い処理時間を計測。\n- ログには機密情報やプロンプト全文を含めない。\n\n### 7.9 テスト設計詳細\n\n| レイヤ | テストケース | 目的 |\n| --- | --- | --- |\n| Unit (`issue-ai-generator.test.ts`) | タスク数制限・文字列トリム・ターゲットファイル上限を検証 | サニタイズ仕様の担保 |\n|  | JSON 以外の応答で `IssueAIValidationError` を投げる | バリデーション |\n|  | 必須セクション欠落、タイトル長不正、HTMLタグ混入で失敗する | FR-1/FR-2 |\n|  | 1回目失敗→2回目成功のリトライ時に最終成功 | リトライ制御 |\n|  | `SecretMasker` により API キーがプロンプトに残らない | セキュリティ |\n| Unit (`issue-client.test.ts`) | LLM 成功時に Octokit へ LLM 出力が渡る | フロー検証 |\n|  | 例外発生時に WARN ログとフォールバックタイトル/本文が使用される | FR-3 |\n| Integration (`followup-issue-llm.test.ts`) | CLI -> PhaseContext -> GitHubClient -> IssueClient のオプション伝搬 | 設定連携 |\n|  | LLM が無効化されている場合に既存挙動が維持される | 後方互換 |\n|  | `FOLLOWUP_LLM_E2E=1` 時のみ実APIを使い、成功時タイトル/本文が要件を満たすか検証 (失敗時はテストをスキップ) | 実API検証 |\n\n### 7.10 要件トレーサビリティ\n\n| 要件ID | 対応箇所 |\n| --- | --- |\n| FR-1 | 7.4 プロンプト設計・タイトル検証、7.5 タイトル採用ロジック |\n| FR-2 | 7.4 セクション検証、7.5 `buildLegacyBody` との比較で差異を吸収 |\n| FR-3 | 7.5 `tryGenerateWithLLM` フォールバック制御 |\n| FR-4 | 7.6 Phase 連携、7.7 CLI/Config 拡張 |\n| FR-5 | 7.5 ログ出力設計、7.8 モニタリング |\n\n### 7.11 ドキュメント更新\n\n- `ARCHITECTURE.md`: Evaluation → GitHubClient → IssueAIGenerator → IssueClient のフロー図と説明を追加。\n- `CLAUDE.md`: Follow-up LLM 設定方法、環境変数、フォールバック観察ポイントを追記。\n- `README.md`: CLI オプションと `.env` 設定例、フォールバック時のトラブルシューティングを追加。\n\n---\n\n## 8. セキュリティ考慮事項\n\n- `SecretMasker` と追加の簡易正規表現 (API キーフォーマット、メールアドレス) を `sanitizePayload` に適用し、機密情報送信を防止。\n- LLM 応答に HTML/スクリプトタグが含まれる場合はバリデーションエラーとし、フォールバックへ切り替える。\n- API キーは `config` ゲッター経由でのみ参照し、ログへ出力しない。\n- プロンプト・レスポンスをファイルへ書き出さない。ログにはメタデータのみを残す。\n- 再試行回数を `maxRetries` で制限し、無限ループやコスト過多を防止。\n\n---\n\n## 9. 非機能要件への対応\n\n- **パフォーマンス**: `timeoutMs` と `maxRetries` で最悪ケースでも 25s × 3 = 75s 以内にフォールバック。タスク数・文字数の制限で入力サイズを抑制し、LLM 呼び出し平均 15s 以内を目指す。\n- **スケーラビリティ**: Provider 抽象化でモデル追加が容易。`maxTasks` で大規模残タスクでも安定して処理。\n- **保守性**: LLM ロジックを `IssueAIGenerator` に集約し、IssueClient と疎結合化。テストで回帰を検知しやすくする。\n- **可用性**: LLM 失敗時でも既存テンプレートで確実に Issue を生成 (FR-3)。WARN ログで運用監視が容易。\n- **コスト管理**: デフォルト無効 (`enabled=false`) で不要な API 呼び出しを防止。`appendMetadata` で生成コストを Issue 上に可視化可能。\n\n---\n\n## 10. 実装の順序\n\n1. **型と設定の整備**: `IssueGenerationOptions`、`PhaseContext`、CLI/Config 拡張。既存コードをコンパイル可能に更新。\n2. **IssueAIGenerator 実装**: プロンプトテンプレート、サニタイズ、Provider アダプタ、検証、専用エラーを実装。\n3. **IssueClient / GitHubClient 更新**: 依存注入、LLM 分岐、フォールバックとログ処理を追加。\n4. **Phase / CLI 連携**: EvaluationPhase がオプションを渡すよう調整し、実行時の設定反映を確認。\n5. **テスト追加・更新**: 新規ユニットテスト、既存テスト更新、統合テストでオプション伝搬とフォールバックを検証。\n6. **ドキュメント更新**: ARCHITECTURE / CLAUDE / README / `.env.example` を更新。\n7. **検証**: `npm run test:unit`, `npm run test:integration` 実行。必要に応じ `FOLLOWUP_LLM_E2E=1` で手動統合テストを確認。\n\n---\n\n## 11. 品質ゲート確認\n\n- 実装戦略 (EXTEND) の判断根拠を明記。\n- テスト戦略 (UNIT_INTEGRATION) の判断根拠を明記。\n- 既存コードへの影響と依存関係を分析。\n- 変更・追加ファイルを列挙。\n- 詳細設計と要件トレーサビリティを提示し実装可能性を保証。\n\n","exit_code":0,"status":"completed"}}
{"type":"item.started","item":{"id":"item_4","type":"command_execution","command":"bash -lc \"sed -n '1,200p' design.md\"","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_4","type":"command_execution","command":"bash -lc \"sed -n '1,200p' design.md\"","aggregated_output":"# 詳細設計書 - Issue #119 フォローアップIssue生成品質の改善（LLM活用）\n\n**Issue番号**: #119  \n**タイトル**: フォローアップIssue生成品質の改善（LLM活用）  \n**バージョン**: 1.1 (Design)\n\n---\n\n## 1. アーキテクチャ設計\n\n### 1.1 システム全体フロー\n\n```\nEvaluationPhase (Phase 9)\n    │ RemainingTask[], IssueContext, evaluation report path, generation options\n    ▼\nGitHubClient.createIssueFromEvaluation(...)\n    │ delegates\n    ▼\nIssueClient (LLM-aware)\n    ├─ IssueAIGenerator.generate(...)\n    │     └─ LLM Provider Adapter (OpenAI / Anthropic)\n    └─ Legacy builders (generateFollowUpTitle + buildLegacyBody)\n    ▼\nOctokit.issues.create(...) → GitHub Issue\n```\n\n### 1.2 コンポーネント責務\n\n| コンポーネント | 役割 | 主な入出力 |\n| --- | --- | --- |\n| `EvaluationPhase` | Phase 9 の処理。残タスク検出後に GitHubClient へフォローアップ生成を依頼 | 入力: Evaluation結果 / 出力: IssueGenerationOptions 付き呼び出し |\n| `GitHubClient` | GitHub API ファサード。IssueClient へ委譲し設定を束ねる | 入力: issue番号, tasks, options / 出力: IssueCreationResult |\n| `IssueClient` | フォローアップIssue生成の集約。LLM生成→フォールバック制御→Octokit呼び出し | 入力: tasks, context, options / 出力: タイトル・本文・ログ |\n| `IssueAIGenerator` (新規) | LLMプロンプト生成、API呼び出し、レスポンス検証 | 入力: tasks, context, options / 出力: { title, body, metadata } |\n| `LlmProviderAdapter` (OpenAI / Anthropic) | 各APIのラッパー。タイムアウト・再試行を実装 | 入出力: prompt, call options, completion JSON |\n| `config` / CLI | 環境変数・CLIから LLM 設定を収集し PhaseContextへ渡す | 入出力: Follow-up LLM 設定値 |\n| `SecretMasker` (既存) | 機密情報のマスキング | 入力: プロンプトPayload / 出力: SanitizedPayload |\n\n### 1.3 データフロー\n\n1. ユーザーが `ai-workflow execute ...` を実行し、CLI が Follow-up LLM オプションを解析 (デフォルトは無効)。\n2. `commands/execute` が `PhaseContext.issueGenerationOptions` を組み立て、`PhaseFactory` 経由で `EvaluationPhase` へ受け渡す。\n3. EvaluationPhase で残タスクが存在すると `GitHubClient.createIssueFromEvaluation(issueNumber, tasks, reportPath, context, options)` を呼び出す。\n4. `GitHubClient` は `IssueAIGenerator` をコンストラクタインジェクション済みの `IssueClient` に委譲。\n5. `IssueClient` が `options.enabled` と `IssueAIGenerator.isAvailable()` を確認し、利用可能なら `generate(tasks, context, options)` を試行。\n6. `IssueAIGenerator` は payload をサニタイズ→プロンプト生成→LLM呼び出し→検証し、成功時にタイトル・本文を返却。\n7. LLM 失敗または無効時、`IssueClient` は既存の `generateFollowUpTitle` と新設の `buildLegacyBody` でフォールバック本文を生成。\n8. 生成結果と `## 参考` セクション (＋オプションで LLM metadata) を結合し、Octokit で Issue を作成。ログへ成否とメタ情報を出力。\n\n### 1.4 主なシーケンスと失敗時動作\n\n- LLM 成功: `IssueAIGenerator` → validated result → `IssueClient` が LLM 出力を採用 → `options.appendMetadata` が true の場合にメタデータ節を付加。\n- LLM タイムアウト / レート制限: Providerアダプタが指数バックオフで再試行。全失敗で `IssueAIError` を返し IssueClient が WARN を記録しフォールバック。\n- プロンプト検証失敗: `IssueAIGenerator` が `IssueAIValidationError` を送出し、同様にフォールバック。\n- Octokit 失敗: 既存処理と同様に ERROR ログを出力し `IssueCreationResult` で失敗を返却。\n\n---\n\n## 2. 実装戦略判断: EXTEND\n\n**判断根拠**:\n- 既存 `IssueClient` / `GitHubClient` / CLI フローを維持したまま責務を拡張する必要があるため。\n- フォールバックとして既存テンプレートを保持しつつ LLM 生成を追加する形で後方互換を守る。\n- Planning Document の戦略 (新規モジュール追加 + 既存コード拡張) と整合。\n\n---\n\n## 3. テスト戦略判断: UNIT_INTEGRATION\n\n**判断根拠**:\n- プロンプト生成・レスポンス検証・リトライといったロジックはモック化が容易であり、ユニットテストで網羅できる。\n- GitHub 連携や Phase からのオプション伝搬、フォールバック全体の動作は統合テストで確認する必要がある。\n\n---\n\n## 4. テストコード戦略判断: BOTH_TEST\n\n**判断根拠**:\n- 既存 `issue-client` テストに LLM 成功/失敗パスを追加する必要がある (既存テストの拡張)。\n- `IssueAIGenerator` 用の専用ユニットテストが新規に必要となる (新規テスト作成)。\n\n---\n\n## 5. 影響範囲分析\n\n### 5.1 既存コードへの影響\n- `src/core/github/issue-client.ts`: 依存注入、LLM 分岐、本文生成をメソッド化、WARN/DEBUG ログ拡張。\n- `src/core/github-client.ts`: `IssueAIGenerator` の初期化と委譲。`createIssueFromEvaluation` にオプションパラメータ追加。\n- `src/phases/evaluation.ts`: `GitHubClient.createIssueFromEvaluation` 呼び出しに LLM オプションを渡す。\n- `src/commands/execute.ts` / `src/commands/execute/options-parser.ts`: CLI オプション解析に Follow-up LLM 設定を追加し `PhaseContext` へ渡す。\n- `src/types.ts`: `IssueGenerationOptions` や LLM 結果の型を追加。\n- `src/types/commands.ts`: `PhaseContext` に `issueGenerationOptions` プロパティを追加。\n- `src/core/config.ts`: LLM 設定用ゲッターを実装。\n- 既存テスト (`tests/unit/github/issue-client*.ts`, `tests/integration/github-client-facade.test.ts`) を LLM 統合ケースで更新。\n\n### 5.2 依存関係の変更\n- 追加パッケージは想定なし。既存 `openai`, `@anthropic-ai/claude-agent-sdk` を再利用。\n- Jest モックは既存 `jest-mock-extended` や手動モックを活用。\n\n### 5.3 マイグレーション要否\n- データマイグレーションは不要。\n- `.env.example` が存在する場合は Follow-up LLM 用環境変数を追加。\n- `ARCHITECTURE.md`, `CLAUDE.md`, `README.md` を更新して設定手順とフォールバック説明を追記。\n\n---\n\n## 6. 変更・追加ファイルリスト\n\n- **新規作成**\n  - `src/core/github/issue-ai-generator.ts`\n  - `tests/unit/github/issue-ai-generator.test.ts`\n  - `tests/integration/followup-issue-llm.test.ts` (Octokit モック中心)\n- **既存修正**\n  - `src/core/github/issue-client.ts`\n  - `src/core/github-client.ts`\n  - `src/phases/evaluation.ts`\n  - `src/commands/execute.ts`\n  - `src/commands/execute/options-parser.ts`\n  - `src/types.ts`\n  - `src/types/commands.ts`\n  - `src/core/config.ts`\n  - `tests/unit/github/issue-client.test.ts`\n  - `tests/unit/github/issue-client-followup.test.ts`\n  - `tests/integration/github-client-facade.test.ts`\n  - ドキュメント (`ARCHITECTURE.md`, `CLAUDE.md`, `README.md`, `.env.example`)\n- **削除予定**: なし\n\n---\n\n## 7. 詳細設計\n\n### 7.1 IssueGenerationOptions / IssueAIGenerationResult\n\n```ts\nexport interface IssueGenerationOptions {\n  enabled: boolean;\n  provider: 'auto' | 'openai' | 'claude';\n  model?: string;\n  temperature?: number;          // default 0.2\n  maxOutputTokens?: number;      // default 1500\n  timeoutMs?: number;            // default 25000\n  maxRetries?: number;           // default 3\n  maxTasks?: number;             // default 5\n  appendMetadata?: boolean;      // default false\n}\n\nexport interface IssueAIGenerationResult {\n  title: string;\n  body: string;\n  metadata: {\n    provider: 'openai' | 'claude';\n    model: string;\n    durationMs: number;\n    retryCount: number;\n    inputTokens?: number;\n    outputTokens?: number;\n    omittedTasks?: number;\n  };\n}\n```\n\n- `config` でデフォルトを構築し、CLI/環境変数で上書き可能にする。\n- `PhaseContext` に `issueGenerationOptions` を追加し、省略時は `{ enabled: false, provider: 'auto' }` を適用。\n\n### 7.2 IssueAIGenerator クラス (新規)\n\n- コンストラクタ: `(providers: Record<'openai' | 'claude', LlmProviderAdapter>, secretMasker = new SecretMasker())`。\n- 補助的なエラー型:\n  - `IssueAIUnavailableError` (credentials 不足など)\n  - `IssueAIValidationError` (出力検証失敗)\n- 公開メソッド:\n  - `isAvailable(options: IssueGenerationOptions): boolean`  \n    - `options.enabled` が true かつ選択された provider（`auto` の場合は利用可能なもの）が `hasCredentials()` を満たす。\n  - `generate(tasks, context, issueNumber, options): Promise<IssueAIGenerationResult>`  \n    1. `sanitizePayload(tasks, context, options.maxTasks ?? 5)`  \n       - `RemainingTask` を優先度順 (High→Medium→Low) に並べ、上位 `maxTasks` を採用。超過分は `omittedTasks` としてメタに記録。  \n       - 各文字列フィールドは 512 文字にトリム。`targetFiles` は 10 件、`steps` / `acceptanceCriteria` は各 8 件まで。  \n       - `SecretMasker.maskObject` で既知のシークレット値・トークン・メールアドレスを `[REDACTED_x]` に置換。\n    2. `buildPrompt(issueNumber, sanitizedPayload, context, options)`  \n       - JSON 文字列化し、テンプレートへ埋め込む。\n    3. `invokeProvider(prompt, options)`  \n       - 選択された provider の `complete()` を呼び出す。  \n       - レート制限時は指数バックオフ (2000ms, 4000ms, 8000ms) とし、回数は `options.maxRetries`。\n    4. `parseAndValidate(responseText)`  \n       - JSON パース → タイトル長 50〜80 文字 → 必須セクションを順番に確認 → `実行内容` セクションが番号付きリスト (`1.` 形式) とテスト手順 (`テスト` or `検証`) を含むか検証 → HTML タグを禁止。  \n       - 失敗時は `IssueAIValidationError`。\n    5. 成功時に metadata (provider, model, duration, retryCount, input/output tokens, omittedTasks) 付きで返却。\n\n### 7.3 LlmProviderAdapter\n\n```ts\ninterface LlmProviderAdapter {\n  name: 'openai' | 'claude';\n  hasCredentials(): boolean;\n  complete(prompt: string, options: IssueGenerationOptions): Promise<LlmProviderResponse>;\n}\n\ninterface LlmProviderResponse {\n  text: string;\n","exit_code":0,"status":"completed"}}
{"type":"item.started","item":{"id":"item_5","type":"command_execution","command":"bash -lc \"sed -n '200,400p' design.md\"","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_5","type":"command_execution","command":"bash -lc \"sed -n '200,400p' design.md\"","aggregated_output":"  text: string;\n  inputTokens?: number;\n  outputTokens?: number;\n  retryCount: number;\n  durationMs: number;\n}\n```\n\n- **OpenAIAdapter**\n  - `openai.chat.completions.create()` を呼び出し、`response_format: { type: 'json_object' }` を指定。\n  - `AbortController` で `timeoutMs` を強制。\n  - HTTP 429/5xx 時は指数バックオフで再試行。最終的に失敗ならエラーをスロー。\n- **AnthropicAdapter**\n  - `@anthropic-ai/claude-agent-sdk` の `messages.create()` を利用。\n  - `options.model` が無ければ `claude-3-sonnet-20240229` を使用。\n  - 応答の `content` を結合し JSON テキストを取得。\n- `provider: 'auto'` の場合は OpenAI キーが存在すれば OpenAIAdapter、それ以外は ClaudeAdapter を選択。\n\n### 7.4 プロンプト生成とバリデーション\n\nテンプレート例 (コード内定数として保持):\n\n````markdown\nあなたはソフトウェア開発プロジェクトのIssue作成アシスタントです。\n以下のJSONを読み取り、フォローアップIssueを構築してください。\n\n入力:\n{{payload}}\n\n要件:\n1. タイトルは50〜80文字。対象コンポーネントや目的のキーワードを含めること。\n2. 本文は以下の見出し順序とします。\n   ## 背景\n   ## 目的\n   ## 実行内容\n   ## 受け入れ基準\n   ## 関連リソース\n3. 実行内容には対象ファイル・手順・テスト方法を含めること。\n4. JSON 形式で回答してください。\n\n出力形式:\n{\n  \"title\": \"...\",\n  \"body\": \"...\"\n}\n````\n\n- `parseAndValidate` 検証ルール:\n  - JSON パース失敗 → `IssueAIValidationError`。\n  - タイトル文字数 (全角半角問わず) が 50 未満または 80 超過で失敗。\n  - 本文に必須5セクションが順番に存在するか正規表現で確認。\n  - `## 実行内容` 内に番号付きリスト (`^\\d+\\. `) があり、いずれかの行に `テスト`/`検証` を含むことを確認。\n  - HTML/スクリプトタグを検出したら失敗。\n  - 余分な末尾空行は `trimEnd()` で整理。\n\n### 7.5 IssueClient 拡張\n\n- コンストラクタに `IssueAIGenerator | null` を追加 (`new IssueClient(octokit, owner, repo, issueAIGenerator)`).\n- 新規ヘルパー:\n  - `private buildLegacyBody(...)`: 現行ロジックを抽出し、フォールバック時に再利用。\n  - `private appendMetadata(body, metadata, options)`: `options.appendMetadata` が true の場合に以下を追加。\n    ```\n    ## 生成メタデータ\n    - モデル: ${metadata.model} (${metadata.provider})\n    - 所要時間: ${metadata.durationMs}ms / 再試行: ${metadata.retryCount}\n    - トークン: in ${metadata.inputTokens ?? '-'} / out ${metadata.outputTokens ?? '-'}\n    - 省略したタスク数: ${metadata.omittedTasks ?? 0}\n    ```\n  - `private async tryGenerateWithLLM(...)`: LLM が利用可能か判定し、失敗時は WARN ログで理由を記録して `null` を返す。\n- `createIssueFromEvaluation` の流れ:\n  1. `const aiResult = await this.tryGenerateWithLLM(...);`\n  2. `const title = aiResult?.title ?? this.generateFollowUpTitle(...);`\n  3. `const baseBody = aiResult?.body ?? this.buildLegacyBody(...);`\n  4. `const body = aiResult ? this.appendMetadata(baseBody, aiResult.metadata, options) : baseBody;`\n  5. 既存どおり Octokit で Issue を作成。\n- ログ出力:\n  - 成功 (`logger.debug`): `FOLLOWUP_LLM_SUCCESS { provider, model, durationMs, retryCount }`\n  - フォールバック (`logger.warn`): `FOLLOWUP_LLM_FALLBACK { reason, fallback: 'legacy_template' }`\n  - ログにはプロンプト本文を含めない。\n\n### 7.6 GitHubClient / Phase 連携\n\n- `GitHubClient` コンストラクタで `IssueAIGenerator` を生成し `IssueClient` に渡す。\n- `createIssueFromEvaluation` の署名を `(..., issueContext?: IssueContext, options?: IssueGenerationOptions)` に拡張。`options` が無い場合は `config` から取得する。\n- `EvaluationPhase`:\n  ```ts\n  const options = this.context.issueGenerationOptions ?? { enabled: false, provider: 'auto' };\n  const result = await this.github.createIssueFromEvaluation(\n    issueNumber,\n    remainingTasks,\n    relativeReportPath,\n    issueContext,\n    options,\n  );\n  ```\n- `PhaseFactory` / `BasePhase` で `PhaseContext.issueGenerationOptions` を新たに受け渡す。\n\n### 7.7 CLI / Config 拡張\n\n- `ExecuteCommandOptions` に以下フィールドを追加:\n  - `followupLlmMode?: 'auto' | 'openai' | 'claude' | 'off'`\n  - `followupLlmModel?: string`\n  - `followupLlmTimeout?: number`\n  - `followupLlmMaxRetries?: number`\n  - `followupLlmAppendMetadata?: boolean`\n- `options-parser.ts` でバリデーション:\n  - `off` → `enabled` false。\n  - timeout/retries は正の整数 (0 許容)。\n  - provider 指定が `openai` なのに OpenAI APIキー不在の場合は警告ログを出して `enabled=false`。\n- `config.ts` で環境変数ゲッターを追加 (`FOLLOWUP_LLM_MODE`, `FOLLOWUP_LLM_MODEL`, `FOLLOWUP_LLM_TIMEOUT_MS`, `FOLLOWUP_LLM_MAX_RETRIES`, `FOLLOWUP_LLM_APPEND_METADATA`)。\n- CLI 例:  \n  `ai-workflow execute --issue 119 --phase evaluation --followup-llm-mode auto --followup-llm-model claude-3-sonnet-20240229`.\n\n### 7.8 ロギング・モニタリング\n\n- LLM 成功時は DEBUG ログ、再試行数 > 0 の場合は WARN と INFO の両方に出力して追跡可能にする。\n- フォールバック発生時は WARN ログを構造化文字列 (JSON 互換) で出力。`event=FOLLOWUP_LLM_FALLBACK`, `fallback_mode=legacy_template`, `reason=...`。\n- `IssueAIGenerator.generate` 内で `performance.now()` を使い処理時間を計測。\n- ログには機密情報やプロンプト全文を含めない。\n\n### 7.9 テスト設計詳細\n\n| レイヤ | テストケース | 目的 |\n| --- | --- | --- |\n| Unit (`issue-ai-generator.test.ts`) | タスク数制限・文字列トリム・ターゲットファイル上限を検証 | サニタイズ仕様の担保 |\n|  | JSON 以外の応答で `IssueAIValidationError` を投げる | バリデーション |\n|  | 必須セクション欠落、タイトル長不正、HTMLタグ混入で失敗する | FR-1/FR-2 |\n|  | 1回目失敗→2回目成功のリトライ時に最終成功 | リトライ制御 |\n|  | `SecretMasker` により API キーがプロンプトに残らない | セキュリティ |\n| Unit (`issue-client.test.ts`) | LLM 成功時に Octokit へ LLM 出力が渡る | フロー検証 |\n|  | 例外発生時に WARN ログとフォールバックタイトル/本文が使用される | FR-3 |\n| Integration (`followup-issue-llm.test.ts`) | CLI -> PhaseContext -> GitHubClient -> IssueClient のオプション伝搬 | 設定連携 |\n|  | LLM が無効化されている場合に既存挙動が維持される | 後方互換 |\n|  | `FOLLOWUP_LLM_E2E=1` 時のみ実APIを使い、成功時タイトル/本文が要件を満たすか検証 (失敗時はテストをスキップ) | 実API検証 |\n\n### 7.10 要件トレーサビリティ\n\n| 要件ID | 対応箇所 |\n| --- | --- |\n| FR-1 | 7.4 プロンプト設計・タイトル検証、7.5 タイトル採用ロジック |\n| FR-2 | 7.4 セクション検証、7.5 `buildLegacyBody` との比較で差異を吸収 |\n| FR-3 | 7.5 `tryGenerateWithLLM` フォールバック制御 |\n| FR-4 | 7.6 Phase 連携、7.7 CLI/Config 拡張 |\n| FR-5 | 7.5 ログ出力設計、7.8 モニタリング |\n\n### 7.11 ドキュメント更新\n\n- `ARCHITECTURE.md`: Evaluation → GitHubClient → IssueAIGenerator → IssueClient のフロー図と説明を追加。\n- `CLAUDE.md`: Follow-up LLM 設定方法、環境変数、フォールバック観察ポイントを追記。\n- `README.md`: CLI オプションと `.env` 設定例、フォールバック時のトラブルシューティングを追加。\n\n---\n\n## 8. セキュリティ考慮事項\n\n- `SecretMasker` と追加の簡易正規表現 (API キーフォーマット、メールアドレス) を `sanitizePayload` に適用し、機密情報送信を防止。\n- LLM 応答に HTML/スクリプトタグが含まれる場合はバリデーションエラーとし、フォールバックへ切り替える。\n- API キーは `config` ゲッター経由でのみ参照し、ログへ出力しない。\n- プロンプト・レスポンスをファイルへ書き出さない。ログにはメタデータのみを残す。\n- 再試行回数を `maxRetries` で制限し、無限ループやコスト過多を防止。\n\n---\n\n## 9. 非機能要件への対応\n\n- **パフォーマンス**: `timeoutMs` と `maxRetries` で最悪ケースでも 25s × 3 = 75s 以内にフォールバック。タスク数・文字数の制限で入力サイズを抑制し、LLM 呼び出し平均 15s 以内を目指す。\n- **スケーラビリティ**: Provider 抽象化でモデル追加が容易。`maxTasks` で大規模残タスクでも安定して処理。\n- **保守性**: LLM ロジックを `IssueAIGenerator` に集約し、IssueClient と疎結合化。テストで回帰を検知しやすくする。\n- **可用性**: LLM 失敗時でも既存テンプレートで確実に Issue を生成 (FR-3)。WARN ログで運用監視が容易。\n- **コスト管理**: デフォルト無効 (`enabled=false`) で不要な API 呼び出しを防止。`appendMetadata` で生成コストを Issue 上に可視化可能。\n\n---\n\n## 10. 実装の順序\n\n1. **型と設定の整備**: `IssueGenerationOptions`、`PhaseContext`、CLI/Config 拡張。既存コードをコンパイル可能に更新。\n2. **IssueAIGenerator 実装**: プロンプトテンプレート、サニタイズ、Provider アダプタ、検証、専用エラーを実装。\n3. **IssueClient / GitHubClient 更新**: 依存注入、LLM 分岐、フォールバックとログ処理を追加。\n4. **Phase / CLI 連携**: EvaluationPhase がオプションを渡すよう調整し、実行時の設定反映を確認。\n5. **テスト追加・更新**: 新規ユニットテスト、既存テスト更新、統合テストでオプション伝搬とフォールバックを検証。\n6. **ドキュメント更新**: ARCHITECTURE / CLAUDE / README / `.env.example` を更新。\n7. **検証**: `npm run test:unit`, `npm run test:integration` 実行。必要に応じ `FOLLOWUP_LLM_E2E=1` で手動統合テストを確認。\n\n---\n\n## 11. 品質ゲート確認\n\n- 実装戦略 (EXTEND) の判断根拠を明記。\n- テスト戦略 (UNIT_INTEGRATION) の判断根拠を明記。\n- 既存コードへの影響と依存関係を分析。\n- 変更・追加ファイルを列挙。\n- 詳細設計と要件トレーサビリティを提示し実装可能性を保証。\n\n","exit_code":0,"status":"completed"}}
{"type":"item.started","item":{"id":"item_6","type":"command_execution","command":"bash -lc \"sed -n '400,600p' design.md\"","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_6","type":"command_execution","command":"bash -lc \"sed -n '400,600p' design.md\"","aggregated_output":"","exit_code":0,"status":"completed"}}
{"type":"item.started","item":{"id":"item_7","type":"command_execution","command":"bash -lc \"sed -n '120,220p' design.md\"","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_7","type":"command_execution","command":"bash -lc \"sed -n '120,220p' design.md\"","aggregated_output":"  - `src/types.ts`\n  - `src/types/commands.ts`\n  - `src/core/config.ts`\n  - `tests/unit/github/issue-client.test.ts`\n  - `tests/unit/github/issue-client-followup.test.ts`\n  - `tests/integration/github-client-facade.test.ts`\n  - ドキュメント (`ARCHITECTURE.md`, `CLAUDE.md`, `README.md`, `.env.example`)\n- **削除予定**: なし\n\n---\n\n## 7. 詳細設計\n\n### 7.1 IssueGenerationOptions / IssueAIGenerationResult\n\n```ts\nexport interface IssueGenerationOptions {\n  enabled: boolean;\n  provider: 'auto' | 'openai' | 'claude';\n  model?: string;\n  temperature?: number;          // default 0.2\n  maxOutputTokens?: number;      // default 1500\n  timeoutMs?: number;            // default 25000\n  maxRetries?: number;           // default 3\n  maxTasks?: number;             // default 5\n  appendMetadata?: boolean;      // default false\n}\n\nexport interface IssueAIGenerationResult {\n  title: string;\n  body: string;\n  metadata: {\n    provider: 'openai' | 'claude';\n    model: string;\n    durationMs: number;\n    retryCount: number;\n    inputTokens?: number;\n    outputTokens?: number;\n    omittedTasks?: number;\n  };\n}\n```\n\n- `config` でデフォルトを構築し、CLI/環境変数で上書き可能にする。\n- `PhaseContext` に `issueGenerationOptions` を追加し、省略時は `{ enabled: false, provider: 'auto' }` を適用。\n\n### 7.2 IssueAIGenerator クラス (新規)\n\n- コンストラクタ: `(providers: Record<'openai' | 'claude', LlmProviderAdapter>, secretMasker = new SecretMasker())`。\n- 補助的なエラー型:\n  - `IssueAIUnavailableError` (credentials 不足など)\n  - `IssueAIValidationError` (出力検証失敗)\n- 公開メソッド:\n  - `isAvailable(options: IssueGenerationOptions): boolean`  \n    - `options.enabled` が true かつ選択された provider（`auto` の場合は利用可能なもの）が `hasCredentials()` を満たす。\n  - `generate(tasks, context, issueNumber, options): Promise<IssueAIGenerationResult>`  \n    1. `sanitizePayload(tasks, context, options.maxTasks ?? 5)`  \n       - `RemainingTask` を優先度順 (High→Medium→Low) に並べ、上位 `maxTasks` を採用。超過分は `omittedTasks` としてメタに記録。  \n       - 各文字列フィールドは 512 文字にトリム。`targetFiles` は 10 件、`steps` / `acceptanceCriteria` は各 8 件まで。  \n       - `SecretMasker.maskObject` で既知のシークレット値・トークン・メールアドレスを `[REDACTED_x]` に置換。\n    2. `buildPrompt(issueNumber, sanitizedPayload, context, options)`  \n       - JSON 文字列化し、テンプレートへ埋め込む。\n    3. `invokeProvider(prompt, options)`  \n       - 選択された provider の `complete()` を呼び出す。  \n       - レート制限時は指数バックオフ (2000ms, 4000ms, 8000ms) とし、回数は `options.maxRetries`。\n    4. `parseAndValidate(responseText)`  \n       - JSON パース → タイトル長 50〜80 文字 → 必須セクションを順番に確認 → `実行内容` セクションが番号付きリスト (`1.` 形式) とテスト手順 (`テスト` or `検証`) を含むか検証 → HTML タグを禁止。  \n       - 失敗時は `IssueAIValidationError`。\n    5. 成功時に metadata (provider, model, duration, retryCount, input/output tokens, omittedTasks) 付きで返却。\n\n### 7.3 LlmProviderAdapter\n\n```ts\ninterface LlmProviderAdapter {\n  name: 'openai' | 'claude';\n  hasCredentials(): boolean;\n  complete(prompt: string, options: IssueGenerationOptions): Promise<LlmProviderResponse>;\n}\n\ninterface LlmProviderResponse {\n  text: string;\n  inputTokens?: number;\n  outputTokens?: number;\n  retryCount: number;\n  durationMs: number;\n}\n```\n\n- **OpenAIAdapter**\n  - `openai.chat.completions.create()` を呼び出し、`response_format: { type: 'json_object' }` を指定。\n  - `AbortController` で `timeoutMs` を強制。\n  - HTTP 429/5xx 時は指数バックオフで再試行。最終的に失敗ならエラーをスロー。\n- **AnthropicAdapter**\n  - `@anthropic-ai/claude-agent-sdk` の `messages.create()` を利用。\n  - `options.model` が無ければ `claude-3-sonnet-20240229` を使用。\n  - 応答の `content` を結合し JSON テキストを取得。\n- `provider: 'auto'` の場合は OpenAI キーが存在すれば OpenAIAdapter、それ以外は ClaudeAdapter を選択。\n\n### 7.4 プロンプト生成とバリデーション\n\nテンプレート例 (コード内定数として保持):\n","exit_code":0,"status":"completed"}}
{"type":"item.started","item":{"id":"item_8","type":"command_execution","command":"bash -lc \"sed -n '90,140p' design.md\"","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_8","type":"command_execution","command":"bash -lc \"sed -n '90,140p' design.md\"","aggregated_output":"- `src/phases/evaluation.ts`: `GitHubClient.createIssueFromEvaluation` 呼び出しに LLM オプションを渡す。\n- `src/commands/execute.ts` / `src/commands/execute/options-parser.ts`: CLI オプション解析に Follow-up LLM 設定を追加し `PhaseContext` へ渡す。\n- `src/types.ts`: `IssueGenerationOptions` や LLM 結果の型を追加。\n- `src/types/commands.ts`: `PhaseContext` に `issueGenerationOptions` プロパティを追加。\n- `src/core/config.ts`: LLM 設定用ゲッターを実装。\n- 既存テスト (`tests/unit/github/issue-client*.ts`, `tests/integration/github-client-facade.test.ts`) を LLM 統合ケースで更新。\n\n### 5.2 依存関係の変更\n- 追加パッケージは想定なし。既存 `openai`, `@anthropic-ai/claude-agent-sdk` を再利用。\n- Jest モックは既存 `jest-mock-extended` や手動モックを活用。\n\n### 5.3 マイグレーション要否\n- データマイグレーションは不要。\n- `.env.example` が存在する場合は Follow-up LLM 用環境変数を追加。\n- `ARCHITECTURE.md`, `CLAUDE.md`, `README.md` を更新して設定手順とフォールバック説明を追記。\n\n---\n\n## 6. 変更・追加ファイルリスト\n\n- **新規作成**\n  - `src/core/github/issue-ai-generator.ts`\n  - `tests/unit/github/issue-ai-generator.test.ts`\n  - `tests/integration/followup-issue-llm.test.ts` (Octokit モック中心)\n- **既存修正**\n  - `src/core/github/issue-client.ts`\n  - `src/core/github-client.ts`\n  - `src/phases/evaluation.ts`\n  - `src/commands/execute.ts`\n  - `src/commands/execute/options-parser.ts`\n  - `src/types.ts`\n  - `src/types/commands.ts`\n  - `src/core/config.ts`\n  - `tests/unit/github/issue-client.test.ts`\n  - `tests/unit/github/issue-client-followup.test.ts`\n  - `tests/integration/github-client-facade.test.ts`\n  - ドキュメント (`ARCHITECTURE.md`, `CLAUDE.md`, `README.md`, `.env.example`)\n- **削除予定**: なし\n\n---\n\n## 7. 詳細設計\n\n### 7.1 IssueGenerationOptions / IssueAIGenerationResult\n\n```ts\nexport interface IssueGenerationOptions {\n  enabled: boolean;\n  provider: 'auto' | 'openai' | 'claude';\n  model?: string;\n  temperature?: number;          // default 0.2\n","exit_code":0,"status":"completed"}}
{"type":"item.started","item":{"id":"item_9","type":"todo_list","items":[{"text":"Review current design.md and reviewer feedback to understand required updates.","completed":true},{"text":"Update design.md to document SecretMasker extension and align file lists with actual change set.","completed":false},{"text":"Double-check revised sections for consistency and prepare response to user.","completed":false}]}}
{"type":"item.started","item":{"id":"item_10","type":"command_execution","command":"bash -lc 'ls src/phases'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_10","type":"command_execution","command":"bash -lc 'ls src/phases'","aggregated_output":"base-phase.ts\ncleanup\ncontext\ncore\ndesign.ts\ndocumentation.ts\nevaluation.ts\nformatters\nimplementation.ts\nlifecycle\nplanning.ts\nreport.ts\nrequirements.ts\ntest-implementation.ts\ntest-scenario.ts\ntesting.ts\n","exit_code":0,"status":"completed"}}
{"type":"item.started","item":{"id":"item_11","type":"command_execution","command":"bash -lc 'ls src/phases/core'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_11","type":"command_execution","command":"bash -lc 'ls src/phases/core'","aggregated_output":"agent-executor.ts\nreview-cycle-manager.ts\n","exit_code":0,"status":"completed"}}
{"type":"item.started","item":{"id":"item_12","type":"command_execution","command":"bash -lc 'rg \"PhaseFactory\" -n'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_12","type":"command_execution","command":"bash -lc 'rg \"PhaseFactory\" -n'","aggregated_output":"bash: line 1: rg: command not found\n","exit_code":127,"status":"failed"}}
{"type":"item.started","item":{"id":"item_13","type":"command_execution","command":"bash -lc 'grep -R \"PhaseFactory\" -n'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_13","type":"command_execution","command":"bash -lc 'grep -R \"PhaseFactory\" -n'","aggregated_output":".ai-workflow/issue-119/02_design/revise/prompt.txt:40:**懸念点**: `PhaseContext` を拡張すると明記しているものの、`PhaseFactory` や `BasePhase` など伝搬に必要なファイルが変更リストに含まれていません（design.md:85, design.md:108）。\n.ai-workflow/issue-119/02_design/revise/prompt.txt:72:   - 現状: `PhaseContext.issueGenerationOptions` を追加すると記載されていますが、`PhaseFactory` や `BasePhase` などで値を渡す作業が変更一覧に載っていません（design.md:85, design.md:108）。\n.ai-workflow/issue-119/02_design/review/result.md:19:**懸念点**: `PhaseContext` を拡張すると明記しているものの、`PhaseFactory` や `BasePhase` など伝搬に必要なファイルが変更リストに含まれていません（design.md:85, design.md:108）。\n.ai-workflow/issue-119/02_design/review/result.md:51:   - 現状: `PhaseContext.issueGenerationOptions` を追加すると記載されていますが、`PhaseFactory` や `BasePhase` などで値を渡す作業が変更一覧に載っていません（design.md:85, design.md:108）。\n.ai-workflow/issue-119/02_design/review/agent_log.md:289:2. `commands/execute` が `PhaseContext.issueGenerationOptions` を組み立て、`PhaseFactory` 経由で `EvaluationPhase` へ受け渡す。\n.ai-workflow/issue-119/02_design/review/agent_log.md:400:2. `commands/execute` が `PhaseContext.issueGenerationOptions` を組み立て、`PhaseFactory` 経由で `EvaluationPhase` へ受け渡す。\n.ai-workflow/issue-119/02_design/review/agent_log_raw.txt:14:{\"type\":\"item.completed\",\"item\":{\"id\":\"item_5\",\"type\":\"command_execution\",\"command\":\"bash -lc 'cat .ai-workflow/issue-119/02_design/output/design.md'\",\"aggregated_output\":\"# 詳細設計書 - Issue #119 フォローアップIssue生成品質の改善（LLM活用）\\n\\n**Issue番号**: #119  \\n**タイトル**: フォローアップIssue生成品質の改善（LLM活用）  \\n**バージョン**: 1.1 (Design)\\n\\n---\\n\\n## 1. アーキテクチャ設計\\n\\n### 1.1 システム全体フロー\\n\\n```\\nEvaluationPhase (Phase 9)\\n    │ RemainingTask[], IssueContext, evaluation report path, generation options\\n    ▼\\nGitHubClient.createIssueFromEvaluation(...)\\n    │ delegates\\n    ▼\\nIssueClient (LLM-aware)\\n    ├─ IssueAIGenerator.generate(...)\\n    │     └─ LLM Provider Adapter (OpenAI / Anthropic)\\n    └─ Legacy builders (generateFollowUpTitle + buildLegacyBody)\\n    ▼\\nOctokit.issues.create(...) → GitHub Issue\\n```\\n\\n### 1.2 コンポーネント責務\\n\\n| コンポーネント | 役割 | 主な入出力 |\\n| --- | --- | --- |\\n| `EvaluationPhase` | Phase 9 の処理。残タスク検出後に GitHubClient へフォローアップ生成を依頼 | 入力: Evaluation結果 / 出力: IssueGenerationOptions 付き呼び出し |\\n| `GitHubClient` | GitHub API ファサード。IssueClient へ委譲し設定を束ねる | 入力: issue番号, tasks, options / 出力: IssueCreationResult |\\n| `IssueClient` | フォローアップIssue生成の集約。LLM生成→フォールバック制御→Octokit呼び出し | 入力: tasks, context, options / 出力: タイトル・本文・ログ |\\n| `IssueAIGenerator` (新規) | LLMプロンプト生成、API呼び出し、レスポンス検証 | 入力: tasks, context, options / 出力: { title, body, metadata } |\\n| `LlmProviderAdapter` (OpenAI / Anthropic) | 各APIのラッパー。タイムアウト・再試行を実装 | 入出力: prompt, call options, completion JSON |\\n| `config` / CLI | 環境変数・CLIから LLM 設定を収集し PhaseContextへ渡す | 入出力: Follow-up LLM 設定値 |\\n| `SecretMasker` (既存) | 機密情報のマスキング | 入力: プロンプトPayload / 出力: SanitizedPayload |\\n\\n### 1.3 データフロー\\n\\n1. ユーザーが `ai-workflow execute ...` を実行し、CLI が Follow-up LLM オプションを解析 (デフォルトは無効)。\\n2. `commands/execute` が `PhaseContext.issueGenerationOptions` を組み立て、`PhaseFactory` 経由で `EvaluationPhase` へ受け渡す。\\n3. EvaluationPhase で残タスクが存在すると `GitHubClient.createIssueFromEvaluation(issueNumber, tasks, reportPath, context, options)` を呼び出す。\\n4. `GitHubClient` は `IssueAIGenerator` をコンストラクタインジェクション済みの `IssueClient` に委譲。\\n5. `IssueClient` が `options.enabled` と `IssueAIGenerator.isAvailable()` を確認し、利用可能なら `generate(tasks, context, options)` を試行。\\n6. `IssueAIGenerator` は payload をサニタイズ→プロンプト生成→LLM呼び出し→検証し、成功時にタイトル・本文を返却。\\n7. LLM 失敗または無効時、`IssueClient` は既存の `generateFollowUpTitle` と新設の `buildLegacyBody` でフォールバック本文を生成。\\n8. 生成結果と `## 参考` セクション (＋オプションで LLM metadata) を結合し、Octokit で Issue を作成。ログへ成否とメタ情報を出力。\\n\\n### 1.4 主なシーケンスと失敗時動作\\n\\n- LLM 成功: `IssueAIGenerator` → validated result → `IssueClient` が LLM 出力を採用 → `options.appendMetadata` が true の場合にメタデータ節を付加。\\n- LLM タイムアウト / レート制限: Providerアダプタが指数バックオフで再試行。全失敗で `IssueAIError` を返し IssueClient が WARN を記録しフォールバック。\\n- プロンプト検証失敗: `IssueAIGenerator` が `IssueAIValidationError` を送出し、同様にフォールバック。\\n- Octokit 失敗: 既存処理と同様に ERROR ログを出力し `IssueCreationResult` で失敗を返却。\\n\\n---\\n\\n## 2. 実装戦略判断: EXTEND\\n\\n**判断根拠**:\\n- 既存 `IssueClient` / `GitHubClient` / CLI フローを維持したまま責務を拡張する必要があるため。\\n- フォールバックとして既存テンプレートを保持しつつ LLM 生成を追加する形で後方互換を守る。\\n- Planning Document の戦略 (新規モジュール追加 + 既存コード拡張) と整合。\\n\\n---\\n\\n## 3. テスト戦略判断: UNIT_INTEGRATION\\n\\n**判断根拠**:\\n- プロンプト生成・レスポンス検証・リトライといったロジックはモック化が容易であり、ユニットテストで網羅できる。\\n- GitHub 連携や Phase からのオプション伝搬、フォールバック全体の動作は統合テストで確認する必要がある。\\n\\n---\\n\\n## 4. テストコード戦略判断: BOTH_TEST\\n\\n**判断根拠**:\\n- 既存 `issue-client` テストに LLM 成功/失敗パスを追加する必要がある (既存テストの拡張)。\\n- `IssueAIGenerator` 用の専用ユニットテストが新規に必要となる (新規テスト作成)。\\n\\n---\\n\\n## 5. 影響範囲分析\\n\\n### 5.1 既存コードへの影響\\n- `src/core/github/issue-client.ts`: 依存注入、LLM 分岐、本文生成をメソッド化、WARN/DEBUG ログ拡張。\\n- `src/core/github-client.ts`: `IssueAIGenerator` の初期化と委譲。`createIssueFromEvaluation` にオプションパラメータ追加。\\n- `src/phases/evaluation.ts`: `GitHubClient.createIssueFromEvaluation` 呼び出しに LLM オプションを渡す。\\n- `src/commands/execute.ts` / `src/commands/execute/options-parser.ts`: CLI オプション解析に Follow-up LLM 設定を追加し `PhaseContext` へ渡す。\\n- `src/types.ts`: `IssueGenerationOptions` や LLM 結果の型を追加。\\n- `src/types/commands.ts`: `PhaseContext` に `issueGenerationOptions` プロパティを追加。\\n- `src/core/config.ts`: LLM 設定用ゲッターを実装。\\n- 既存テスト (`tests/unit/github/issue-client*.ts`, `tests/integration/github-client-facade.test.ts`) を LLM 統合ケースで更新。\\n\\n### 5.2 依存関係の変更\\n- 追加パッケージは想定なし。既存 `openai`, `@anthropic-ai/claude-agent-sdk` を再利用。\\n- Jest モックは既存 `jest-mock-extended` や手動モックを活用。\\n\\n### 5.3 マイグレーション要否\\n- データマイグレーションは不要。\\n- `.env.example` が存在する場合は Follow-up LLM 用環境変数を追加。\\n- `ARCHITECTURE.md`, `CLAUDE.md`, `README.md` を更新して設定手順とフォールバック説明を追記。\\n\\n---\\n\\n## 6. 変更・追加ファイルリスト\\n\\n- **新規作成**\\n  - `src/core/github/issue-ai-generator.ts`\\n  - `tests/unit/github/issue-ai-generator.test.ts`\\n  - `tests/integration/followup-issue-llm.test.ts` (Octokit モック中心)\\n- **既存修正**\\n  - `src/core/github/issue-client.ts`\\n  - `src/core/github-client.ts`\\n  - `src/phases/evaluation.ts`\\n  - `src/commands/execute.ts`\\n  - `src/commands/execute/options-parser.ts`\\n  - `src/types.ts`\\n  - `src/types/commands.ts`\\n  - `src/core/config.ts`\\n  - `tests/unit/github/issue-client.test.ts`\\n  - `tests/unit/github/issue-client-followup.test.ts`\\n  - `tests/integration/github-client-facade.test.ts`\\n  - ドキュメント (`ARCHITECTURE.md`, `CLAUDE.md`, `README.md`, `.env.example`)\\n- **削除予定**: なし\\n\\n---\\n\\n## 7. 詳細設計\\n\\n### 7.1 IssueGenerationOptions / IssueAIGenerationResult\\n\\n```ts\\nexport interface IssueGenerationOptions {\\n  enabled: boolean;\\n  provider: 'auto' | 'openai' | 'claude';\\n  model?: string;\\n  temperature?: number;          // default 0.2\\n  maxOutputTokens?: number;      // default 1500\\n  timeoutMs?: number;            // default 25000\\n  maxRetries?: number;           // default 3\\n  maxTasks?: number;             // default 5\\n  appendMetadata?: boolean;      // default false\\n}\\n\\nexport interface IssueAIGenerationResult {\\n  title: string;\\n  body: string;\\n  metadata: {\\n    provider: 'openai' | 'claude';\\n    model: string;\\n    durationMs: number;\\n    retryCount: number;\\n    inputTokens?: number;\\n    outputTokens?: number;\\n    omittedTasks?: number;\\n  };\\n}\\n```\\n\\n- `config` でデフォルトを構築し、CLI/環境変数で上書き可能にする。\\n- `PhaseContext` に `issueGenerationOptions` を追加し、省略時は `{ enabled: false, provider: 'auto' }` を適用。\\n\\n### 7.2 IssueAIGenerator クラス (新規)\\n\\n- コンストラクタ: `(providers: Record<'openai' | 'claude', LlmProviderAdapter>, secretMasker = new SecretMasker())`。\\n- 補助的なエラー型:\\n  - `IssueAIUnavailableError` (credentials 不足など)\\n  - `IssueAIValidationError` (出力検証失敗)\\n- 公開メソッド:\\n  - `isAvailable(options: IssueGenerationOptions): boolean`  \\n    - `options.enabled` が true かつ選択された provider（`auto` の場合は利用可能なもの）が `hasCredentials()` を満たす。\\n  - `generate(tasks, context, issueNumber, options): Promise<IssueAIGenerationResult>`  \\n    1. `sanitizePayload(tasks, context, options.maxTasks ?? 5)`  \\n       - `RemainingTask` を優先度順 (High→Medium→Low) に並べ、上位 `maxTasks` を採用。超過分は `omittedTasks` としてメタに記録。  \\n       - 各文字列フィールドは 512 文字にトリム。`targetFiles` は 10 件、`steps` / `acceptanceCriteria` は各 8 件まで。  \\n       - `SecretMasker.maskObject` で既知のシークレット値・トークン・メールアドレスを `[REDACTED_x]` に置換。\\n    2. `buildPrompt(issueNumber, sanitizedPayload, context, options)`  \\n       - JSON 文字列化し、テンプレートへ埋め込む。\\n    3. `invokeProvider(prompt, options)`  \\n       - 選択された provider の `complete()` を呼び出す。  \\n       - レート制限時は指数バックオフ (2000ms, 4000ms, 8000ms) とし、回数は `options.maxRetries`。\\n    4. `parseAndValidate(responseText)`  \\n       - JSON パース → タイトル長 50〜80 文字 → 必須セクションを順番に確認 → `実行内容` セクションが番号付きリスト (`1.` 形式) とテスト手順 (`テスト` or `検証`) を含むか検証 → HTML タグを禁止。  \\n       - 失敗時は `IssueAIValidationError`。\\n    5. 成功時に metadata (provider, model, duration, retryCount, input/output tokens, omittedTasks) 付きで返却。\\n\\n### 7.3 LlmProviderAdapter\\n\\n```ts\\ninterface LlmProviderAdapter {\\n  name: 'openai' | 'claude';\\n  hasCredentials(): boolean;\\n  complete(prompt: string, options: IssueGenerationOptions): Promise<LlmProviderResponse>;\\n}\\n\\ninterface LlmProviderResponse {\\n  text: string;\\n  inputTokens?: number;\\n  outputTokens?: number;\\n  retryCount: number;\\n  durationMs: number;\\n}\\n```\\n\\n- **OpenAIAdapter**\\n  - `openai.chat.completions.create()` を呼び出し、`response_format: { type: 'json_object' }` を指定。\\n  - `AbortController` で `timeoutMs` を強制。\\n  - HTTP 429/5xx 時は指数バックオフで再試行。最終的に失敗ならエラーをスロー。\\n- **AnthropicAdapter**\\n  - `@anthropic-ai/claude-agent-sdk` の `messages.create()` を利用。\\n  - `options.model` が無ければ `claude-3-sonnet-20240229` を使用。\\n  - 応答の `content` を結合し JSON テキストを取得。\\n- `provider: 'auto'` の場合は OpenAI キーが存在すれば OpenAIAdapter、それ以外は ClaudeAdapter を選択。\\n\\n### 7.4 プロンプト生成とバリデーション\\n\\nテンプレート例 (コード内定数として保持):\\n\\n````markdown\\nあなたはソフトウェア開発プロジェクトのIssue作成アシスタントです。\\n以下のJSONを読み取り、フォローアップIssueを構築してください。\\n\\n入力:\\n{{payload}}\\n\\n要件:\\n1. タイトルは50〜80文字。対象コンポーネントや目的のキーワードを含めること。\\n2. 本文は以下の見出し順序とします。\\n   ## 背景\\n   ## 目的\\n   ## 実行内容\\n   ## 受け入れ基準\\n   ## 関連リソース\\n3. 実行内容には対象ファイル・手順・テスト方法を含めること。\\n4. JSON 形式で回答してください。\\n\\n出力形式:\\n{\\n  \\\"title\\\": \\\"...\\\",\\n  \\\"body\\\": \\\"...\\\"\\n}\\n````\\n\\n- `parseAndValidate` 検証ルール:\\n  - JSON パース失敗 → `IssueAIValidationError`。\\n  - タイトル文字数 (全角半角問わず) が 50 未満または 80 超過で失敗。\\n  - 本文に必須5セクションが順番に存在するか正規表現で確認。\\n  - `## 実行内容` 内に番号付きリスト (`^\\\\d+\\\\. `) があり、いずれかの行に `テスト`/`検証` を含むことを確認。\\n  - HTML/スクリプトタグを検出したら失敗。\\n  - 余分な末尾空行は `trimEnd()` で整理。\\n\\n### 7.5 IssueClient 拡張\\n\\n- コンストラクタに `IssueAIGenerator | null` を追加 (`new IssueClient(octokit, owner, repo, issueAIGenerator)`).\\n- 新規ヘルパー:\\n  - `private buildLegacyBody(...)`: 現行ロジックを抽出し、フォールバック時に再利用。\\n  - `private appendMetadata(body, metadata, options)`: `options.appendMetadata` が true の場合に以下を追加。\\n    ```\\n    ## 生成メタデータ\\n    - モデル: ${metadata.model} (${metadata.provider})\\n    - 所要時間: ${metadata.durationMs}ms / 再試行: ${metadata.retryCount}\\n    - トークン: in ${metadata.inputTokens ?? '-'} / out ${metadata.outputTokens ?? '-'}\\n    - 省略したタスク数: ${metadata.omittedTasks ?? 0}\\n    ```\\n  - `private async tryGenerateWithLLM(...)`: LLM が利用可能か判定し、失敗時は WARN ログで理由を記録して `null` を返す。\\n- `createIssueFromEvaluation` の流れ:\\n  1. `const aiResult = await this.tryGenerateWithLLM(...);`\\n  2. `const title = aiResult?.title ?? this.generateFollowUpTitle(...);`\\n  3. `const baseBody = aiResult?.body ?? this.buildLegacyBody(...);`\\n  4. `const body = aiResult ? this.appendMetadata(baseBody, aiResult.metadata, options) : baseBody;`\\n  5. 既存どおり Octokit で Issue を作成。\\n- ログ出力:\\n  - 成功 (`logger.debug`): `FOLLOWUP_LLM_SUCCESS { provider, model, durationMs, retryCount }`\\n  - フォールバック (`logger.warn`): `FOLLOWUP_LLM_FALLBACK { reason, fallback: 'legacy_template' }`\\n  - ログにはプロンプト本文を含めない。\\n\\n### 7.6 GitHubClient / Phase 連携\\n\\n- `GitHubClient` コンストラクタで `IssueAIGenerator` を生成し `IssueClient` に渡す。\\n- `createIssueFromEvaluation` の署名を `(..., issueContext?: IssueContext, options?: IssueGenerationOptions)` に拡張。`options` が無い場合は `config` から取得する。\\n- `EvaluationPhase`:\\n  ```ts\\n  const options = this.context.issueGenerationOptions ?? { enabled: false, provider: 'auto' };\\n  const result = await this.github.createIssueFromEvaluation(\\n    issueNumber,\\n    remainingTasks,\\n    relativeReportPath,\\n    issueContext,\\n    options,\\n  );\\n  ```\\n- `PhaseFactory` / `BasePhase` で `PhaseContext.issueGenerationOptions` を新たに受け渡す。\\n\\n### 7.7 CLI / Config 拡張\\n\\n- `ExecuteCommandOptions` に以下フィールドを追加:\\n  - `followupLlmMode?: 'auto' | 'openai' | 'claude' | 'off'`\\n  - `followupLlmModel?: string`\\n  - `followupLlmTimeout?: number`\\n  - `followupLlmMaxRetries?: number`\\n  - `followupLlmAppendMetadata?: boolean`\\n- `options-parser.ts` でバリデーション:\\n  - `off` → `enabled` false。\\n  - timeout/retries は正の整数 (0 許容)。\\n  - provider 指定が `openai` なのに OpenAI APIキー不在の場合は警告ログを出して `enabled=false`。\\n- `config.ts` で環境変数ゲッターを追加 (`FOLLOWUP_LLM_MODE`, `FOLLOWUP_LLM_MODEL`, `FOLLOWUP_LLM_TIMEOUT_MS`, `FOLLOWUP_LLM_MAX_RETRIES`, `FOLLOWUP_LLM_APPEND_METADATA`)。\\n- CLI 例:  \\n  `ai-workflow execute --issue 119 --phase evaluation --followup-llm-mode auto --followup-llm-model claude-3-sonnet-20240229`.\\n\\n### 7.8 ロギング・モニタリング\\n\\n- LLM 成功時は DEBUG ログ、再試行数 > 0 の場合は WARN と INFO の両方に出力して追跡可能にする。\\n- フォールバック発生時は WARN ログを構造化文字列 (JSON 互換) で出力。`event=FOLLOWUP_LLM_FALLBACK`, `fallback_mode=legacy_template`, `reason=...`。\\n- `IssueAIGenerator.generate` 内で `performance.now()` を使い処理時間を計測。\\n- ログには機密情報やプロンプト全文を含めない。\\n\\n### 7.9 テスト設計詳細\\n\\n| レイヤ | テストケース | 目的 |\\n| --- | --- | --- |\\n| Unit (`issue-ai-generator.test.ts`) | タスク数制限・文字列トリム・ターゲットファイル上限を検証 | サニタイズ仕様の担保 |\\n|  | JSON 以外の応答で `IssueAIValidationError` を投げる | バリデーション |\\n|  | 必須セクション欠落、タイトル長不正、HTMLタグ混入で失敗する | FR-1/FR-2 |\\n|  | 1回目失敗→2回目成功のリトライ時に最終成功 | リトライ制御 |\\n|  | `SecretMasker` により API キーがプロンプトに残らない | セキュリティ |\\n| Unit (`issue-client.test.ts`) | LLM 成功時に Octokit へ LLM 出力が渡る | フロー検証 |\\n|  | 例外発生時に WARN ログとフォールバックタイトル/本文が使用される | FR-3 |\\n| Integration (`followup-issue-llm.test.ts`) | CLI -> PhaseContext -> GitHubClient -> IssueClient のオプション伝搬 | 設定連携 |\\n|  | LLM が無効化されている場合に既存挙動が維持される | 後方互換 |\\n|  | `FOLLOWUP_LLM_E2E=1` 時のみ実APIを使い、成功時タイトル/本文が要件を満たすか検証 (失敗時はテストをスキップ) | 実API検証 |\\n\\n### 7.10 要件トレーサビリティ\\n\\n| 要件ID | 対応箇所 |\\n| --- | --- |\\n| FR-1 | 7.4 プロンプト設計・タイトル検証、7.5 タイトル採用ロジック |\\n| FR-2 | 7.4 セクション検証、7.5 `buildLegacyBody` との比較で差異を吸収 |\\n| FR-3 | 7.5 `tryGenerateWithLLM` フォールバック制御 |\\n| FR-4 | 7.6 Phase 連携、7.7 CLI/Config 拡張 |\\n| FR-5 | 7.5 ログ出力設計、7.8 モニタリング |\\n\\n### 7.11 ドキュメント更新\\n\\n- `ARCHITECTURE.md`: Evaluation → GitHubClient → IssueAIGenerator → IssueClient のフロー図と説明を追加。\\n- `CLAUDE.md`: Follow-up LLM 設定方法、環境変数、フォールバック観察ポイントを追記。\\n- `README.md`: CLI オプションと `.env` 設定例、フォールバック時のトラブルシューティングを追加。\\n\\n---\\n\\n## 8. セキュリティ考慮事項\\n\\n- `SecretMasker` と追加の簡易正規表現 (API キーフォーマット、メールアドレス) を `sanitizePayload` に適用し、機密情報送信を防止。\\n- LLM 応答に HTML/スクリプトタグが含まれる場合はバリデーションエラーとし、フォールバックへ切り替える。\\n- API キーは `config` ゲッター経由でのみ参照し、ログへ出力しない。\\n- プロンプト・レスポンスをファイルへ書き出さない。ログにはメタデータのみを残す。\\n- 再試行回数を `maxRetries` で制限し、無限ループやコスト過多を防止。\\n\\n---\\n\\n## 9. 非機能要件への対応\\n\\n- **パフォーマンス**: `timeoutMs` と `maxRetries` で最悪ケースでも 25s × 3 = 75s 以内にフォールバック。タスク数・文字数の制限で入力サイズを抑制し、LLM 呼び出し平均 15s 以内を目指す。\\n- **スケーラビリティ**: Provider 抽象化でモデル追加が容易。`maxTasks` で大規模残タスクでも安定して処理。\\n- **保守性**: LLM ロジックを `IssueAIGenerator` に集約し、IssueClient と疎結合化。テストで回帰を検知しやすくする。\\n- **可用性**: LLM 失敗時でも既存テンプレートで確実に Issue を生成 (FR-3)。WARN ログで運用監視が容易。\\n- **コスト管理**: デフォルト無効 (`enabled=false`) で不要な API 呼び出しを防止。`appendMetadata` で生成コストを Issue 上に可視化可能。\\n\\n---\\n\\n## 10. 実装の順序\\n\\n1. **型と設定の整備**: `IssueGenerationOptions`、`PhaseContext`、CLI/Config 拡張。既存コードをコンパイル可能に更新。\\n2. **IssueAIGenerator 実装**: プロンプトテンプレート、サニタイズ、Provider アダプタ、検証、専用エラーを実装。\\n3. **IssueClient / GitHubClient 更新**: 依存注入、LLM 分岐、フォールバックとログ処理を追加。\\n4. **Phase / CLI 連携**: EvaluationPhase がオプションを渡すよう調整し、実行時の設定反映を確認。\\n5. **テスト追加・更新**: 新規ユニットテスト、既存テスト更新、統合テストでオプション伝搬とフォールバックを検証。\\n6. **ドキュメント更新**: ARCHITECTURE / CLAUDE / README / `.env.example` を更新。\\n7. **検証**: `npm run test:unit`, `npm run test:integration` 実行。必要に応じ `FOLLOWUP_LLM_E2E=1` で手動統合テストを確認。\\n\\n---\\n\\n## 11. 品質ゲート確認\\n\\n- 実装戦略 (EXTEND) の判断根拠を明記。\\n- テスト戦略 (UNIT_INTEGRATION) の判断根拠を明記。\\n- 既存コードへの影響と依存関係を分析。\\n- 変更・追加ファイルを列挙。\\n- 詳細設計と要件トレーサビリティを提示し実装可能性を保証。\\n\\n\",\"exit_code\":0,\"status\":\"completed\"}}\n.ai-workflow/issue-119/02_design/review/agent_log_raw.txt:16:{\"type\":\"item.completed\",\"item\":{\"id\":\"item_6\",\"type\":\"command_execution\",\"command\":\"bash -lc \\\"sed -n '1,160p' .ai-workflow/issue-119/02_design/output/design.md\\\"\",\"aggregated_output\":\"# 詳細設計書 - Issue #119 フォローアップIssue生成品質の改善（LLM活用）\\n\\n**Issue番号**: #119  \\n**タイトル**: フォローアップIssue生成品質の改善（LLM活用）  \\n**バージョン**: 1.1 (Design)\\n\\n---\\n\\n## 1. アーキテクチャ設計\\n\\n### 1.1 システム全体フロー\\n\\n```\\nEvaluationPhase (Phase 9)\\n    │ RemainingTask[], IssueContext, evaluation report path, generation options\\n    ▼\\nGitHubClient.createIssueFromEvaluation(...)\\n    │ delegates\\n    ▼\\nIssueClient (LLM-aware)\\n    ├─ IssueAIGenerator.generate(...)\\n    │     └─ LLM Provider Adapter (OpenAI / Anthropic)\\n    └─ Legacy builders (generateFollowUpTitle + buildLegacyBody)\\n    ▼\\nOctokit.issues.create(...) → GitHub Issue\\n```\\n\\n### 1.2 コンポーネント責務\\n\\n| コンポーネント | 役割 | 主な入出力 |\\n| --- | --- | --- |\\n| `EvaluationPhase` | Phase 9 の処理。残タスク検出後に GitHubClient へフォローアップ生成を依頼 | 入力: Evaluation結果 / 出力: IssueGenerationOptions 付き呼び出し |\\n| `GitHubClient` | GitHub API ファサード。IssueClient へ委譲し設定を束ねる | 入力: issue番号, tasks, options / 出力: IssueCreationResult |\\n| `IssueClient` | フォローアップIssue生成の集約。LLM生成→フォールバック制御→Octokit呼び出し | 入力: tasks, context, options / 出力: タイトル・本文・ログ |\\n| `IssueAIGenerator` (新規) | LLMプロンプト生成、API呼び出し、レスポンス検証 | 入力: tasks, context, options / 出力: { title, body, metadata } |\\n| `LlmProviderAdapter` (OpenAI / Anthropic) | 各APIのラッパー。タイムアウト・再試行を実装 | 入出力: prompt, call options, completion JSON |\\n| `config` / CLI | 環境変数・CLIから LLM 設定を収集し PhaseContextへ渡す | 入出力: Follow-up LLM 設定値 |\\n| `SecretMasker` (既存) | 機密情報のマスキング | 入力: プロンプトPayload / 出力: SanitizedPayload |\\n\\n### 1.3 データフロー\\n\\n1. ユーザーが `ai-workflow execute ...` を実行し、CLI が Follow-up LLM オプションを解析 (デフォルトは無効)。\\n2. `commands/execute` が `PhaseContext.issueGenerationOptions` を組み立て、`PhaseFactory` 経由で `EvaluationPhase` へ受け渡す。\\n3. EvaluationPhase で残タスクが存在すると `GitHubClient.createIssueFromEvaluation(issueNumber, tasks, reportPath, context, options)` を呼び出す。\\n4. `GitHubClient` は `IssueAIGenerator` をコンストラクタインジェクション済みの `IssueClient` に委譲。\\n5. `IssueClient` が `options.enabled` と `IssueAIGenerator.isAvailable()` を確認し、利用可能なら `generate(tasks, context, options)` を試行。\\n6. `IssueAIGenerator` は payload をサニタイズ→プロンプト生成→LLM呼び出し→検証し、成功時にタイトル・本文を返却。\\n7. LLM 失敗または無効時、`IssueClient` は既存の `generateFollowUpTitle` と新設の `buildLegacyBody` でフォールバック本文を生成。\\n8. 生成結果と `## 参考` セクション (＋オプションで LLM metadata) を結合し、Octokit で Issue を作成。ログへ成否とメタ情報を出力。\\n\\n### 1.4 主なシーケンスと失敗時動作\\n\\n- LLM 成功: `IssueAIGenerator` → validated result → `IssueClient` が LLM 出力を採用 → `options.appendMetadata` が true の場合にメタデータ節を付加。\\n- LLM タイムアウト / レート制限: Providerアダプタが指数バックオフで再試行。全失敗で `IssueAIError` を返し IssueClient が WARN を記録しフォールバック。\\n- プロンプト検証失敗: `IssueAIGenerator` が `IssueAIValidationError` を送出し、同様にフォールバック。\\n- Octokit 失敗: 既存処理と同様に ERROR ログを出力し `IssueCreationResult` で失敗を返却。\\n\\n---\\n\\n## 2. 実装戦略判断: EXTEND\\n\\n**判断根拠**:\\n- 既存 `IssueClient` / `GitHubClient` / CLI フローを維持したまま責務を拡張する必要があるため。\\n- フォールバックとして既存テンプレートを保持しつつ LLM 生成を追加する形で後方互換を守る。\\n- Planning Document の戦略 (新規モジュール追加 + 既存コード拡張) と整合。\\n\\n---\\n\\n## 3. テスト戦略判断: UNIT_INTEGRATION\\n\\n**判断根拠**:\\n- プロンプト生成・レスポンス検証・リトライといったロジックはモック化が容易であり、ユニットテストで網羅できる。\\n- GitHub 連携や Phase からのオプション伝搬、フォールバック全体の動作は統合テストで確認する必要がある。\\n\\n---\\n\\n## 4. テストコード戦略判断: BOTH_TEST\\n\\n**判断根拠**:\\n- 既存 `issue-client` テストに LLM 成功/失敗パスを追加する必要がある (既存テストの拡張)。\\n- `IssueAIGenerator` 用の専用ユニットテストが新規に必要となる (新規テスト作成)。\\n\\n---\\n\\n## 5. 影響範囲分析\\n\\n### 5.1 既存コードへの影響\\n- `src/core/github/issue-client.ts`: 依存注入、LLM 分岐、本文生成をメソッド化、WARN/DEBUG ログ拡張。\\n- `src/core/github-client.ts`: `IssueAIGenerator` の初期化と委譲。`createIssueFromEvaluation` にオプションパラメータ追加。\\n- `src/phases/evaluation.ts`: `GitHubClient.createIssueFromEvaluation` 呼び出しに LLM オプションを渡す。\\n- `src/commands/execute.ts` / `src/commands/execute/options-parser.ts`: CLI オプション解析に Follow-up LLM 設定を追加し `PhaseContext` へ渡す。\\n- `src/types.ts`: `IssueGenerationOptions` や LLM 結果の型を追加。\\n- `src/types/commands.ts`: `PhaseContext` に `issueGenerationOptions` プロパティを追加。\\n- `src/core/config.ts`: LLM 設定用ゲッターを実装。\\n- 既存テスト (`tests/unit/github/issue-client*.ts`, `tests/integration/github-client-facade.test.ts`) を LLM 統合ケースで更新。\\n\\n### 5.2 依存関係の変更\\n- 追加パッケージは想定なし。既存 `openai`, `@anthropic-ai/claude-agent-sdk` を再利用。\\n- Jest モックは既存 `jest-mock-extended` や手動モックを活用。\\n\\n### 5.3 マイグレーション要否\\n- データマイグレーションは不要。\\n- `.env.example` が存在する場合は Follow-up LLM 用環境変数を追加。\\n- `ARCHITECTURE.md`, `CLAUDE.md`, `README.md` を更新して設定手順とフォールバック説明を追記。\\n\\n---\\n\\n## 6. 変更・追加ファイルリスト\\n\\n- **新規作成**\\n  - `src/core/github/issue-ai-generator.ts`\\n  - `tests/unit/github/issue-ai-generator.test.ts`\\n  - `tests/integration/followup-issue-llm.test.ts` (Octokit モック中心)\\n- **既存修正**\\n  - `src/core/github/issue-client.ts`\\n  - `src/core/github-client.ts`\\n  - `src/phases/evaluation.ts`\\n  - `src/commands/execute.ts`\\n  - `src/commands/execute/options-parser.ts`\\n  - `src/types.ts`\\n  - `src/types/commands.ts`\\n  - `src/core/config.ts`\\n  - `tests/unit/github/issue-client.test.ts`\\n  - `tests/unit/github/issue-client-followup.test.ts`\\n  - `tests/integration/github-client-facade.test.ts`\\n  - ドキュメント (`ARCHITECTURE.md`, `CLAUDE.md`, `README.md`, `.env.example`)\\n- **削除予定**: なし\\n\\n---\\n\\n## 7. 詳細設計\\n\\n### 7.1 IssueGenerationOptions / IssueAIGenerationResult\\n\\n```ts\\nexport interface IssueGenerationOptions {\\n  enabled: boolean;\\n  provider: 'auto' | 'openai' | 'claude';\\n  model?: string;\\n  temperature?: number;          // default 0.2\\n  maxOutputTokens?: number;      // default 1500\\n  timeoutMs?: number;            // default 25000\\n  maxRetries?: number;           // default 3\\n  maxTasks?: number;             // default 5\\n  appendMetadata?: boolean;      // default false\\n}\\n\\nexport interface IssueAIGenerationResult {\\n  title: string;\\n  body: string;\\n  metadata: {\\n    provider: 'openai' | 'claude';\\n    model: string;\\n    durationMs: number;\\n    retryCount: number;\\n    inputTokens?: number;\\n    outputTokens?: number;\\n    omittedTasks?: number;\\n  };\\n}\\n\",\"exit_code\":0,\"status\":\"completed\"}}\n.ai-workflow/issue-119/02_design/review/agent_log_raw.txt:18:{\"type\":\"item.completed\",\"item\":{\"id\":\"item_7\",\"type\":\"command_execution\",\"command\":\"bash -lc \\\"sed -n '161,320p' .ai-workflow/issue-119/02_design/output/design.md\\\"\",\"aggregated_output\":\"```\\n\\n- `config` でデフォルトを構築し、CLI/環境変数で上書き可能にする。\\n- `PhaseContext` に `issueGenerationOptions` を追加し、省略時は `{ enabled: false, provider: 'auto' }` を適用。\\n\\n### 7.2 IssueAIGenerator クラス (新規)\\n\\n- コンストラクタ: `(providers: Record<'openai' | 'claude', LlmProviderAdapter>, secretMasker = new SecretMasker())`。\\n- 補助的なエラー型:\\n  - `IssueAIUnavailableError` (credentials 不足など)\\n  - `IssueAIValidationError` (出力検証失敗)\\n- 公開メソッド:\\n  - `isAvailable(options: IssueGenerationOptions): boolean`  \\n    - `options.enabled` が true かつ選択された provider（`auto` の場合は利用可能なもの）が `hasCredentials()` を満たす。\\n  - `generate(tasks, context, issueNumber, options): Promise<IssueAIGenerationResult>`  \\n    1. `sanitizePayload(tasks, context, options.maxTasks ?? 5)`  \\n       - `RemainingTask` を優先度順 (High→Medium→Low) に並べ、上位 `maxTasks` を採用。超過分は `omittedTasks` としてメタに記録。  \\n       - 各文字列フィールドは 512 文字にトリム。`targetFiles` は 10 件、`steps` / `acceptanceCriteria` は各 8 件まで。  \\n       - `SecretMasker.maskObject` で既知のシークレット値・トークン・メールアドレスを `[REDACTED_x]` に置換。\\n    2. `buildPrompt(issueNumber, sanitizedPayload, context, options)`  \\n       - JSON 文字列化し、テンプレートへ埋め込む。\\n    3. `invokeProvider(prompt, options)`  \\n       - 選択された provider の `complete()` を呼び出す。  \\n       - レート制限時は指数バックオフ (2000ms, 4000ms, 8000ms) とし、回数は `options.maxRetries`。\\n    4. `parseAndValidate(responseText)`  \\n       - JSON パース → タイトル長 50〜80 文字 → 必須セクションを順番に確認 → `実行内容` セクションが番号付きリスト (`1.` 形式) とテスト手順 (`テスト` or `検証`) を含むか検証 → HTML タグを禁止。  \\n       - 失敗時は `IssueAIValidationError`。\\n    5. 成功時に metadata (provider, model, duration, retryCount, input/output tokens, omittedTasks) 付きで返却。\\n\\n### 7.3 LlmProviderAdapter\\n\\n```ts\\ninterface LlmProviderAdapter {\\n  name: 'openai' | 'claude';\\n  hasCredentials(): boolean;\\n  complete(prompt: string, options: IssueGenerationOptions): Promise<LlmProviderResponse>;\\n}\\n\\ninterface LlmProviderResponse {\\n  text: string;\\n  inputTokens?: number;\\n  outputTokens?: number;\\n  retryCount: number;\\n  durationMs: number;\\n}\\n```\\n\\n- **OpenAIAdapter**\\n  - `openai.chat.completions.create()` を呼び出し、`response_format: { type: 'json_object' }` を指定。\\n  - `AbortController` で `timeoutMs` を強制。\\n  - HTTP 429/5xx 時は指数バックオフで再試行。最終的に失敗ならエラーをスロー。\\n- **AnthropicAdapter**\\n  - `@anthropic-ai/claude-agent-sdk` の `messages.create()` を利用。\\n  - `options.model` が無ければ `claude-3-sonnet-20240229` を使用。\\n  - 応答の `content` を結合し JSON テキストを取得。\\n- `provider: 'auto'` の場合は OpenAI キーが存在すれば OpenAIAdapter、それ以外は ClaudeAdapter を選択。\\n\\n### 7.4 プロンプト生成とバリデーション\\n\\nテンプレート例 (コード内定数として保持):\\n\\n````markdown\\nあなたはソフトウェア開発プロジェクトのIssue作成アシスタントです。\\n以下のJSONを読み取り、フォローアップIssueを構築してください。\\n\\n入力:\\n{{payload}}\\n\\n要件:\\n1. タイトルは50〜80文字。対象コンポーネントや目的のキーワードを含めること。\\n2. 本文は以下の見出し順序とします。\\n   ## 背景\\n   ## 目的\\n   ## 実行内容\\n   ## 受け入れ基準\\n   ## 関連リソース\\n3. 実行内容には対象ファイル・手順・テスト方法を含めること。\\n4. JSON 形式で回答してください。\\n\\n出力形式:\\n{\\n  \\\"title\\\": \\\"...\\\",\\n  \\\"body\\\": \\\"...\\\"\\n}\\n````\\n\\n- `parseAndValidate` 検証ルール:\\n  - JSON パース失敗 → `IssueAIValidationError`。\\n  - タイトル文字数 (全角半角問わず) が 50 未満または 80 超過で失敗。\\n  - 本文に必須5セクションが順番に存在するか正規表現で確認。\\n  - `## 実行内容` 内に番号付きリスト (`^\\\\d+\\\\. `) があり、いずれかの行に `テスト`/`検証` を含むことを確認。\\n  - HTML/スクリプトタグを検出したら失敗。\\n  - 余分な末尾空行は `trimEnd()` で整理。\\n\\n### 7.5 IssueClient 拡張\\n\\n- コンストラクタに `IssueAIGenerator | null` を追加 (`new IssueClient(octokit, owner, repo, issueAIGenerator)`).\\n- 新規ヘルパー:\\n  - `private buildLegacyBody(...)`: 現行ロジックを抽出し、フォールバック時に再利用。\\n  - `private appendMetadata(body, metadata, options)`: `options.appendMetadata` が true の場合に以下を追加。\\n    ```\\n    ## 生成メタデータ\\n    - モデル: ${metadata.model} (${metadata.provider})\\n    - 所要時間: ${metadata.durationMs}ms / 再試行: ${metadata.retryCount}\\n    - トークン: in ${metadata.inputTokens ?? '-'} / out ${metadata.outputTokens ?? '-'}\\n    - 省略したタスク数: ${metadata.omittedTasks ?? 0}\\n    ```\\n  - `private async tryGenerateWithLLM(...)`: LLM が利用可能か判定し、失敗時は WARN ログで理由を記録して `null` を返す。\\n- `createIssueFromEvaluation` の流れ:\\n  1. `const aiResult = await this.tryGenerateWithLLM(...);`\\n  2. `const title = aiResult?.title ?? this.generateFollowUpTitle(...);`\\n  3. `const baseBody = aiResult?.body ?? this.buildLegacyBody(...);`\\n  4. `const body = aiResult ? this.appendMetadata(baseBody, aiResult.metadata, options) : baseBody;`\\n  5. 既存どおり Octokit で Issue を作成。\\n- ログ出力:\\n  - 成功 (`logger.debug`): `FOLLOWUP_LLM_SUCCESS { provider, model, durationMs, retryCount }`\\n  - フォールバック (`logger.warn`): `FOLLOWUP_LLM_FALLBACK { reason, fallback: 'legacy_template' }`\\n  - ログにはプロンプト本文を含めない。\\n\\n### 7.6 GitHubClient / Phase 連携\\n\\n- `GitHubClient` コンストラクタで `IssueAIGenerator` を生成し `IssueClient` に渡す。\\n- `createIssueFromEvaluation` の署名を `(..., issueContext?: IssueContext, options?: IssueGenerationOptions)` に拡張。`options` が無い場合は `config` から取得する。\\n- `EvaluationPhase`:\\n  ```ts\\n  const options = this.context.issueGenerationOptions ?? { enabled: false, provider: 'auto' };\\n  const result = await this.github.createIssueFromEvaluation(\\n    issueNumber,\\n    remainingTasks,\\n    relativeReportPath,\\n    issueContext,\\n    options,\\n  );\\n  ```\\n- `PhaseFactory` / `BasePhase` で `PhaseContext.issueGenerationOptions` を新たに受け渡す。\\n\\n### 7.7 CLI / Config 拡張\\n\\n- `ExecuteCommandOptions` に以下フィールドを追加:\\n  - `followupLlmMode?: 'auto' | 'openai' | 'claude' | 'off'`\\n  - `followupLlmModel?: string`\\n  - `followupLlmTimeout?: number`\\n  - `followupLlmMaxRetries?: number`\\n  - `followupLlmAppendMetadata?: boolean`\\n- `options-parser.ts` でバリデーション:\\n  - `off` → `enabled` false。\\n  - timeout/retries は正の整数 (0 許容)。\\n  - provider 指定が `openai` なのに OpenAI APIキー不在の場合は警告ログを出して `enabled=false`。\\n- `config.ts` で環境変数ゲッターを追加 (`FOLLOWUP_LLM_MODE`, `FOLLOWUP_LLM_MODEL`, `FOLLOWUP_LLM_TIMEOUT_MS`, `FOLLOWUP_LLM_MAX_RETRIES`, `FOLLOWUP_LLM_APPEND_METADATA`)。\\n- CLI 例:  \\n  `ai-workflow execute --issue 119 --phase evaluation --followup-llm-mode auto --followup-llm-model claude-3-sonnet-20240229`.\\n\\n### 7.8 ロギング・モニタリング\\n\\n- LLM 成功時は DEBUG ログ、再試行数 > 0 の場合は WARN と INFO の両方に出力して追跡可能にする。\\n- フォールバック発生時は WARN ログを構造化文字列 (JSON 互換) で出力。`event=FOLLOWUP_LLM_FALLBACK`, `fallback_mode=legacy_template`, `reason=...`。\\n- `IssueAIGenerator.generate` 内で `performance.now()` を使い処理時間を計測。\\n- ログには機密情報やプロンプト全文を含めない。\\n\\n### 7.9 テスト設計詳細\\n\",\"exit_code\":0,\"status\":\"completed\"}}\n.ai-workflow/issue-119/02_design/review/agent_log_raw.txt:82:{\"type\":\"item.completed\",\"item\":{\"id\":\"item_38\",\"type\":\"agent_message\",\"text\":\"## 品質ゲート評価\\n\\n- [x] **実装戦略の判断根拠が明記されている**: **PASS** - EXTEND を選んだ理由が既存フロー維持とフォールバック確保の観点で整理されています（design.md:60）。\\n- [x] **テスト戦略の判断根拠が明記されている**: **PASS** - ユニット／統合それぞれの役割分担が明確です（design.md:69）。\\n- [x] **既存コードへの影響範囲が分析されている**: **PASS** - 影響ファイルと依存関係の整理が網羅的です（design.md:85）。\\n- [ ] **変更が必要なファイルがリストアップされている**: **FAIL** - LLM入力をマスクするために必須となる `SecretMasker` の拡張が設計に記載されている一方、変更ファイル一覧に `src/core/secret-masker.ts` が含まれていません（design.md:108, design.md:179, src/core/secret-masker.ts:24）。\\n- [ ] **設計が実装可能である**: **FAIL** - 設計が依存する `SecretMasker.maskObject` が現行コードに存在せず、追加方法も定義されていないため、このままでは実装できません（design.md:179, src/core/secret-masker.ts:24）。\\n\\n**品質ゲート総合判定: FAIL**\\n\\n## 詳細レビュー\\n\\n### 1. 戦略判断の妥当性\\n**良好な点**: EXTEND 戦略で既存フローを保護しつつ LLM を組み込む方針が要件と整合しています（design.md:60）。  \\n**懸念点**: 特になし。\\n\\n### 2. 影響範囲分析の適切性\\n**良好な点**: 主要モジュールと依存設定の更新が整理されており、想定範囲が把握できます（design.md:85）。  \\n**懸念点**: `PhaseContext` を拡張すると明記しているものの、`PhaseFactory` や `BasePhase` など伝搬に必要なファイルが変更リストに含まれていません（design.md:85, design.md:108）。\\n\\n### 3. ファイルリストの完全性\\n**良好な点**: 新規モジュールと主要既存ファイルの更新予定が列挙されています（design.md:108）。  \\n**懸念点**: LLM入力をマスクするための `SecretMasker` 変更が漏れており、必要作業が反映されていません（design.md:179, src/core/secret-masker.ts:24）。\\n\\n### 4. 設計の実装可能性\\n**良好な点**: LLM応答の検証やフォールバック手順が段階的に整理されています（design.md:176）。  \\n**懸念点**: `SecretMasker.maskObject` を利用する前提ですが、現行クラスには該当メソッドが存在せず実装方法も未定義で、設計通りに実装できません（design.md:179, src/core/secret-masker.ts:24）。\\n\\n### 5. 要件との対応\\n**良好な点**: 要件トレーサビリティ表で各機能要件への対応が紐付けられています（design.md:210）。  \\n**懸念点**: 特になし。\\n\\n### 6. セキュリティ考慮\\n**良好な点**: 機密情報マスキングやHTML拒否などの対策が記載されています（design.md:176, design.md:218）。  \\n**改善の余地**: 実際にマスキングを担う `SecretMasker` へどのような拡張を行うか明文化すると、実装者が迷いません。\\n\\n### 7. 非機能要件への対応\\n**良好な点**: タイムアウトとリトライの上限設計、コスト配慮などが示されています（design.md:240）。  \\n**改善の余地**: 特になし。\\n\\n## ブロッカー（BLOCKER）\\n\\n1. **SecretMasker 拡張の欠落**\\n   - 問題: `IssueAIGenerator` が `SecretMasker.maskObject` を利用するとしているが、そのメソッドは現行クラスに存在せず、どこで追加するかも設計に含まれていません（design.md:179, src/core/secret-masker.ts:24）。\\n   - 影響: マスキング処理が実装できず、設計通りにLLMへ安全な入力を渡せません。\\n   - 対策: `SecretMasker` にオブジェクトマスキング機能を追加する設計（メソッド仕様・置換ロジック・テスト方針）を明記し、変更ファイルリストにも `src/core/secret-masker.ts` を加えてください。\\n\\n## 改善提案（SUGGESTION）\\n\\n1. **PhaseContext 伝搬ファイルの明示**\\n   - 現状: `PhaseContext.issueGenerationOptions` を追加すると記載されていますが、`PhaseFactory` や `BasePhase` などで値を渡す作業が変更一覧に載っていません（design.md:85, design.md:108）。\\n   - 提案: どのファイルでコンテキストを保持・参照するかを具体的に列挙し、変更リストにも追記すると実装計画の抜け漏れ防止につながります。\\n   - 効果: 設計と作業計画の整合性が上がり、実装時の見落としを減らせます。\\n\\n## 総合評価\\n\\n**主な強み**:\\n- EXTEND 戦略とテスト方針が要件と一致し、フォールバック設計も整っています（design.md:60, design.md:69）。\\n- LLM出力の検証手順やメタデータ付与など、実務利用を意識した詳細設計が充実しています（design.md:176, design.md:205）。\\n\\n**主な改善提案**:\\n- `SecretMasker` のオブジェクトマスキング仕様を明示し、変更ファイルリストを補完してください（design.md:179, src/core/secret-masker.ts:24）。\\n- `PhaseContext` 伝搬に関わる基盤ファイルを変更対象として追記することで、実装計画の抜け漏れを防ぐと安心です（design.md:85, design.md:108）。\\n\\n`SecretMasker` への依存ギャップが解消されれば、実装に進む準備が整った設計になると思います。まずはマスキング機構の設計補強と変更リストの更新をご検討ください。\\n\\n---\\n判定: FAIL\"}}\n.ai-workflow/issue-119/02_design/output/design.md:43:2. `commands/execute` が `PhaseContext.issueGenerationOptions` を組み立て、`PhaseFactory` 経由で `EvaluationPhase` へ受け渡す。\n.ai-workflow/issue-119/02_design/output/design.md:295:- `PhaseFactory` / `BasePhase` で `PhaseContext.issueGenerationOptions` を新たに受け渡す。\n.ai-workflow/issue-119/02_design/execute/agent_log_raw.txt:42:{\"type\":\"item.completed\",\"item\":{\"id\":\"item_19\",\"type\":\"command_execution\",\"command\":\"bash -lc 'cat .ai-workflow/issue-119/02_design/output/design.md'\",\"aggregated_output\":\"# 詳細設計書 - Issue #119 フォローアップIssue生成品質の改善（LLM活用）\\n\\n**Issue番号**: #119  \\n**タイトル**: フォローアップIssue生成品質の改善（LLM活用）  \\n**バージョン**: 1.0 (Draft)\\n\\n---\\n\\n## 1. アーキテクチャ設計\\n\\n### 1.1 システム全体図\\n\\n```\\nEvaluation Phase (PhaseRunner)\\n        │ RemainingTask[], IssueContext, Report Path\\n        ▼\\nGitHubClient.createIssueFromEvaluation(issueNumber, tasks, report, context, options)\\n        │\\n        ▼\\nIssueClient (LLM-aware)\\n   ├─ tryGenerateWithLLM(...)\\n   │     │ sanitized prompt payload\\n   │     ▼\\n   │  IssueAIGenerator\\n   │     ├─ buildPrompt()\\n   │     ├─ invokeProvider(OpenAI | Anthropic)\\n   │     └─ validateAndNormalize()\\n   │            │\\n   │            └─ JSON(title, body)\\n   └─ fallbackToLegacyBuilders()  ← LLM disabled/エラー時\\n        │\\n        ▼\\nOctokit.issues.create(...)  → GitHub Issue\\n```\\n\\n### 1.2 コンポーネント責務と関係\\n\\n| コンポーネント | 役割 | 入出力・備考 |\\n| --- | --- | --- |\\n| `EvaluationPhase` | Phase 9 実装。残タスク発見時に Issue 作成を依頼 | `GitHubClient.createIssueFromEvaluation` 呼び出し |\\n| `GitHubClient` | GitHub 操作ファサード | `IssueClient` へ委譲しつつ LLM オプションを引き渡す |\\n| `IssueClient` | フォローアップ Issue 生成の中心 | 既存組版ロジックを保持しつつ、LLM 優先フローとフォールバック制御を担当 |\\n| `IssueAIGenerator` (**新規**) | プロンプト生成・LLM呼び出し・レスポンス検証を集約 | OpenAI / Claude どちらにも対応するアダプタを組み込み |\\n| `OpenAILLMAdapter` / `ClaudeLLMAdapter` (**新規サブモジュール**) | 各プロバイダの API 呼び出しを抽象化 | 公式 SDK (`openai`, `@anthropic-ai/sdk`) を利用 |\\n| `SecretMasker` （既存） | プロンプトへの機密情報流出防止 | IssueAIGenerator 内で再利用 |\\n| `Octokit` | GitHub REST API クライアント | 最終的な Issue 作成を実行 |\\n\\n### 1.3 データフロー\\n\\n1. Evaluation Phase が `RemainingTask[]`, `IssueContext`, `evaluationReportPath` を構築し、`IssueGenerationOptions` を併せて `GitHubClient` に渡す。\\n2. `GitHubClient` はパラメータを `IssueClient.createIssueFromEvaluation` に委譲。\\n3. `IssueClient` は LLM が有効 (`options.enabled === true`) かつ `IssueAIGenerator` が利用可能な場合、`tryGenerateWithLLM()` を呼び出す。\\n4. `IssueAIGenerator` は以下を順に処理:\\n   - `sanitizeContext()` でタスクを最大5件に絞り、各フィールドを 512 文字にトリムしつつ、`SecretMasker` で機密値を除去。\\n   - `buildPrompt()` で要件定義書記載のテンプレートを埋め込み、モデルへ渡す JSON 指示を生成。\\n   - `invokeProvider()` で OpenAI もしくは Claude API を呼び出し、指数バックオフ付きリトライを適用。\\n   - `validateResponse()` で JSON 形式・必須セクション・タイトル長(50-80文字)を検証。\\n5. LLM 生成に成功した場合、`IssueClient` は生成タイトル/本文を採用し、Octokit へ送信。失敗や無効時は既存 `generateFollowUpTitle` / `formatTaskDetails` と同等のフォールバックを使用。\\n6. 成否情報は LOGGER に WARN/INFO で記録され、呼び出し元へ `IssueCreationResult` として返却される。\\n\\n### 1.4 プロンプト・レスポンス設計\\n\\n- プロンプトは Markdown ではなく JSON 指示テキストを生成し、LLM に `{ \\\"title\\\": \\\"...\\\", \\\"body\\\": \\\"...\\\" }` 形式で応答させる。\\n- 本文は `## 背景`, `## 目的`, `## 実行内容`, `## 受け入れ基準`, `## 関連リソース` の順序を必須とし、`validateResponse()` でセクション存在を確認。\\n- タイトルは 50〜80 文字制約。検証時に不足/超過があればフォールバック。\\n- レスポンスは Markdown のみ許容。HTML タグやコードフェンス内の命令文は検出して除外。\\n\\n---\\n\\n## 2. 実装戦略判断\\n\\n### 実装戦略: EXTEND\\n\\n**判断根拠**:\\n- 既存 `IssueClient` に LLM 優先の分岐を追加し、既存タイトル/本文組版ロジックを変更せずにフォールバックとして残すため。\\n- `GitHubClient`, `EvaluationPhase`, CLI オプションなど既存フローとの統合が必要で、新規モジュール追加に加えて既存コードの拡張が中心となるため。\\n- 既存テストスイート (`issue-client` ユニット/インテグレーション) を拡張し互換性を担保する計画であり、大規模なリファクタではないため。\\n\\n---\\n\\n## 3. テスト戦略判断\\n\\n### テスト戦略: UNIT_INTEGRATION\\n\\n**判断根拠**:\\n- LLM プロンプト生成・レスポンス検証・リトライ制御など純粋ロジックはモックで十分かつユニットテストで網羅可能。\\n- `IssueClient` との統合作用（LLM成功/失敗・フォールバック・Octokit呼び出し）は依存注入を用いたインテグレーションテストで回帰防止が必要。\\n- 実 API 呼び出しはオプトイン統合テスト（環境変数によるスキップ制御）で品質確認する計画のため、ユニットとインテグレーション双方が不可欠。\\n\\n---\\n\\n## 4. テストコード戦略判断\\n\\n### テストコード戦略: BOTH_TEST\\n\\n**判断根拠**:\\n- 既存 `tests/unit/github/issue-client(-followup).test.ts` に LLM フォールバックの追加ケースを組み込む必要がある（既存拡張）。\\n- `IssueAIGenerator` 専用のユニットテストファイルを新規作成し、プロンプト/バリデーション/リトライ挙動を検証する必要がある（新規作成）。\\n\\n---\\n\\n## 5. 影響範囲分析\\n\\n- **コード**: `src/core/github/issue-client.ts`, `src/core/github-client.ts`, `src/phases/evaluation.ts`, `src/commands/execute.ts`, `src/commands/execute/options-parser.ts`, `src/types.ts`, `src/types/commands.ts` が主対象。  \\n- **新規モジュール**: `src/core/github/issue-ai-generator.ts`（およびサブアダプタ/ユーティリティ）、`src/prompts/follow_up_issue/*.md`。  \\n- **依存関係**: Anthropic 公式 SDK (`@anthropic-ai/sdk`) を追加予定。既存 `openai` は再利用。  \\n- **設定**: `.env` / 環境変数に LLM 有効化フラグ・モデル指定・タイムアウト設定を追加。`config.ts` にゲッターを実装。  \\n- **ドキュメント**: `ARCHITECTURE.md`, `CLAUDE.md`, `README.md` の LLM セクションを更新。  \\n- **テスト**: ユニット・インテグレーションテストの拡張、新規 `tests/integration/followup-issue-llm.test.ts` を追加。  \\n- **マイグレーション要否**: 既存 Issue には影響なし。新しい環境変数はデフォルトで無効 (`enabled = false`) とし、設定が無い場合は従来どおり動作。\\n\\n---\\n\\n## 6. 変更・追加ファイルリスト\\n\\n- **新規作成**\\n  - `src/core/github/issue-ai-generator.ts`\\n  - `src/core/github/llm/base-llm-adapter.ts`\\n  - `src/core/github/llm/openai-adapter.ts`\\n  - `src/core/github/llm/anthropic-adapter.ts`\\n  - `src/prompts/follow_up_issue/title_prompt.md`\\n  - `src/prompts/follow_up_issue/body_prompt.md`\\n  - `tests/unit/github/issue-ai-generator.test.ts`\\n  - `tests/integration/followup-issue-llm.test.ts`\\n- **既存修正**\\n  - `src/core/github/issue-client.ts`\\n  - `src/core/github-client.ts`\\n  - `src/phases/evaluation.ts`\\n  - `src/commands/execute.ts`\\n  - `src/commands/execute/options-parser.ts`\\n  - `src/types.ts`\\n  - `src/types/commands.ts`\\n  - `src/core/config.ts`\\n  - 既存テスト: `tests/unit/github/issue-client.test.ts`, `tests/unit/github/issue-client-followup.test.ts`\\n- **ドキュメント**\\n  - `ARCHITECTURE.md`\\n  - `CLAUDE.md`\\n  - `README.md`（環境変数と使い方）\\n- **削除**: なし\\n\\n---\\n\\n## 7. 詳細設計\\n\\n### 7.1 IssueAIGenerator モジュール（新規）\\n\\n- **クラス構成**\\n  ```mermaid\\n  classDiagram\\n    class IssueAIGenerator {\\n      -options: IssueGenerationOptions\\n      -provider: LLMProviderAdapter\\n      -secretMasker: SecretMasker\\n      -clock: Clock\\n      +generateTitle(task: RemainingTask, ctx: IssueContext, meta: GenerationMeta): Promise<string>\\n      +generateDescription(task: RemainingTask, ctx: IssueContext, meta: GenerationMeta): Promise<string>\\n      +generateIssue(task: RemainingTask, ctx: IssueContext, meta: GenerationMeta): Promise<IssueAiResult>\\n    }\\n    class LLMProviderAdapter {\\n      <<interface>>\\n      +complete(prompt: string, opts: ProviderCallOptions): Promise<string>\\n    }\\n    IssueAIGenerator --> LLMProviderAdapter\\n  ```\\n- **主要責務**\\n  - `sanitizeContext(tasks, context)`：  \\n    - 最大5件の `RemainingTask` を対象。`task`, `steps`, `acceptanceCriteria`, `priorityReason`, `dependencies` は 512 文字にトリム。  \\n    - `targetFiles` は 10 件に制限。  \\n    - `SecretMasker` により既知のシークレット値を `[REDACTED_*]` に置換。  \\n  - `buildPrompt(payload)`：要件定義書のテンプレートを読み込み、`JSON.stringify` で安全に埋め込む。タイトルと本文を同時生成する複合リクエスト（FR-1, FR-2 対応）。\\n  - `invokeProvider(prompt)`：`options.maxRetries`（デフォルト3回）、指数バックオフ（1s, 2s, 4s）で再試行。`AbortController` による `timeoutMs` 制御。\\n  - `validateResponse(raw)`：  \\n    1. JSON 解析。  \\n    2. `title` 文字数チェック (50〜80)。  \\n    3. `body` に必須セクションが全て含まれるか正規表現で検証。  \\n    4. Markdown 以外のタグ検出 (`/<\\\\w+>/`) で拒否。  \\n    5. 失敗時は `IssueAiValidationError` を throw。\\n  - 成功時は `{ title, body, metadata }` を返却。`metadata` には使用モデル・推定トークン数・処理時間等を格納し DEBUG ログで出力。\\n\\n### 7.2 LLM Provider アダプタ\\n\\n- **OpenAIAdapter**\\n  - 既存 `openai` パッケージを利用し `chat.completions.create()` を呼び出す。\\n  - デフォルトモデル: `options.model ?? 'gpt-4o-mini'`。\\n  - `response_format: { type: 'json_object' }` を指定し JSON を強制。\\n- **AnthropicAdapter**\\n  - 公式 SDK `@anthropic-ai/sdk` を追加。`messages.create()` を使用し JSON 出力を指示。\\n  - `model` は `options.model ?? 'claude-3-5-sonnet-latest'`。\\n  - プロンプトは `messages: [{ role: 'user', content: prompt }]` 形式。\\n- **Adapter 選択ロジック**\\n  - `IssueGenerationOptions.provider` が `claude`／`openai`／`auto` を選択。  \\n  - `auto` 時は OpenAI API キーが存在すれば優先、なければ Claude にフォールバック。  \\n  - API キー未設定・どちらも使用不可の場合は `IssueAIGenerator.isAvailable()` が `false` を返却し、IssueClient が即座にフォールバックする。\\n\\n### 7.3 プロンプトテンプレート\\n\\n- `src/prompts/follow_up_issue/title_prompt.md` / `body_prompt.md` を追加し、テンプレート文字列中に `{{original_issue_title}}` 等のプレースホルダを定義。\\n- IssueAIGenerator は `fs.readFileSync` (同期) で初期化時にロードし、ホットリロード不要。\\n- プロンプトには以下を明示:\\n  1. タイトル 50〜80文字。\\n  2. 本文の必須セクション。\\n  3. 各セクションの内容ガイドライン（目的は1文、実行内容は番号付きリストなど）。\\n  4. JSON 形式で回答すること。\\n- テンプレートは Markdown コメント (`<!-- -->`) でヒューマン向け説明を記載しつつ、モデルへの指示はプレーンテキストで記述。\\n\\n### 7.4 IssueClient 拡張\\n\\n- 依存注入: `constructor(octokit, owner, repo, aiGenerator?: IssueAIGenerator)` に変更。`GitHubClient` から `IssueAIGenerator` を渡す。\\n- `createIssueFromEvaluation` 署名を以下に拡張:\\n  ```ts\\n  public async createIssueFromEvaluation(\\n    issueNumber: number,\\n    remainingTasks: RemainingTask[],\\n    evaluationReportPath: string,\\n    issueContext?: IssueContext,\\n    generationOptions?: IssueGenerationOptions,\\n  ): Promise<IssueCreationResult>\\n  ```\\n- 本文生成ロジック:\\n  ```ts\\n  let aiResult: IssueAiResult | null = null;\\n  if (generationOptions?.enabled && this.aiGenerator?.isAvailable()) {\\n    aiResult = await this.tryGenerateWithLLM(...).catch((error) => {\\n      logger.warn(`LLM generation failed: ${encodeWarning(getErrorMessage(error))}`);\\n      return null;\\n    });\\n  }\\n  const title = aiResult?.title ?? this.generateFollowUpTitle(...);\\n  const body = aiResult?.body ?? this.buildLegacyBody(...);\\n  ```\\n- `tryGenerateWithLLM` 内で:\\n  - すべての `RemainingTask` を `IssueAIGenerator.generateIssue` に渡し、レスポンスを適用。\\n  - 生成内容に必須セクションが欠落している場合は LLM 失敗扱いとし、WARN ログに詳細（セクション欠如、タイトル長超過など）を出力。\\n  - 成功時は `## LLM生成メタデータ` を本文末尾（`## 参考` 手前）に追加し、モデル名・生成時刻を記録（要件 FR-5 のログ補助。ユーザーが不要な場合は `options.appendMetadata` で制御）。\\n\\n### 7.5 GitHubClient / CLI / Phase 連携\\n\\n- `GitHubClient` コンストラクタで `IssueAIGenerator` を初期化。`config.ts` から取得した LLM 設定を渡す。\\n- `createIssueFromEvaluation` 引数に `generationOptions` を追加。Phase 側で動的に変更したい場合に備える。\\n- `ExecuteCommandOptions` / `ParsedExecuteOptions` に以下オプション追加:\\n  - `followupLlmMode` (`'auto' | 'openai' | 'claude' | 'off'`, デフォルト `'off'`)\\n  - `followupLlmModel?: string`\\n  - `followupLlmTimeout?: number`\\n  - `followupLlmRetries?: number`\\n- CLI サンプル: `ai-workflow execute --issue 119 --phase evaluation --followup-llm-mode auto`.\\n- `PhaseContext` に `issueGenerationOptions` を追加。`PhaseFactory` と各 Phase のコンストラクタに影響が出ないよう、`BasePhase` にプロパティを追加する。\\n- `EvaluationPhase` では `this.context.issueGenerationOptions` を取得し、`this.github.createIssueFromEvaluation(..., options)` を呼び出す。\\n\\n### 7.6 型・設定拡張\\n\\n- `src/types.ts` に `IssueGenerationOptions` を追加:\\n  ```ts\\n  export interface IssueGenerationOptions {\\n    enabled: boolean;\\n    provider: 'auto' | 'openai' | 'claude';\\n    model?: string;\\n    temperature?: number;\\n    maxTokens?: number;\\n    timeoutMs?: number;\\n    maxRetries?: number;\\n    maxTasks?: number; // プロンプトへ含める残タスク数（デフォルト5）\\n    appendMetadata?: boolean; // 本文末尾にAIメタデータを追記するか\\n  }\\n  ```\\n- `config.ts` へ以下ゲッター追加:\\n  - `getFollowupLlmMode()`, `getFollowupLlmModel()`, `getFollowupLlmTimeoutMs()`, `getFollowupLlmRetries()`, `getFollowupLlmEnabled()`.\\n- 環境変数命名例:\\n  - `FOLLOWUP_LLM_MODE` (`off` / `auto` / `openai` / `claude`)\\n  - `FOLLOWUP_LLM_MODEL`\\n  - `FOLLOWUP_LLM_TIMEOUT_MS`\\n  - `FOLLOWUP_LLM_MAX_RETRIES`\\n  - `FOLLOWUP_LLM_APPEND_METADATA`\\n\\n### 7.7 テスト設計詳細\\n\\n- **ユニットテスト (`tests/unit/github/issue-ai-generator.test.ts`)**\\n  1. `buildPrompt()` がタスク5件超過時に切り詰めること。\\n  2. API 応答が JSON 以外の場合に `ValidationError` を throw。\\n  3. 必須セクション欠落時に失敗すること。\\n  4. タイトル長が 50 未満/80 超過で失敗すること。\\n  5. リトライ設定が機能し、2回目で成功した場合に成功として返ること（モックで制御）。\\n  6. シークレット値が `[REDACTED_*]` に置換されること。\\n- **既存ユニットテスト拡張**\\n  - `issue-client.followup` テストに LLM 成功シナリオを追加（モック `IssueAIGenerator` を注入）。\\n  - LLM 例外時に WARN ログが発生し、既存フォールバックが使われることを検証。\\n- **インテグレーションテスト (`tests/integration/followup-issue-llm.test.ts`)**\\n  - Octokit モック + `IssueAIGenerator` フェイクを用意し、`createIssueFromEvaluation` が最終的に Octokit へ期待値を渡すことを確認。\\n  - 実 API 呼び出しテストは `process.env.FOLLOWUP_LLM_E2E === '1'` の時のみ実行。APIキー未設定時は `it.skip`。\\n\\n### 7.8 ドキュメント更新\\n\\n- `ARCHITECTURE.md`: Evaluation Phase → GitHubClient → IssueAIGenerator フロー図と説��を追加。\\n- `CLAUDE.md`: 新しい環境変数、Claude モデル選択、フォールバック挙動を追記。\\n- `README.md`: CLI オプション、設定例（`.env` テンプレート抜粋）、Troubleshooting（LLM失敗時のログの読み方）を追加。\\n\\n### 7.9 要件トレーサビリティ\\n\\n| 要件ID | 設計対応箇所 |\\n| --- | --- |\\n| FR-1 (タイトル 50-80文字) | 7.1 `validateResponse` で文字数検証、7.4 で LLM タイトル採用 |\\n| FR-2 (本文セクション) | 7.1 `buildPrompt` / `validateResponse` と 7.4 本文構築 |\\n| FR-3 (フォールバック) | 7.4 `tryGenerateWithLLM` → `buildLegacyBody` |\\n| FR-4 (設定反映) | 7.5 CLI/Phase 連携、7.6 `IssueGenerationOptions` |\\n| FR-5 (ログ) | 7.1 メタデータ記録、7.4 WARN/DEBUG ログ設計 |\\n\\n---\\n\\n## 8. セキュリティ考慮事項\\n\\n- プロンプト前処理で `SecretMasker` により環境変数シークレットを除去。ユーザー提供データ内のメール/トークン形式を正規表現で追加検査。\\n- LLM 応答に URL やコマンドが含まれる場合はそのまま Issue へ反映するが、HTML/スクリプトタグは拒否。\\n- ログには API 応答本文を含めず、`encodeWarning` でエラー文字列をエンコード。APIキーは `config` ゲッター経由のみ取得し、再出力しない。\\n- 送信データには評価レポート本文等機密情報を含めない。ファイルパスは `evaluationReportPath` のみで内容は送信しない。\\n- レート制限超過時は再試行後にフォールバックし、無限ループ防止のため maxRetries を強制適用。\\n\\n---\\n\\n## 9. 非機能要件への対応\\n\\n- **パフォーマンス**: タイムアウト (`timeoutMs`, デフォルト 30,000ms) と最大再試行 3 回で最悪 90 秒以内にフォールバック。タスク数制限・文字数トリムでプロンプトサイズを制御。\\n- **スケーラビリティ**: `IssueGenerationOptions.maxTasks` でプロンプト長を制御し、大規模残タスクでも安定。今後プロンプトテンプレート差し替えやモデル追加を `IssueAIGenerator` 内で閉じる設計。\\n- **保守性**: Provider アダプタを分離しテスト可能に。設定値は `config` 経由で集中管理し、ドキュメント更新でオンボーディングを容易にする。\\n- **可用性**: LLM 失敗時でも既存ロジックで必ず Issue 作成できる（FR-3）。WARN ログで原因を追跡可能。\\n\\n---\\n\\n## 10. 実装の順序\\n\\n1. **型・設定整備**: `IssueGenerationOptions` 追加、`config.ts` ゲッター、CLI オプション解析/PhaseContext 拡張を実装。\\n2. **IssueAIGenerator 実装**: プロンプトテンプレート追加、Provider アダプタとサニタイズ・バリデーションロジックを開発。\\n3. **IssueClient / GitHubClient 拡張**: 依存注入、LLM 優先フロー、フォールバック実装、ログ整備。\\n4. **Phase/Evaluation 更新**: `IssueGenerationOptions` を渡すように修正。\\n5. **テスト実装**: 新規/既存テストを追加・更新。API キーが無い環境でも全テストが通るようモック設計。\\n6. **ドキュメント更新**: README / ARCHITECTURE / CLAUDE を更新し、利用手順と環境変数を明記。\\n7. **検証**: `npm run test:unit`, `npm run test:integration` を実行。必要に応じて `FOLLOWUP_LLM_E2E=1` で手動統合テストを実施。\\n\\n---\\n\\n本設計は以下の品質ゲートを満たしています:\\n- 実装戦略・テスト戦略・テストコード戦略の根拠を明記\\n- 既存コードへの影響範囲を分析\\n- 変更ファイルをリストアップ\\n- 実装手順と要件トレーサビリティを提示し、実装可能な設計を提供\\n\",\"exit_code\":0,\"status\":\"completed\"}}\n.ai-workflow/issue-119/02_design/execute/agent_log_raw.txt:44:{\"type\":\"item.completed\",\"item\":{\"id\":\"item_20\",\"type\":\"command_execution\",\"command\":\"bash -lc \\\"node - <<'NODE'\\nconst fs = require('fs');\\nconst lines = fs.readFileSync('.ai-workflow/issue-119/02_design/output/design.md','utf8').split(/\\\\\\\\r?\\\\\\\\n/);\\nfor (let i=0; i<lines.length; i++) {\\n  console.log(String(i+1).padStart(4,' '), lines[i]);\\n}\\nNODE\\\"\",\"aggregated_output\":\"   1 # 詳細設計書 - Issue #119 フォローアップIssue生成品質の改善（LLM活用）\\n   2 \\n   3 **Issue番号**: #119  \\n   4 **タイトル**: フォローアップIssue生成品質の改善（LLM活用）  \\n   5 **バージョン**: 1.0 (Draft)\\n   6 \\n   7 ---\\n   8 \\n   9 ## 1. アーキテクチャ設計\\n  10 \\n  11 ### 1.1 システム全体図\\n  12 \\n  13 ```\\n  14 Evaluation Phase (PhaseRunner)\\n  15         │ RemainingTask[], IssueContext, Report Path\\n  16         ▼\\n  17 GitHubClient.createIssueFromEvaluation(issueNumber, tasks, report, context, options)\\n  18         │\\n  19         ▼\\n  20 IssueClient (LLM-aware)\\n  21    ├─ tryGenerateWithLLM(...)\\n  22    │     │ sanitized prompt payload\\n  23    │     ▼\\n  24    │  IssueAIGenerator\\n  25    │     ├─ buildPrompt()\\n  26    │     ├─ invokeProvider(OpenAI | Anthropic)\\n  27    │     └─ validateAndNormalize()\\n  28    │            │\\n  29    │            └─ JSON(title, body)\\n  30    └─ fallbackToLegacyBuilders()  ← LLM disabled/エラー時\\n  31         │\\n  32         ▼\\n  33 Octokit.issues.create(...)  → GitHub Issue\\n  34 ```\\n  35 \\n  36 ### 1.2 コンポーネント責務と関係\\n  37 \\n  38 | コンポーネント | 役割 | 入出力・備考 |\\n  39 | --- | --- | --- |\\n  40 | `EvaluationPhase` | Phase 9 実装。残タスク発見時に Issue 作成を依頼 | `GitHubClient.createIssueFromEvaluation` 呼び出し |\\n  41 | `GitHubClient` | GitHub 操作ファサード | `IssueClient` へ委譲しつつ LLM オプションを引き渡す |\\n  42 | `IssueClient` | フォローアップ Issue 生成の中心 | 既存組版ロジックを保持しつつ、LLM 優先フローとフォールバック制御を担当 |\\n  43 | `IssueAIGenerator` (**新規**) | プロンプト生成・LLM呼び出し・レスポンス検証を集約 | OpenAI / Claude どちらにも対応するアダプタを組み込み |\\n  44 | `OpenAILLMAdapter` / `ClaudeLLMAdapter` (**新規サブモジュール**) | 各プロバイダの API 呼び出しを抽象化 | 公式 SDK (`openai`, `@anthropic-ai/sdk`) を利用 |\\n  45 | `SecretMasker` （既存） | プロンプトへの機密情報流出防止 | IssueAIGenerator 内で再利用 |\\n  46 | `Octokit` | GitHub REST API クライアント | 最終的な Issue 作成を実行 |\\n  47 \\n  48 ### 1.3 データフロー\\n  49 \\n  50 1. Evaluation Phase が `RemainingTask[]`, `IssueContext`, `evaluationReportPath` を構築し、`IssueGenerationOptions` を併せて `GitHubClient` に渡す。\\n  51 2. `GitHubClient` はパラメータを `IssueClient.createIssueFromEvaluation` に委譲。\\n  52 3. `IssueClient` は LLM が有効 (`options.enabled === true`) かつ `IssueAIGenerator` が利用可能な場合、`tryGenerateWithLLM()` を呼び出す。\\n  53 4. `IssueAIGenerator` は以下を順に処理:\\n  54    - `sanitizeContext()` でタスクを最大5件に絞り、各フィールドを 512 文字にトリムしつつ、`SecretMasker` で機密値を除去。\\n  55    - `buildPrompt()` で要件定義書記載のテンプレートを埋め込み、モデルへ渡す JSON 指示を生成。\\n  56    - `invokeProvider()` で OpenAI もしくは Claude API を呼び出し、指数バックオフ付きリトライを適用。\\n  57    - `validateResponse()` で JSON 形式・必須セクション・タイトル長(50-80文字)を検証。\\n  58 5. LLM 生成に成功した場合、`IssueClient` は生成タイトル/本文を採用し、Octokit へ送信。失敗や無効時は既存 `generateFollowUpTitle` / `formatTaskDetails` と同等のフォールバックを使用。\\n  59 6. 成否情報は LOGGER に WARN/INFO で記録され、呼び出し元へ `IssueCreationResult` として返却される。\\n  60 \\n  61 ### 1.4 プロンプト・レスポンス設計\\n  62 \\n  63 - プロンプトは Markdown ではなく JSON 指示テキストを生成し、LLM に `{ \\\"title\\\": \\\"...\\\", \\\"body\\\": \\\"...\\\" }` 形式で応答させる。\\n  64 - 本文は `## 背景`, `## 目的`, `## 実行内容`, `## 受け入れ基準`, `## 関連リソース` の順序を必須とし、`validateResponse()` でセクション存在を確認。\\n  65 - タイトルは 50〜80 文字制約。検証時に不足/超過があればフォールバック。\\n  66 - レスポンスは Markdown のみ許容。HTML タグやコードフェンス内の命令文は検出して除外。\\n  67 \\n  68 ---\\n  69 \\n  70 ## 2. 実装戦略判断\\n  71 \\n  72 ### 実装戦略: EXTEND\\n  73 \\n  74 **判断根拠**:\\n  75 - 既存 `IssueClient` に LLM 優先の分岐を追加し、既存タイトル/本文組版ロジックを変更せずにフォールバックとして残すため。\\n  76 - `GitHubClient`, `EvaluationPhase`, CLI オプションなど既存フローとの統合が必要で、新規モジュール追加に加えて既存コードの拡張が中心となるため。\\n  77 - 既存テストスイート (`issue-client` ユニット/インテグレーション) を拡張し互換性を担保する計画であり、大規模なリファクタではないため。\\n  78 \\n  79 ---\\n  80 \\n  81 ## 3. テスト戦略判断\\n  82 \\n  83 ### テスト戦略: UNIT_INTEGRATION\\n  84 \\n  85 **判断根拠**:\\n  86 - LLM プロンプト生成・レスポンス検証・リトライ制御など純粋ロジックはモックで十分かつユニットテストで網羅可能。\\n  87 - `IssueClient` との統合作用（LLM成功/失敗・フォールバック・Octokit呼び出し）は依存注入を用いたインテグレーションテストで回帰防止が必要。\\n  88 - 実 API 呼び出しはオプトイン統合テスト（環境変数によるスキップ制御）で品質確認する計画のため、ユニットとインテグレーション双方が不可欠。\\n  89 \\n  90 ---\\n  91 \\n  92 ## 4. テストコード戦略判断\\n  93 \\n  94 ### テストコード戦略: BOTH_TEST\\n  95 \\n  96 **判断根拠**:\\n  97 - 既存 `tests/unit/github/issue-client(-followup).test.ts` に LLM フォールバックの追加ケースを組み込む必要がある（既存拡張）。\\n  98 - `IssueAIGenerator` 専用のユニットテストファイルを新規作成し、プロンプト/バリデーション/リトライ挙動を検証する必要がある（新規作成）。\\n  99 \\n 100 ---\\n 101 \\n 102 ## 5. 影響範囲分析\\n 103 \\n 104 - **コード**: `src/core/github/issue-client.ts`, `src/core/github-client.ts`, `src/phases/evaluation.ts`, `src/commands/execute.ts`, `src/commands/execute/options-parser.ts`, `src/types.ts`, `src/types/commands.ts` が主対象。  \\n 105 - **新規モジュール**: `src/core/github/issue-ai-generator.ts`（およびサブアダプタ/ユーティリティ）、`src/prompts/follow_up_issue/*.md`。  \\n 106 - **依存関係**: Anthropic 公式 SDK (`@anthropic-ai/sdk`) を追加予定。既存 `openai` は再利用。  \\n 107 - **設定**: `.env` / 環境変数に LLM 有効化フラグ・モデル指定・タイムアウト設定を追加。`config.ts` にゲッターを実装。  \\n 108 - **ドキュメント**: `ARCHITECTURE.md`, `CLAUDE.md`, `README.md` の LLM セクションを更新。  \\n 109 - **テスト**: ユニット・インテグレーションテストの拡張、新規 `tests/integration/followup-issue-llm.test.ts` を追加。  \\n 110 - **マイグレーション要否**: 既存 Issue には影響なし。新しい環境変数はデフォルトで無効 (`enabled = false`) とし、設定が無い場合は従来どおり動作。\\n 111 \\n 112 ---\\n 113 \\n 114 ## 6. 変更・追加ファイルリスト\\n 115 \\n 116 - **新規作成**\\n 117   - `src/core/github/issue-ai-generator.ts`\\n 118   - `src/core/github/llm/base-llm-adapter.ts`\\n 119   - `src/core/github/llm/openai-adapter.ts`\\n 120   - `src/core/github/llm/anthropic-adapter.ts`\\n 121   - `src/prompts/follow_up_issue/title_prompt.md`\\n 122   - `src/prompts/follow_up_issue/body_prompt.md`\\n 123   - `tests/unit/github/issue-ai-generator.test.ts`\\n 124   - `tests/integration/followup-issue-llm.test.ts`\\n 125 - **既存修正**\\n 126   - `src/core/github/issue-client.ts`\\n 127   - `src/core/github-client.ts`\\n 128   - `src/phases/evaluation.ts`\\n 129   - `src/commands/execute.ts`\\n 130   - `src/commands/execute/options-parser.ts`\\n 131   - `src/types.ts`\\n 132   - `src/types/commands.ts`\\n 133   - `src/core/config.ts`\\n 134   - 既存テスト: `tests/unit/github/issue-client.test.ts`, `tests/unit/github/issue-client-followup.test.ts`\\n 135 - **ドキュメント**\\n 136   - `ARCHITECTURE.md`\\n 137   - `CLAUDE.md`\\n 138   - `README.md`（環境変数と使い方）\\n 139 - **削除**: なし\\n 140 \\n 141 ---\\n 142 \\n 143 ## 7. 詳細設計\\n 144 \\n 145 ### 7.1 IssueAIGenerator モジュール（新規）\\n 146 \\n 147 - **クラス構成**\\n 148   ```mermaid\\n 149   classDiagram\\n 150     class IssueAIGenerator {\\n 151       -options: IssueGenerationOptions\\n 152       -provider: LLMProviderAdapter\\n 153       -secretMasker: SecretMasker\\n 154       -clock: Clock\\n 155       +generateTitle(task: RemainingTask, ctx: IssueContext, meta: GenerationMeta): Promise<string>\\n 156       +generateDescription(task: RemainingTask, ctx: IssueContext, meta: GenerationMeta): Promise<string>\\n 157       +generateIssue(task: RemainingTask, ctx: IssueContext, meta: GenerationMeta): Promise<IssueAiResult>\\n 158     }\\n 159     class LLMProviderAdapter {\\n 160       <<interface>>\\n 161       +complete(prompt: string, opts: ProviderCallOptions): Promise<string>\\n 162     }\\n 163     IssueAIGenerator --> LLMProviderAdapter\\n 164   ```\\n 165 - **主要責務**\\n 166   - `sanitizeContext(tasks, context)`：  \\n 167     - 最大5件の `RemainingTask` を対象。`task`, `steps`, `acceptanceCriteria`, `priorityReason`, `dependencies` は 512 文字にトリム。  \\n 168     - `targetFiles` は 10 件に制限。  \\n 169     - `SecretMasker` により既知のシークレット値を `[REDACTED_*]` に置換。  \\n 170   - `buildPrompt(payload)`：要件定義書のテンプレートを読み込み、`JSON.stringify` で安全に埋め込む。タイトルと本文を同時生成する複合リクエスト（FR-1, FR-2 対応）。\\n 171   - `invokeProvider(prompt)`：`options.maxRetries`（デフォルト3回）、指数バックオフ（1s, 2s, 4s）で再試行。`AbortController` による `timeoutMs` 制御。\\n 172   - `validateResponse(raw)`：  \\n 173     1. JSON 解析。  \\n 174     2. `title` 文字数チェック (50〜80)。  \\n 175     3. `body` に必須セクションが全て含まれるか正規表現で検証。  \\n 176     4. Markdown 以外のタグ検出 (`/<\\\\w+>/`) で拒否。  \\n 177     5. 失敗時は `IssueAiValidationError` を throw。\\n 178   - 成功時は `{ title, body, metadata }` を返却。`metadata` には使用モデル・推定トークン数・処理時間等を格納し DEBUG ログで出力。\\n 179 \\n 180 ### 7.2 LLM Provider アダプタ\\n 181 \\n 182 - **OpenAIAdapter**\\n 183   - 既存 `openai` パッケージを利用し `chat.completions.create()` を呼び出す。\\n 184   - デフォルトモデル: `options.model ?? 'gpt-4o-mini'`。\\n 185   - `response_format: { type: 'json_object' }` を指定し JSON を強制。\\n 186 - **AnthropicAdapter**\\n 187   - 公式 SDK `@anthropic-ai/sdk` を追加。`messages.create()` を使用し JSON 出力を指示。\\n 188   - `model` は `options.model ?? 'claude-3-5-sonnet-latest'`。\\n 189   - プロンプトは `messages: [{ role: 'user', content: prompt }]` 形式。\\n 190 - **Adapter 選択ロジック**\\n 191   - `IssueGenerationOptions.provider` が `claude`／`openai`／`auto` を選択。  \\n 192   - `auto` 時は OpenAI API キーが存在すれば優先、なければ Claude にフォールバック。  \\n 193   - API キー未設定・どちらも使用不可の場合は `IssueAIGenerator.isAvailable()` が `false` を返却し、IssueClient が即座にフォールバックする。\\n 194 \\n 195 ### 7.3 プロンプトテンプレート\\n 196 \\n 197 - `src/prompts/follow_up_issue/title_prompt.md` / `body_prompt.md` を追加し、テンプレート文字列中に `{{original_issue_title}}` 等のプレースホルダを定義。\\n 198 - IssueAIGenerator は `fs.readFileSync` (同期) で初期化時にロードし、ホットリロード不要。\\n 199 - プロンプトには以下を明示:\\n 200   1. タイトル 50〜80文字。\\n 201   2. 本文の必須セクション。\\n 202   3. 各セクションの内容ガイドライン（目的は1文、実行内容は番号付きリストなど）。\\n 203   4. JSON 形式で回答すること。\\n 204 - テンプレートは Markdown コメント (`<!-- -->`) でヒューマン向け説明を記載しつつ、モデルへの指示はプレーンテキストで記述。\\n 205 \\n 206 ### 7.4 IssueClient 拡張\\n 207 \\n 208 - 依存注入: `constructor(octokit, owner, repo, aiGenerator?: IssueAIGenerator)` に変更。`GitHubClient` から `IssueAIGenerator` を渡す。\\n 209 - `createIssueFromEvaluation` 署名を以下に拡張:\\n 210   ```ts\\n 211   public async createIssueFromEvaluation(\\n 212     issueNumber: number,\\n 213     remainingTasks: RemainingTask[],\\n 214     evaluationReportPath: string,\\n 215     issueContext?: IssueContext,\\n 216     generationOptions?: IssueGenerationOptions,\\n 217   ): Promise<IssueCreationResult>\\n 218   ```\\n 219 - 本文生成ロジック:\\n 220   ```ts\\n 221   let aiResult: IssueAiResult | null = null;\\n 222   if (generationOptions?.enabled && this.aiGenerator?.isAvailable()) {\\n 223     aiResult = await this.tryGenerateWithLLM(...).catch((error) => {\\n 224       logger.warn(`LLM generation failed: ${encodeWarning(getErrorMessage(error))}`);\\n 225       return null;\\n 226     });\\n 227   }\\n 228   const title = aiResult?.title ?? this.generateFollowUpTitle(...);\\n 229   const body = aiResult?.body ?? this.buildLegacyBody(...);\\n 230   ```\\n 231 - `tryGenerateWithLLM` 内で:\\n 232   - すべての `RemainingTask` を `IssueAIGenerator.generateIssue` に渡し、レスポンスを適用。\\n 233   - 生成内容に必須セクションが欠落している場合は LLM 失敗扱いとし、WARN ログに詳細（セクション欠如、タイトル長超過など）を出力。\\n 234   - 成功時は `## LLM生成メタデータ` を本文末尾（`## 参考` 手前）に追加し、モデル名・生成時刻を記録（要件 FR-5 のログ補助。ユーザーが不要な場合は `options.appendMetadata` で制御）。\\n 235 \\n 236 ### 7.5 GitHubClient / CLI / Phase 連携\\n 237 \\n 238 - `GitHubClient` コンストラクタで `IssueAIGenerator` を初期化。`config.ts` から取得した LLM 設定を渡す。\\n 239 - `createIssueFromEvaluation` 引数に `generationOptions` を追加。Phase 側で動的に変更したい場合に備える。\\n 240 - `ExecuteCommandOptions` / `ParsedExecuteOptions` に以下オプション追加:\\n 241   - `followupLlmMode` (`'auto' | 'openai' | 'claude' | 'off'`, デフォルト `'off'`)\\n 242   - `followupLlmModel?: string`\\n 243   - `followupLlmTimeout?: number`\\n 244   - `followupLlmRetries?: number`\\n 245 - CLI サンプル: `ai-workflow execute --issue 119 --phase evaluation --followup-llm-mode auto`.\\n 246 - `PhaseContext` に `issueGenerationOptions` を追加。`PhaseFactory` と各 Phase のコンストラクタに影響が出ないよう、`BasePhase` にプロパティを追加する。\\n 247 - `EvaluationPhase` では `this.context.issueGenerationOptions` を取得し、`this.github.createIssueFromEvaluation(..., options)` を呼び出す。\\n 248 \\n 249 ### 7.6 型・設定拡張\\n 250 \\n 251 - `src/types.ts` に `IssueGenerationOptions` を追加:\\n 252   ```ts\\n 253   export interface IssueGenerationOptions {\\n 254     enabled: boolean;\\n 255     provider: 'auto' | 'openai' | 'claude';\\n 256     model?: string;\\n 257     temperature?: number;\\n 258     maxTokens?: number;\\n 259     timeoutMs?: number;\\n 260     maxRetries?: number;\\n 261     maxTasks?: number; // プロンプトへ含める残タスク数（デフォルト5）\\n 262     appendMetadata?: boolean; // 本文末尾にAIメタデータを追記するか\\n 263   }\\n 264   ```\\n 265 - `config.ts` へ以下ゲッター追加:\\n 266   - `getFollowupLlmMode()`, `getFollowupLlmModel()`, `getFollowupLlmTimeoutMs()`, `getFollowupLlmRetries()`, `getFollowupLlmEnabled()`.\\n 267 - 環境変数命名例:\\n 268   - `FOLLOWUP_LLM_MODE` (`off` / `auto` / `openai` / `claude`)\\n 269   - `FOLLOWUP_LLM_MODEL`\\n 270   - `FOLLOWUP_LLM_TIMEOUT_MS`\\n 271   - `FOLLOWUP_LLM_MAX_RETRIES`\\n 272   - `FOLLOWUP_LLM_APPEND_METADATA`\\n 273 \\n 274 ### 7.7 テスト設計詳細\\n 275 \\n 276 - **ユニットテスト (`tests/unit/github/issue-ai-generator.test.ts`)**\\n 277   1. `buildPrompt()` がタスク5件超過時に切り詰めること。\\n 278   2. API 応答が JSON 以外の場合に `ValidationError` を throw。\\n 279   3. 必須セクション欠落時に失敗すること。\\n 280   4. タイトル長が 50 未満/80 超過で失敗すること。\\n 281   5. リトライ設定が機能し、2回目で成功した場合に成功として返ること（モックで制御）。\\n 282   6. シークレット値が `[REDACTED_*]` に置換されること。\\n 283 - **既存ユニットテスト拡張**\\n 284   - `issue-client.followup` テストに LLM 成功シナリオを追加（モック `IssueAIGenerator` を注入）。\\n 285   - LLM 例外時に WARN ログが発生し、既存フォールバックが使われることを検証。\\n 286 - **インテグレーションテスト (`tests/integration/followup-issue-llm.test.ts`)**\\n 287   - Octokit モック + `IssueAIGenerator` フェイクを用意し、`createIssueFromEvaluation` が最終的に Octokit へ期待値を渡すことを確認。\\n 288   - 実 API 呼び出しテストは `process.env.FOLLOWUP_LLM_E2E === '1'` の時のみ実行。APIキー未設定時は `it.skip`。\\n 289 \\n 290 ### 7.8 ドキュメント更新\\n 291 \\n 292 - `ARCHITECTURE.md`: Evaluation Phase → GitHubClient → IssueAIGenerator フロー図と説明を追加。\\n 293 - `CLAUDE.md`: 新しい環境変数、Claude モデル選択、フォールバック挙動を追記。\\n 294 - `README.md`: CLI オプション、設定例（`.env` テンプレート抜粋）、Troubleshooting（LLM失敗時のログの読み方）を追加。\\n 295 \\n 296 ### 7.9 要件トレーサビリティ\\n 297 \\n 298 | 要件ID | 設計対応箇所 |\\n 299 | --- | --- |\\n 300 | FR-1 (タイトル 50-80文字) | 7.1 `validateResponse` で文字数検証、7.4 で LLM タイトル採用 |\\n 301 | FR-2 (本文セクション) | 7.1 `buildPrompt` / `validateResponse` と 7.4 本文構築 |\\n 302 | FR-3 (フォールバック) | 7.4 `tryGenerateWithLLM` → `buildLegacyBody` |\\n 303 | FR-4 (設定反映) | 7.5 CLI/Phase 連携、7.6 `IssueGenerationOptions` |\\n 304 | FR-5 (ログ) | 7.1 メタデータ記録、7.4 WARN/DEBUG ログ設計 |\\n 305 \\n 306 ---\\n 307 \\n 308 ## 8. セキュリティ考慮事項\\n 309 \\n 310 - プロンプト前処理で `SecretMasker` により環境変数シークレットを除去。ユーザー提供データ内のメール/トークン形式を正規表現で追加検査。\\n 311 - LLM 応答に URL やコマンドが含まれる場合はそのまま Issue へ反映するが、HTML/スクリプトタグは拒否。\\n 312 - ログには API 応答本文を含めず、`encodeWarning` でエラー文字列をエンコード。APIキーは `config` ゲッター経由のみ取得し、再出力しない。\\n 313 - 送信データには評価レポート本文等機密情報を含めない。ファイルパスは `evaluationReportPath` のみで内容は送信しない。\\n 314 - レート制限超過時は再試行後にフォールバックし、無限ループ防止のため maxRetries を強制適用。\\n 315 \\n 316 ---\\n 317 \\n 318 ## 9. 非機能要件への対応\\n 319 \\n 320 - **パフォーマンス**: タイムアウト (`timeoutMs`, デフォルト 30,000ms) と最大再試行 3 回で最悪 90 秒以内にフォールバック。タスク数制限・文字数トリムでプロンプトサイズを制御。\\n 321 - **スケーラビリティ**: `IssueGenerationOptions.maxTasks` でプロンプト長を制御し、大規模残タスクでも安定。今後プロンプトテンプレート差し替えやモデル追加を `IssueAIGenerator` 内で閉じる設計。\\n 322 - **保守性**: Provider アダプタを分離しテスト可能に。設定値は `config` 経由で集中管理し、ドキュメント更新でオンボーディングを容易にする。\\n 323 - **可用性**: LLM 失敗時でも既存ロジックで必ず Issue 作成できる（FR-3）。WARN ログで原因を追跡可能。\\n 324 \\n 325 ---\\n 326 \\n 327 ## 10. 実装の順序\\n 328 \\n 329 1. **型・設定整備**: `IssueGenerationOptions` 追加、`config.ts` ゲッター、CLI オプション解析/PhaseContext 拡張を実装。\\n 330 2. **IssueAIGenerator 実装**: プロンプトテンプレート追加、Provider アダプタとサニタイズ・バリデーションロジックを開発。\\n 331 3. **IssueClient / GitHubClient 拡張**: 依存注入、LLM 優先フロー、フォールバック実装、ログ整備。\\n 332 4. **Phase/Evaluation 更新**: `IssueGenerationOptions` を渡すように修正。\\n 333 5. **テスト実装**: 新規/既存テストを追加・更新。API キーが無い環境でも全テストが通るようモック設計。\\n 334 6. **ドキュメント更新**: README / ARCHITECTURE / CLAUDE を更新し、利用手順と環境変数を明記。\\n 335 7. **検証**: `npm run test:unit`, `npm run test:integration` を実行。必要に応じて `FOLLOWUP_LLM_E2E=1` で手動統合テストを実施。\\n 336 \\n 337 ---\\n 338 \\n 339 本設計は以下の品質ゲートを満たしています:\\n 340 - 実装戦略・テスト戦略・テストコード戦略の根拠を明記\\n 341 - 既存コードへの影響範囲を分析\\n 342 - 変更ファイルをリストアップ\\n 343 - 実装手順と要件トレーサビリティを提示し、実装可能な設計を提供\\n 344 \\n\",\"exit_code\":0,\"status\":\"completed\"}}\n.ai-workflow/issue-119/02_design/execute/agent_log_raw.txt:46:{\"type\":\"item.completed\",\"item\":{\"id\":\"item_21\",\"type\":\"command_execution\",\"command\":\"bash -lc \\\"node - <<'NODE'\\nconst fs = require('fs');\\nconst lines = fs.readFileSync('.ai-workflow/issue-119/02_design/output/design.md','utf8').split(/\\\\\\\\r?\\\\\\\\n/);\\nfor (let i=120; i<lines.length; i++) {\\n  console.log(String(i+1).padStart(4,' '), lines[i]);\\n}\\nNODE\\\"\",\"aggregated_output\":\" 121   - `src/prompts/follow_up_issue/title_prompt.md`\\n 122   - `src/prompts/follow_up_issue/body_prompt.md`\\n 123   - `tests/unit/github/issue-ai-generator.test.ts`\\n 124   - `tests/integration/followup-issue-llm.test.ts`\\n 125 - **既存修正**\\n 126   - `src/core/github/issue-client.ts`\\n 127   - `src/core/github-client.ts`\\n 128   - `src/phases/evaluation.ts`\\n 129   - `src/commands/execute.ts`\\n 130   - `src/commands/execute/options-parser.ts`\\n 131   - `src/types.ts`\\n 132   - `src/types/commands.ts`\\n 133   - `src/core/config.ts`\\n 134   - 既存テスト: `tests/unit/github/issue-client.test.ts`, `tests/unit/github/issue-client-followup.test.ts`\\n 135 - **ドキュメント**\\n 136   - `ARCHITECTURE.md`\\n 137   - `CLAUDE.md`\\n 138   - `README.md`（環境変数と使い方）\\n 139 - **削除**: なし\\n 140 \\n 141 ---\\n 142 \\n 143 ## 7. 詳細設計\\n 144 \\n 145 ### 7.1 IssueAIGenerator モジュール（新規）\\n 146 \\n 147 - **クラス構成**\\n 148   ```mermaid\\n 149   classDiagram\\n 150     class IssueAIGenerator {\\n 151       -options: IssueGenerationOptions\\n 152       -provider: LLMProviderAdapter\\n 153       -secretMasker: SecretMasker\\n 154       -clock: Clock\\n 155       +generateTitle(task: RemainingTask, ctx: IssueContext, meta: GenerationMeta): Promise<string>\\n 156       +generateDescription(task: RemainingTask, ctx: IssueContext, meta: GenerationMeta): Promise<string>\\n 157       +generateIssue(task: RemainingTask, ctx: IssueContext, meta: GenerationMeta): Promise<IssueAiResult>\\n 158     }\\n 159     class LLMProviderAdapter {\\n 160       <<interface>>\\n 161       +complete(prompt: string, opts: ProviderCallOptions): Promise<string>\\n 162     }\\n 163     IssueAIGenerator --> LLMProviderAdapter\\n 164   ```\\n 165 - **主要責務**\\n 166   - `sanitizeContext(tasks, context)`：  \\n 167     - 最大5件の `RemainingTask` を対象。`task`, `steps`, `acceptanceCriteria`, `priorityReason`, `dependencies` は 512 文字にトリム。  \\n 168     - `targetFiles` は 10 件に制限。  \\n 169     - `SecretMasker` により既知のシークレット値を `[REDACTED_*]` に置換。  \\n 170   - `buildPrompt(payload)`：要件定義書のテンプレートを読み込み、`JSON.stringify` で安全に埋め込む。タイトルと本文を同時生成する複合リクエスト（FR-1, FR-2 対応）。\\n 171   - `invokeProvider(prompt)`：`options.maxRetries`（デフォルト3回）、指数バックオフ（1s, 2s, 4s）で再試行。`AbortController` による `timeoutMs` 制御。\\n 172   - `validateResponse(raw)`：  \\n 173     1. JSON 解析。  \\n 174     2. `title` 文字数チェック (50〜80)。  \\n 175     3. `body` に必須セクションが全て含まれるか正規表現で検証。  \\n 176     4. Markdown 以外のタグ検出 (`/<\\\\w+>/`) で拒否。  \\n 177     5. 失敗時は `IssueAiValidationError` を throw。\\n 178   - 成功時は `{ title, body, metadata }` を返却。`metadata` には使用モデル・推定トークン数・処理時間等を格納し DEBUG ログで出力。\\n 179 \\n 180 ### 7.2 LLM Provider アダプタ\\n 181 \\n 182 - **OpenAIAdapter**\\n 183   - 既存 `openai` パッケージを利用し `chat.completions.create()` を呼び出す。\\n 184   - デフォルトモデル: `options.model ?? 'gpt-4o-mini'`。\\n 185   - `response_format: { type: 'json_object' }` を指定し JSON を強制。\\n 186 - **AnthropicAdapter**\\n 187   - 公式 SDK `@anthropic-ai/sdk` を追加。`messages.create()` を使用し JSON 出力を指示。\\n 188   - `model` は `options.model ?? 'claude-3-5-sonnet-latest'`。\\n 189   - プロンプトは `messages: [{ role: 'user', content: prompt }]` 形式。\\n 190 - **Adapter 選択ロジック**\\n 191   - `IssueGenerationOptions.provider` が `claude`／`openai`／`auto` を選択。  \\n 192   - `auto` 時は OpenAI API キーが存在すれば優先、なければ Claude にフォールバック。  \\n 193   - API キー未設定・どちらも使用不可の場合は `IssueAIGenerator.isAvailable()` が `false` を返却し、IssueClient が即座にフォールバックする。\\n 194 \\n 195 ### 7.3 プロンプトテンプレート\\n 196 \\n 197 - `src/prompts/follow_up_issue/title_prompt.md` / `body_prompt.md` を追加し、テンプレート文字列中に `{{original_issue_title}}` 等のプレースホルダを定義。\\n 198 - IssueAIGenerator は `fs.readFileSync` (同期) で初期化時にロードし、ホットリロード不要。\\n 199 - プロンプトには以下を明示:\\n 200   1. タイトル 50〜80文字。\\n 201   2. 本文の必須セクション。\\n 202   3. 各セクションの内容ガイドライン（目的は1文、実行内容は番号付きリストなど）。\\n 203   4. JSON 形式で回答すること。\\n 204 - テンプレートは Markdown コメント (`<!-- -->`) でヒューマン向け説明を記載しつつ、モデルへの指示はプレーンテキストで記述。\\n 205 \\n 206 ### 7.4 IssueClient 拡張\\n 207 \\n 208 - 依存注入: `constructor(octokit, owner, repo, aiGenerator?: IssueAIGenerator)` に変更。`GitHubClient` から `IssueAIGenerator` を渡す。\\n 209 - `createIssueFromEvaluation` 署名を以下に拡張:\\n 210   ```ts\\n 211   public async createIssueFromEvaluation(\\n 212     issueNumber: number,\\n 213     remainingTasks: RemainingTask[],\\n 214     evaluationReportPath: string,\\n 215     issueContext?: IssueContext,\\n 216     generationOptions?: IssueGenerationOptions,\\n 217   ): Promise<IssueCreationResult>\\n 218   ```\\n 219 - 本文生成ロジック:\\n 220   ```ts\\n 221   let aiResult: IssueAiResult | null = null;\\n 222   if (generationOptions?.enabled && this.aiGenerator?.isAvailable()) {\\n 223     aiResult = await this.tryGenerateWithLLM(...).catch((error) => {\\n 224       logger.warn(`LLM generation failed: ${encodeWarning(getErrorMessage(error))}`);\\n 225       return null;\\n 226     });\\n 227   }\\n 228   const title = aiResult?.title ?? this.generateFollowUpTitle(...);\\n 229   const body = aiResult?.body ?? this.buildLegacyBody(...);\\n 230   ```\\n 231 - `tryGenerateWithLLM` 内で:\\n 232   - すべての `RemainingTask` を `IssueAIGenerator.generateIssue` に渡し、レスポンスを適用。\\n 233   - 生成内容に必須セクションが欠落している場合は LLM 失敗扱いとし、WARN ログに詳細（セクション欠如、タイトル長超過など）を出力。\\n 234   - 成功時は `## LLM生成メタデータ` を本文末尾（`## 参考` 手前）に追加し、モデル名・生成時刻を記録（要件 FR-5 のログ補助。ユーザーが不要な場合は `options.appendMetadata` で制御）。\\n 235 \\n 236 ### 7.5 GitHubClient / CLI / Phase 連携\\n 237 \\n 238 - `GitHubClient` コンストラクタで `IssueAIGenerator` を初期化。`config.ts` から取得した LLM 設定を渡す。\\n 239 - `createIssueFromEvaluation` 引数に `generationOptions` を追加。Phase 側で動的に変更したい場合に備える。\\n 240 - `ExecuteCommandOptions` / `ParsedExecuteOptions` に以下オプション追加:\\n 241   - `followupLlmMode` (`'auto' | 'openai' | 'claude' | 'off'`, デフォルト `'off'`)\\n 242   - `followupLlmModel?: string`\\n 243   - `followupLlmTimeout?: number`\\n 244   - `followupLlmRetries?: number`\\n 245 - CLI サンプル: `ai-workflow execute --issue 119 --phase evaluation --followup-llm-mode auto`.\\n 246 - `PhaseContext` に `issueGenerationOptions` を追加。`PhaseFactory` と各 Phase のコンストラクタに影響が出ないよう、`BasePhase` にプロパティを追加する。\\n 247 - `EvaluationPhase` では `this.context.issueGenerationOptions` を取得し、`this.github.createIssueFromEvaluation(..., options)` を呼び出す。\\n 248 \\n 249 ### 7.6 型・設定拡張\\n 250 \\n 251 - `src/types.ts` に `IssueGenerationOptions` を追加:\\n 252   ```ts\\n 253   export interface IssueGenerationOptions {\\n 254     enabled: boolean;\\n 255     provider: 'auto' | 'openai' | 'claude';\\n 256     model?: string;\\n 257     temperature?: number;\\n 258     maxTokens?: number;\\n 259     timeoutMs?: number;\\n 260     maxRetries?: number;\\n 261     maxTasks?: number; // プロンプトへ含める残タスク数（デフォルト5）\\n 262     appendMetadata?: boolean; // 本文末尾にAIメタデータを追記するか\\n 263   }\\n 264   ```\\n 265 - `config.ts` へ以下ゲッター追加:\\n 266   - `getFollowupLlmMode()`, `getFollowupLlmModel()`, `getFollowupLlmTimeoutMs()`, `getFollowupLlmRetries()`, `getFollowupLlmEnabled()`.\\n 267 - 環境変数命名例:\\n 268   - `FOLLOWUP_LLM_MODE` (`off` / `auto` / `openai` / `claude`)\\n 269   - `FOLLOWUP_LLM_MODEL`\\n 270   - `FOLLOWUP_LLM_TIMEOUT_MS`\\n 271   - `FOLLOWUP_LLM_MAX_RETRIES`\\n 272   - `FOLLOWUP_LLM_APPEND_METADATA`\\n 273 \\n 274 ### 7.7 テスト設計詳細\\n 275 \\n 276 - **ユニットテスト (`tests/unit/github/issue-ai-generator.test.ts`)**\\n 277   1. `buildPrompt()` がタスク5件超過時に切り詰めること。\\n 278   2. API 応答が JSON 以外の場合に `ValidationError` を throw。\\n 279   3. 必須セクション欠落時に失敗すること。\\n 280   4. タイトル長が 50 未満/80 超過で失敗すること。\\n 281   5. リトライ設定が機能し、2回目で成功した場合に成功として返ること（モックで制御）。\\n 282   6. シークレット値が `[REDACTED_*]` に置換されること。\\n 283 - **既存ユニットテスト拡張**\\n 284   - `issue-client.followup` テストに LLM 成功シナリオを追加（モック `IssueAIGenerator` を注入）。\\n 285   - LLM 例外時に WARN ログが発生し、既存フォールバックが使われることを検証。\\n 286 - **インテグレーションテスト (`tests/integration/followup-issue-llm.test.ts`)**\\n 287   - Octokit モック + `IssueAIGenerator` フェイクを用意し、`createIssueFromEvaluation` が最終的に Octokit へ期待値を渡すことを確認。\\n 288   - 実 API 呼び出しテストは `process.env.FOLLOWUP_LLM_E2E === '1'` の時のみ実行。APIキー未設定時は `it.skip`。\\n 289 \\n 290 ### 7.8 ドキュメント更新\\n 291 \\n 292 - `ARCHITECTURE.md`: Evaluation Phase → GitHubClient → IssueAIGenerator フロー図と説明を追加。\\n 293 - `CLAUDE.md`: 新しい環境変数、Claude モデル選択、フォールバック挙動を追記。\\n 294 - `README.md`: CLI オプション、設定例（`.env` テンプレート抜粋）、Troubleshooting（LLM失敗時のログの読み方）を追加。\\n 295 \\n 296 ### 7.9 要件トレーサビリティ\\n 297 \\n 298 | 要件ID | 設計対応箇所 |\\n 299 | --- | --- |\\n 300 | FR-1 (タイトル 50-80文字) | 7.1 `validateResponse` で文字数検証、7.4 で LLM タイトル採用 |\\n 301 | FR-2 (本文セクション) | 7.1 `buildPrompt` / `validateResponse` と 7.4 本文構築 |\\n 302 | FR-3 (フォールバック) | 7.4 `tryGenerateWithLLM` → `buildLegacyBody` |\\n 303 | FR-4 (設定反映) | 7.5 CLI/Phase 連携、7.6 `IssueGenerationOptions` |\\n 304 | FR-5 (ログ) | 7.1 メタデータ記録、7.4 WARN/DEBUG ログ設計 |\\n 305 \\n 306 ---\\n 307 \\n 308 ## 8. セキュリティ考慮事項\\n 309 \\n 310 - プロンプト前処理で `SecretMasker` により環境変数シークレットを除去。ユーザー提供データ内のメール/トークン形式を正規表現で追加検査。\\n 311 - LLM 応答に URL やコマンドが含まれる場合はそのまま Issue へ反映するが、HTML/スクリプトタグは拒否。\\n 312 - ログには API 応答本文を含めず、`encodeWarning` でエラー文字列をエンコード。APIキーは `config` ゲッター経由のみ取得し、再出力しない。\\n 313 - 送信データには評価レポート本文等機密情報を含めない。ファイルパスは `evaluationReportPath` のみで内容は送信しない。\\n 314 - レート制限超過時は再試行後にフォールバックし、無限ループ防止のため maxRetries を強制適用。\\n 315 \\n 316 ---\\n 317 \\n 318 ## 9. 非機能要件への対応\\n 319 \\n 320 - **パフォーマンス**: タイムアウト (`timeoutMs`, デフォルト 30,000ms) と最大再試行 3 回で最悪 90 秒以内にフォールバック。タスク数制限・文字数トリムでプロンプトサイズを制御。\\n 321 - **スケーラビリティ**: `IssueGenerationOptions.maxTasks` でプロンプト長を制御し、大規模残タスクでも安定。今後プロンプトテンプレート差し替えやモデル追加を `IssueAIGenerator` 内で閉じる設計。\\n 322 - **保守性**: Provider アダプタを分離しテスト可能に。設定値は `config` 経由で集中管理し、ドキュメント更新でオンボーディングを容易にする。\\n 323 - **可用性**: LLM 失敗時でも既存ロジックで必ず Issue 作成できる（FR-3）。WARN ログで原因を追跡可能。\\n 324 \\n 325 ---\\n 326 \\n 327 ## 10. 実装の順序\\n 328 \\n 329 1. **型・設定整備**: `IssueGenerationOptions` 追加、`config.ts` ゲッター、CLI オプション解析/PhaseContext 拡張を実装。\\n 330 2. **IssueAIGenerator 実装**: プロンプトテンプレート追加、Provider アダプタとサニタイズ・バリデーションロジックを開発。\\n 331 3. **IssueClient / GitHubClient 拡張**: 依存注入、LLM 優先フロー、フォールバック実装、ログ整備。\\n 332 4. **Phase/Evaluation 更新**: `IssueGenerationOptions` を渡すように修正。\\n 333 5. **テスト実装**: 新規/既存テストを追加・更新。API キーが無い環境でも全テストが通るようモック設計。\\n 334 6. **ドキュメント更新**: README / ARCHITECTURE / CLAUDE を更新し、利用手順と環境変数を明記。\\n 335 7. **検証**: `npm run test:unit`, `npm run test:integration` を実行。必要に応じて `FOLLOWUP_LLM_E2E=1` で手動統合テストを実施。\\n 336 \\n 337 ---\\n 338 \\n 339 本設計は以下の品質ゲートを満たしています:\\n 340 - 実装戦略・テスト戦略・テストコード戦略の根拠を明記\\n 341 - 既存コードへの影響範囲を分析\\n 342 - 変更ファイルをリストアップ\\n 343 - 実装手順と要件トレーサビリティを提示し、実装可能な設計を提供\\n 344 \\n\",\"exit_code\":0,\"status\":\"completed\"}}\n.ai-workflow/issue-119/02_design/execute/agent_log_raw.txt:48:{\"type\":\"item.completed\",\"item\":{\"id\":\"item_22\",\"type\":\"command_execution\",\"command\":\"bash -lc \\\"node - <<'NODE'\\nconst fs = require('fs');\\nconst lines = fs.readFileSync('.ai-workflow/issue-119/02_design/output/design.md','utf8').split(/\\\\\\\\r?\\\\\\\\n/);\\nfor (let i=200; i<lines.length; i++) {\\n  console.log(String(i+1).padStart(4,' '), lines[i]);\\n}\\nNODE\\\"\",\"aggregated_output\":\" 201   2. 本文の必須セクション。\\n 202   3. 各セクションの内容ガイドライン（目的は1文、実行内容は番号付きリストなど）。\\n 203   4. JSON 形式で回答すること。\\n 204 - テンプレートは Markdown コメント (`<!-- -->`) でヒューマン向け説明を記載しつつ、モデルへの指示はプレーンテキストで記述。\\n 205 \\n 206 ### 7.4 IssueClient 拡張\\n 207 \\n 208 - 依存注入: `constructor(octokit, owner, repo, aiGenerator?: IssueAIGenerator)` に変更。`GitHubClient` から `IssueAIGenerator` を渡す。\\n 209 - `createIssueFromEvaluation` 署名を以下に拡張:\\n 210   ```ts\\n 211   public async createIssueFromEvaluation(\\n 212     issueNumber: number,\\n 213     remainingTasks: RemainingTask[],\\n 214     evaluationReportPath: string,\\n 215     issueContext?: IssueContext,\\n 216     generationOptions?: IssueGenerationOptions,\\n 217   ): Promise<IssueCreationResult>\\n 218   ```\\n 219 - 本文生成ロジック:\\n 220   ```ts\\n 221   let aiResult: IssueAiResult | null = null;\\n 222   if (generationOptions?.enabled && this.aiGenerator?.isAvailable()) {\\n 223     aiResult = await this.tryGenerateWithLLM(...).catch((error) => {\\n 224       logger.warn(`LLM generation failed: ${encodeWarning(getErrorMessage(error))}`);\\n 225       return null;\\n 226     });\\n 227   }\\n 228   const title = aiResult?.title ?? this.generateFollowUpTitle(...);\\n 229   const body = aiResult?.body ?? this.buildLegacyBody(...);\\n 230   ```\\n 231 - `tryGenerateWithLLM` 内で:\\n 232   - すべての `RemainingTask` を `IssueAIGenerator.generateIssue` に渡し、レスポンスを適用。\\n 233   - 生成内容に必須セクションが欠落している場合は LLM 失敗扱いとし、WARN ログに詳細（セクション欠如、タイトル長超過など）を出力。\\n 234   - 成功時は `## LLM生成メタデータ` を本文末尾（`## 参考` 手前）に追加し、モデル名・生成時刻を記録（要件 FR-5 のログ補助。ユーザーが不要な場合は `options.appendMetadata` で制御）。\\n 235 \\n 236 ### 7.5 GitHubClient / CLI / Phase 連携\\n 237 \\n 238 - `GitHubClient` コンストラクタで `IssueAIGenerator` を初期化。`config.ts` から取得した LLM 設定を渡す。\\n 239 - `createIssueFromEvaluation` 引数に `generationOptions` を追加。Phase 側で動的に変更したい場合に備える。\\n 240 - `ExecuteCommandOptions` / `ParsedExecuteOptions` に以下オプション追加:\\n 241   - `followupLlmMode` (`'auto' | 'openai' | 'claude' | 'off'`, デフォルト `'off'`)\\n 242   - `followupLlmModel?: string`\\n 243   - `followupLlmTimeout?: number`\\n 244   - `followupLlmRetries?: number`\\n 245 - CLI サンプル: `ai-workflow execute --issue 119 --phase evaluation --followup-llm-mode auto`.\\n 246 - `PhaseContext` に `issueGenerationOptions` を追加。`PhaseFactory` と各 Phase のコンストラクタに影響が出ないよう、`BasePhase` にプロパティを追加する。\\n 247 - `EvaluationPhase` では `this.context.issueGenerationOptions` を取得し、`this.github.createIssueFromEvaluation(..., options)` を呼び出す。\\n 248 \\n 249 ### 7.6 型・設定拡張\\n 250 \\n 251 - `src/types.ts` に `IssueGenerationOptions` を追加:\\n 252   ```ts\\n 253   export interface IssueGenerationOptions {\\n 254     enabled: boolean;\\n 255     provider: 'auto' | 'openai' | 'claude';\\n 256     model?: string;\\n 257     temperature?: number;\\n 258     maxTokens?: number;\\n 259     timeoutMs?: number;\\n 260     maxRetries?: number;\\n 261     maxTasks?: number; // プロンプトへ含める残タスク数（デフォルト5）\\n 262     appendMetadata?: boolean; // 本文末尾にAIメタデータを追記するか\\n 263   }\\n 264   ```\\n 265 - `config.ts` へ以下ゲッター追加:\\n 266   - `getFollowupLlmMode()`, `getFollowupLlmModel()`, `getFollowupLlmTimeoutMs()`, `getFollowupLlmRetries()`, `getFollowupLlmEnabled()`.\\n 267 - 環境変数命名例:\\n 268   - `FOLLOWUP_LLM_MODE` (`off` / `auto` / `openai` / `claude`)\\n 269   - `FOLLOWUP_LLM_MODEL`\\n 270   - `FOLLOWUP_LLM_TIMEOUT_MS`\\n 271   - `FOLLOWUP_LLM_MAX_RETRIES`\\n 272   - `FOLLOWUP_LLM_APPEND_METADATA`\\n 273 \\n 274 ### 7.7 テスト設計詳細\\n 275 \\n 276 - **ユニットテスト (`tests/unit/github/issue-ai-generator.test.ts`)**\\n 277   1. `buildPrompt()` がタスク5件超過時に切り詰めること。\\n 278   2. API 応答が JSON 以外の場合に `ValidationError` を throw。\\n 279   3. 必須セクション欠落時に失敗すること。\\n 280   4. タイトル長が 50 未満/80 超過で失敗すること。\\n 281   5. リトライ設定が機能し、2回目で成功した場合に成功として返ること（モックで制御）。\\n 282   6. シークレット値が `[REDACTED_*]` に置換されること。\\n 283 - **既存ユニットテスト拡張**\\n 284   - `issue-client.followup` テストに LLM 成功シナリオを追加（モック `IssueAIGenerator` を注入）。\\n 285   - LLM 例外時に WARN ログが発生し、既存フォールバックが使われることを検証。\\n 286 - **インテグレーションテスト (`tests/integration/followup-issue-llm.test.ts`)**\\n 287   - Octokit モック + `IssueAIGenerator` フェイクを用意し、`createIssueFromEvaluation` が最終的に Octokit へ期待値を渡すことを確認。\\n 288   - 実 API 呼び出しテストは `process.env.FOLLOWUP_LLM_E2E === '1'` の時のみ実行。APIキー未設定時は `it.skip`。\\n 289 \\n 290 ### 7.8 ドキュメント更新\\n 291 \\n 292 - `ARCHITECTURE.md`: Evaluation Phase → GitHubClient → IssueAIGenerator フロー図と説明を追加。\\n 293 - `CLAUDE.md`: 新しい環境変数、Claude モデル選択、フォールバック挙動を追記。\\n 294 - `README.md`: CLI オプション、設定例（`.env` テンプレート抜粋）、Troubleshooting（LLM失敗時のログの読み方）を追加。\\n 295 \\n 296 ### 7.9 要件トレーサビリティ\\n 297 \\n 298 | 要件ID | 設計対応箇所 |\\n 299 | --- | --- |\\n 300 | FR-1 (タイトル 50-80文字) | 7.1 `validateResponse` で文字数検証、7.4 で LLM タイトル採用 |\\n 301 | FR-2 (本文セクション) | 7.1 `buildPrompt` / `validateResponse` と 7.4 本文構築 |\\n 302 | FR-3 (フォールバック) | 7.4 `tryGenerateWithLLM` → `buildLegacyBody` |\\n 303 | FR-4 (設定反映) | 7.5 CLI/Phase 連携、7.6 `IssueGenerationOptions` |\\n 304 | FR-5 (ログ) | 7.1 メタデータ記録、7.4 WARN/DEBUG ログ設計 |\\n 305 \\n 306 ---\\n 307 \\n 308 ## 8. セキュリティ考慮事項\\n 309 \\n 310 - プロンプト前処理で `SecretMasker` により環境変数シークレットを除去。ユーザー提供データ内のメール/トークン形式を正規表現で追加検査。\\n 311 - LLM 応答に URL やコマンドが含まれる場合はそのまま Issue へ反映するが、HTML/スクリプトタグは拒否。\\n 312 - ログには API 応答本文を含めず、`encodeWarning` でエラー文字列をエンコード。APIキーは `config` ゲッター経由のみ取得し、再出力しない。\\n 313 - 送信データには評価レポート本文等機密情報を含めない。ファイルパスは `evaluationReportPath` のみで内容は送信しない。\\n 314 - レート制限超過時は再試行後にフォールバックし、無限ループ防止のため maxRetries を強制適用。\\n 315 \\n 316 ---\\n 317 \\n 318 ## 9. 非機能要件への対応\\n 319 \\n 320 - **パフォーマンス**: タイムアウト (`timeoutMs`, デフォルト 30,000ms) と最大再試行 3 回で最悪 90 秒以内にフォールバック。タスク数制限・文字数トリムでプロンプトサイズを制御。\\n 321 - **スケーラビリティ**: `IssueGenerationOptions.maxTasks` でプロンプト長を制御し、大規模残タスクでも安定。今後プロンプトテンプレート差し替えやモデル追加を `IssueAIGenerator` 内で閉じる設計。\\n 322 - **保守性**: Provider アダプタを分離しテスト可能に。設定値は `config` 経由で集中管理し、ドキュメント更新でオンボーディングを容易にする。\\n 323 - **可用性**: LLM 失敗時でも既存ロジックで必ず Issue 作成できる（FR-3）。WARN ログで原因を追跡可能。\\n 324 \\n 325 ---\\n 326 \\n 327 ## 10. 実装の順序\\n 328 \\n 329 1. **型・設定整備**: `IssueGenerationOptions` 追加、`config.ts` ゲッター、CLI オプション解析/PhaseContext 拡張を実装。\\n 330 2. **IssueAIGenerator 実装**: プロンプトテンプレート追加、Provider アダプタとサニタイズ・バリデーションロジックを開発。\\n 331 3. **IssueClient / GitHubClient 拡張**: 依存注入、LLM 優先フロー、フォールバック実装、ログ整備。\\n 332 4. **Phase/Evaluation 更新**: `IssueGenerationOptions` を渡すように修正。\\n 333 5. **テスト実装**: 新規/既存テストを追加・更新。API キーが無い環境でも全テストが通るようモック設計。\\n 334 6. **ドキュメント更新**: README / ARCHITECTURE / CLAUDE を更新し、利用手順と環境変数を明記。\\n 335 7. **検証**: `npm run test:unit`, `npm run test:integration` を実行。必要に応じて `FOLLOWUP_LLM_E2E=1` で手動統合テストを実施。\\n 336 \\n 337 ---\\n 338 \\n 339 本設計は以下の品質ゲートを満たしています:\\n 340 - 実装戦略・テスト戦略・テストコード戦略の根拠を明記\\n 341 - 既存コードへの影響範囲を分析\\n 342 - 変更ファイルをリストアップ\\n 343 - 実装手順と要件トレーサビリティを提示し、実装可能な設計を提供\\n 344 \\n\",\"exit_code\":0,\"status\":\"completed\"}}\n.ai-workflow/issue-119/02_design/execute/agent_log.md:1920: 246 - `PhaseContext` に `issueGenerationOptions` を追加。`PhaseFactory` と各 Phase のコンストラクタに影響が出ないよう、`BasePhase` にプロパティを追加する。\n","exit_code":0,"status":"completed"}}
{"type":"item.started","item":{"id":"item_14","type":"command_execution","command":"bash -lc \"find src -name '*phase-factory*'\"","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_14","type":"command_execution","command":"bash -lc \"find src -name '*phase-factory*'\"","aggregated_output":"src/core/phase-factory.ts\n","exit_code":0,"status":"completed"}}
{"type":"item.started","item":{"id":"item_15","type":"command_execution","command":"bash -lc \"sed -n '220,360p' design.md\"","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_15","type":"command_execution","command":"bash -lc \"sed -n '220,360p' design.md\"","aggregated_output":"テンプレート例 (コード内定数として保持):\n\n````markdown\nあなたはソフトウェア開発プロジェクトのIssue作成アシスタントです。\n以下のJSONを読み取り、フォローアップIssueを構築してください。\n\n入力:\n{{payload}}\n\n要件:\n1. タイトルは50〜80文字。対象コンポーネントや目的のキーワードを含めること。\n2. 本文は以下の見出し順序とします。\n   ## 背景\n   ## 目的\n   ## 実行内容\n   ## 受け入れ基準\n   ## 関連リソース\n3. 実行内容には対象ファイル・手順・テスト方法を含めること。\n4. JSON 形式で回答してください。\n\n出力形式:\n{\n  \"title\": \"...\",\n  \"body\": \"...\"\n}\n````\n\n- `parseAndValidate` 検証ルール:\n  - JSON パース失敗 → `IssueAIValidationError`。\n  - タイトル文字数 (全角半角問わず) が 50 未満または 80 超過で失敗。\n  - 本文に必須5セクションが順番に存在するか正規表現で確認。\n  - `## 実行内容` 内に番号付きリスト (`^\\d+\\. `) があり、いずれかの行に `テスト`/`検証` を含むことを確認。\n  - HTML/スクリプトタグを検出したら失敗。\n  - 余分な末尾空行は `trimEnd()` で整理。\n\n### 7.5 IssueClient 拡張\n\n- コンストラクタに `IssueAIGenerator | null` を追加 (`new IssueClient(octokit, owner, repo, issueAIGenerator)`).\n- 新規ヘルパー:\n  - `private buildLegacyBody(...)`: 現行ロジックを抽出し、フォールバック時に再利用。\n  - `private appendMetadata(body, metadata, options)`: `options.appendMetadata` が true の場合に以下を追加。\n    ```\n    ## 生成メタデータ\n    - モデル: ${metadata.model} (${metadata.provider})\n    - 所要時間: ${metadata.durationMs}ms / 再試行: ${metadata.retryCount}\n    - トークン: in ${metadata.inputTokens ?? '-'} / out ${metadata.outputTokens ?? '-'}\n    - 省略したタスク数: ${metadata.omittedTasks ?? 0}\n    ```\n  - `private async tryGenerateWithLLM(...)`: LLM が利用可能か判定し、失敗時は WARN ログで理由を記録して `null` を返す。\n- `createIssueFromEvaluation` の流れ:\n  1. `const aiResult = await this.tryGenerateWithLLM(...);`\n  2. `const title = aiResult?.title ?? this.generateFollowUpTitle(...);`\n  3. `const baseBody = aiResult?.body ?? this.buildLegacyBody(...);`\n  4. `const body = aiResult ? this.appendMetadata(baseBody, aiResult.metadata, options) : baseBody;`\n  5. 既存どおり Octokit で Issue を作成。\n- ログ出力:\n  - 成功 (`logger.debug`): `FOLLOWUP_LLM_SUCCESS { provider, model, durationMs, retryCount }`\n  - フォールバック (`logger.warn`): `FOLLOWUP_LLM_FALLBACK { reason, fallback: 'legacy_template' }`\n  - ログにはプロンプト本文を含めない。\n\n### 7.6 GitHubClient / Phase 連携\n\n- `GitHubClient` コンストラクタで `IssueAIGenerator` を生成し `IssueClient` に渡す。\n- `createIssueFromEvaluation` の署名を `(..., issueContext?: IssueContext, options?: IssueGenerationOptions)` に拡張。`options` が無い場合は `config` から取得する。\n- `EvaluationPhase`:\n  ```ts\n  const options = this.context.issueGenerationOptions ?? { enabled: false, provider: 'auto' };\n  const result = await this.github.createIssueFromEvaluation(\n    issueNumber,\n    remainingTasks,\n    relativeReportPath,\n    issueContext,\n    options,\n  );\n  ```\n- `PhaseFactory` / `BasePhase` で `PhaseContext.issueGenerationOptions` を新たに受け渡す。\n\n### 7.7 CLI / Config 拡張\n\n- `ExecuteCommandOptions` に以下フィールドを追加:\n  - `followupLlmMode?: 'auto' | 'openai' | 'claude' | 'off'`\n  - `followupLlmModel?: string`\n  - `followupLlmTimeout?: number`\n  - `followupLlmMaxRetries?: number`\n  - `followupLlmAppendMetadata?: boolean`\n- `options-parser.ts` でバリデーション:\n  - `off` → `enabled` false。\n  - timeout/retries は正の整数 (0 許容)。\n  - provider 指定が `openai` なのに OpenAI APIキー不在の場合は警告ログを出して `enabled=false`。\n- `config.ts` で環境変数ゲッターを追加 (`FOLLOWUP_LLM_MODE`, `FOLLOWUP_LLM_MODEL`, `FOLLOWUP_LLM_TIMEOUT_MS`, `FOLLOWUP_LLM_MAX_RETRIES`, `FOLLOWUP_LLM_APPEND_METADATA`)。\n- CLI 例:  \n  `ai-workflow execute --issue 119 --phase evaluation --followup-llm-mode auto --followup-llm-model claude-3-sonnet-20240229`.\n\n### 7.8 ロギング・モニタリング\n\n- LLM 成功時は DEBUG ログ、再試行数 > 0 の場合は WARN と INFO の両方に出力して追跡可能にする。\n- フォールバック発生時は WARN ログを構造化文字列 (JSON 互換) で出力。`event=FOLLOWUP_LLM_FALLBACK`, `fallback_mode=legacy_template`, `reason=...`。\n- `IssueAIGenerator.generate` 内で `performance.now()` を使い処理時間を計測。\n- ログには機密情報やプロンプト全文を含めない。\n\n### 7.9 テスト設計詳細\n\n| レイヤ | テストケース | 目的 |\n| --- | --- | --- |\n| Unit (`issue-ai-generator.test.ts`) | タスク数制限・文字列トリム・ターゲットファイル上限を検証 | サニタイズ仕様の担保 |\n|  | JSON 以外の応答で `IssueAIValidationError` を投げる | バリデーション |\n|  | 必須セクション欠落、タイトル長不正、HTMLタグ混入で失敗する | FR-1/FR-2 |\n|  | 1回目失敗→2回目成功のリトライ時に最終成功 | リトライ制御 |\n|  | `SecretMasker` により API キーがプロンプトに残らない | セキュリティ |\n| Unit (`issue-client.test.ts`) | LLM 成功時に Octokit へ LLM 出力が渡る | フロー検証 |\n|  | 例外発生時に WARN ログとフォールバックタイトル/本文が使用される | FR-3 |\n| Integration (`followup-issue-llm.test.ts`) | CLI -> PhaseContext -> GitHubClient -> IssueClient のオプション伝搬 | 設定連携 |\n|  | LLM が無効化されている場合に既存挙動が維持される | 後方互換 |\n|  | `FOLLOWUP_LLM_E2E=1` 時のみ実APIを使い、成功時タイトル/本文が要件を満たすか検証 (失敗時はテストをスキップ) | 実API検証 |\n\n### 7.10 要件トレーサビリティ\n\n| 要件ID | 対応箇所 |\n| --- | --- |\n| FR-1 | 7.4 プロンプト設計・タイトル検証、7.5 タイトル採用ロジック |\n| FR-2 | 7.4 セクション検証、7.5 `buildLegacyBody` との比較で差異を吸収 |\n| FR-3 | 7.5 `tryGenerateWithLLM` フォールバック制御 |\n| FR-4 | 7.6 Phase 連携、7.7 CLI/Config 拡張 |\n| FR-5 | 7.5 ログ出力設計、7.8 モニタリング |\n\n### 7.11 ドキュメント更新\n\n- `ARCHITECTURE.md`: Evaluation → GitHubClient → IssueAIGenerator → IssueClient のフロー図と説明を追加。\n- `CLAUDE.md`: Follow-up LLM 設定方法、環境変数、フォールバック観察ポイントを追記。\n- `README.md`: CLI オプションと `.env` 設定例、フォールバック時のトラブルシューティングを追加。\n\n---\n\n## 8. セキュリティ考慮事項\n\n- `SecretMasker` と追加の簡易正規表現 (API キーフォーマット、メールアドレス) を `sanitizePayload` に適用し、機密情報送信を防止。\n- LLM 応答に HTML/スクリプトタグが含まれる場合はバリデーションエラーとし、フォールバックへ切り替える。\n- API キーは `config` ゲッター経由でのみ参照し、ログへ出力しない。\n- プロンプト・レスポンスをファイルへ書き出さない。ログにはメタデータのみを残す。\n- 再試行回数を `maxRetries` で制限し、無限ループやコスト過多を防止。\n\n","exit_code":0,"status":"completed"}}
{"type":"item.started","item":{"id":"item_16","type":"command_execution","command":"bash -lc 'ls src/core'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_16","type":"command_execution","command":"bash -lc 'ls src/core'","aggregated_output":"claude-agent-client.ts\ncodex-agent-client.ts\nconfig.ts\ncontent-parser.ts\ngit\ngit-manager.ts\ngithub\ngithub-client.ts\nhelpers\nlogger.ts\nmetadata-manager.ts\npath-utils.ts\nphase-dependencies.ts\nphase-factory.ts\nrepository-utils.ts\nsecret-masker.ts\nworkflow-state.ts\n","exit_code":0,"status":"completed"}}
{"type":"item.started","item":{"id":"item_17","type":"command_execution","command":"bash -lc 'grep -R \"secret-masker\" -n tests'","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_17","type":"command_execution","command":"bash -lc 'grep -R \"secret-masker\" -n tests'","aggregated_output":"tests/unit/secret-masker.test.ts:2: * ユニットテスト: secret-masker.ts\ntests/unit/secret-masker.test.ts:14:import { SecretMasker } from '../../src/core/secret-masker.js';\ntests/unit/secret-masker.test.ts:18:const TEST_DIR = path.join(process.cwd(), 'tests', 'temp', 'secret-masker-test');\ntests/unit/git/commit-manager.test.ts:11:import { SecretMasker } from '../../../src/core/secret-masker';\ntests/integration/init-token-sanitization.test.ts:18:import { SecretMasker } from '../../src/core/secret-masker.js';\n","exit_code":0,"status":"completed"}}
{"type":"item.started","item":{"id":"item_18","type":"command_execution","command":"bash -lc \"sed -n '1,200p' src/core/secret-masker.ts\"","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_18","type":"command_execution","command":"bash -lc \"sed -n '1,200p' src/core/secret-masker.ts\"","aggregated_output":"import * as fs from 'fs/promises';\nimport { logger } from '../utils/logger.js';\nimport * as path from 'path';\nimport { glob } from 'glob';\nimport { getErrorMessage } from '../utils/error-utils.js';\n\nexport interface Secret {\n  name: string;\n  value: string;\n}\n\nexport interface MaskingResult {\n  filesProcessed: number;\n  secretsMasked: number;\n  errors: string[];\n}\n\n/**\n * SecretMasker - Masks secrets in workflow files before Git commit\n *\n * This class prevents GitHub Secret Scanning from blocking pushes by\n * replacing secret values from environment variables with redacted placeholders.\n */\nexport class SecretMasker {\n  private readonly targetFilePatterns = [\n    'agent_log_raw.txt',\n    'agent_log.md',\n    'prompt.txt',\n    'metadata.json', // Issue #54: Scan metadata.json for tokens\n  ];\n\n  private readonly envVarNames = [\n    'GITHUB_TOKEN',\n    'OPENAI_API_KEY',\n    'CODEX_API_KEY',\n    'CLAUDE_CODE_OAUTH_TOKEN',\n    'AWS_ACCESS_KEY_ID',\n    'AWS_SECRET_ACCESS_KEY',\n    'AWS_SESSION_TOKEN',\n  ];\n\n  /**\n   * Get list of secrets from environment variables\n   */\n  public getSecretList(): Secret[] {\n    const secrets: Secret[] = [];\n\n    for (const name of this.envVarNames) {\n      const value = process.env[name];\n      if (value && value.length > 10) {\n        secrets.push({ name, value });\n      }\n    }\n\n    return secrets;\n  }\n\n  /**\n   * Mask secrets in all files within workflow directory\n   *\n   * @param workflowDir - Path to .ai-workflow/issue-{number}/ directory\n   * @returns MaskingResult with statistics\n   */\n  public async maskSecretsInWorkflowDir(\n    workflowDir: string,\n  ): Promise<MaskingResult> {\n    const secrets = this.getSecretList();\n\n    if (secrets.length === 0) {\n      logger.info('No secrets found in environment variables');\n      return {\n        filesProcessed: 0,\n        secretsMasked: 0,\n        errors: [],\n      };\n    }\n\n    logger.info(`Found ${secrets.length} secret(s) in environment variables`);\n\n    // Find all target files in workflow directory\n    const files = await this.findTargetFiles(workflowDir);\n\n    if (files.length === 0) {\n      logger.info('No files found to scan for secrets');\n      return {\n        filesProcessed: 0,\n        secretsMasked: 0,\n        errors: [],\n      };\n    }\n\n    logger.info(`Scanning ${files.length} file(s) for secrets`);\n\n    let filesProcessed = 0;\n    let totalSecretsMasked = 0;\n    const errors: string[] = [];\n\n    // Process each file\n    for (const filePath of files) {\n      try {\n        const result = await this.maskSecretsInFile(filePath, secrets);\n        if (result.masked) {\n          filesProcessed++;\n          totalSecretsMasked += result.count;\n          logger.info(\n            `Masked ${result.count} secret(s) in ${path.basename(filePath)}`,\n          );\n        }\n      } catch (error) {\n        const errorMsg = `Failed to process ${filePath}: ${getErrorMessage(error)}`;\n        logger.error(`${errorMsg}`);\n        errors.push(errorMsg);\n      }\n    }\n\n    return {\n      filesProcessed,\n      secretsMasked: totalSecretsMasked,\n      errors,\n    };\n  }\n\n  /**\n   * Find all target files in workflow directory\n   */\n  private async findTargetFiles(workflowDir: string): Promise<string[]> {\n    const files: string[] = [];\n\n    for (const pattern of this.targetFilePatterns) {\n      const globPattern = path.join(workflowDir, '**', pattern);\n      try {\n        const matches = await glob(globPattern, {\n          nodir: true,\n          absolute: true,\n          windowsPathsNoEscape: true,\n        });\n        files.push(...matches);\n      } catch (error) {\n        logger.warn(\n          `Failed to glob pattern ${globPattern}: ${getErrorMessage(error)}`,\n        );\n      }\n    }\n\n    return files;\n  }\n\n  /**\n   * Mask secrets in a single file\n   */\n  private async maskSecretsInFile(\n    filePath: string,\n    secrets: Secret[],\n  ): Promise<{ masked: boolean; count: number }> {\n    let content = await fs.readFile(filePath, 'utf-8');\n    let maskedCount = 0;\n    let modified = false;\n\n    for (const secret of secrets) {\n      const replacement = `[REDACTED_${secret.name}]`;\n      const occurrences = this.countOccurrences(content, secret.value);\n\n      if (occurrences > 0) {\n        content = this.replaceAll(content, secret.value, replacement);\n        maskedCount += occurrences;\n        modified = true;\n      }\n    }\n\n    if (modified) {\n      await fs.writeFile(filePath, content, 'utf-8');\n    }\n\n    return { masked: modified, count: maskedCount };\n  }\n\n  /**\n   * Count occurrences of a substring in a string\n   */\n  private countOccurrences(text: string, searchString: string): number {\n    let count = 0;\n    let position = 0;\n\n    while (true) {\n      const index = text.indexOf(searchString, position);\n      if (index === -1) break;\n      count++;\n      position = index + searchString.length;\n    }\n\n    return count;\n  }\n\n  /**\n   * Replace all occurrences of a substring\n   */\n  private replaceAll(text: string, search: string, replace: string): string {\n    return text.split(search).join(replace);\n  }\n}\n","exit_code":0,"status":"completed"}}
{"type":"item.started","item":{"id":"item_19","type":"command_execution","command":"bash -lc \"sed -n '70,120p' design.md\"","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_19","type":"command_execution","command":"bash -lc \"sed -n '70,120p' design.md\"","aggregated_output":"\n**判断根拠**:\n- プロンプト生成・レスポンス検証・リトライといったロジックはモック化が容易であり、ユニットテストで網羅できる。\n- GitHub 連携や Phase からのオプション伝搬、フォールバック全体の動作は統合テストで確認する必要がある。\n\n---\n\n## 4. テストコード戦略判断: BOTH_TEST\n\n**判断根拠**:\n- 既存 `issue-client` テストに LLM 成功/失敗パスを追加する必要がある (既存テストの拡張)。\n- `IssueAIGenerator` 用の専用ユニットテストが新規に必要となる (新規テスト作成)。\n\n---\n\n## 5. 影響範囲分析\n\n### 5.1 既存コードへの影響\n- `src/core/github/issue-client.ts`: 依存注入、LLM 分岐、本文生成をメソッド化、WARN/DEBUG ログ拡張。\n- `src/core/github-client.ts`: `IssueAIGenerator` の初期化と委譲。`createIssueFromEvaluation` にオプションパラメータ追加。\n- `src/phases/evaluation.ts`: `GitHubClient.createIssueFromEvaluation` 呼び出しに LLM オプションを渡す。\n- `src/commands/execute.ts` / `src/commands/execute/options-parser.ts`: CLI オプション解析に Follow-up LLM 設定を追加し `PhaseContext` へ渡す。\n- `src/types.ts`: `IssueGenerationOptions` や LLM 結果の型を追加。\n- `src/types/commands.ts`: `PhaseContext` に `issueGenerationOptions` プロパティを追加。\n- `src/core/config.ts`: LLM 設定用ゲッターを実装。\n- 既存テスト (`tests/unit/github/issue-client*.ts`, `tests/integration/github-client-facade.test.ts`) を LLM 統合ケースで更新。\n\n### 5.2 依存関係の変更\n- 追加パッケージは想定なし。既存 `openai`, `@anthropic-ai/claude-agent-sdk` を再利用。\n- Jest モックは既存 `jest-mock-extended` や手動モックを活用。\n\n### 5.3 マイグレーション要否\n- データマイグレーションは不要。\n- `.env.example` が存在する場合は Follow-up LLM 用環境変数を追加。\n- `ARCHITECTURE.md`, `CLAUDE.md`, `README.md` を更新して設定手順とフォールバック説明を追記。\n\n---\n\n## 6. 変更・追加ファイルリスト\n\n- **新規作成**\n  - `src/core/github/issue-ai-generator.ts`\n  - `tests/unit/github/issue-ai-generator.test.ts`\n  - `tests/integration/followup-issue-llm.test.ts` (Octokit モック中心)\n- **既存修正**\n  - `src/core/github/issue-client.ts`\n  - `src/core/github-client.ts`\n  - `src/phases/evaluation.ts`\n  - `src/commands/execute.ts`\n  - `src/commands/execute/options-parser.ts`\n  - `src/types.ts`\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_20","type":"file_change","changes":[{"path":"/tmp/jenkins-33ebb7ab/workspace/AI_Workflow/ai_workflow_orchestrator_develop/.ai-workflow/issue-119/02_design/output/design.md","kind":"update"}],"status":"completed"}}
{"type":"item.started","item":{"id":"item_21","type":"command_execution","command":"bash -lc \"grep -n \\\"7\\\\.8\\\" design.md\"","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_21","type":"command_execution","command":"bash -lc \"grep -n \\\"7\\\\.8\\\" design.md\"","aggregated_output":"320:### 7.8 SecretMasker 拡張\n","exit_code":0,"status":"completed"}}
{"type":"item.started","item":{"id":"item_22","type":"command_execution","command":"bash -lc \"grep -n \\\"7\\\\.12\\\" design.md\"","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_22","type":"command_execution","command":"bash -lc \"grep -n \\\"7\\\\.12\\\" design.md\"","aggregated_output":"369:### 7.12 ドキュメント更新\n","exit_code":0,"status":"completed"}}
{"type":"item.updated","item":{"id":"item_9","type":"todo_list","items":[{"text":"Review current design.md and reviewer feedback to understand required updates.","completed":true},{"text":"Update design.md to document SecretMasker extension and align file lists with actual change set.","completed":true},{"text":"Double-check revised sections for consistency and prepare response to user.","completed":false}]}}
{"type":"item.started","item":{"id":"item_23","type":"command_execution","command":"bash -lc \"sed -n '300,360p' design.md\"","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_23","type":"command_execution","command":"bash -lc \"sed -n '300,360p' design.md\"","aggregated_output":"  );\n  ```\n- `PhaseFactory` / `BasePhase` で `PhaseContext.issueGenerationOptions` を新たに受け渡す。\n\n### 7.7 CLI / Config 拡張\n\n- `ExecuteCommandOptions` に以下フィールドを追加:\n  - `followupLlmMode?: 'auto' | 'openai' | 'claude' | 'off'`\n  - `followupLlmModel?: string`\n  - `followupLlmTimeout?: number`\n  - `followupLlmMaxRetries?: number`\n  - `followupLlmAppendMetadata?: boolean`\n- `options-parser.ts` でバリデーション:\n  - `off` → `enabled` false。\n  - timeout/retries は正の整数 (0 許容)。\n  - provider 指定が `openai` なのに OpenAI APIキー不在の場合は警告ログを出して `enabled=false`。\n- `config.ts` で環境変数ゲッターを追加 (`FOLLOWUP_LLM_MODE`, `FOLLOWUP_LLM_MODEL`, `FOLLOWUP_LLM_TIMEOUT_MS`, `FOLLOWUP_LLM_MAX_RETRIES`, `FOLLOWUP_LLM_APPEND_METADATA`)。\n- CLI 例:  \n  `ai-workflow execute --issue 119 --phase evaluation --followup-llm-mode auto --followup-llm-model claude-3-sonnet-20240229`.\n\n### 7.8 SecretMasker 拡張\n\n- 新規メソッド `maskObject<T>(input: T, options?: { ignoredPaths?: string[] }): T` を追加し、入力オブジェクトを破壊せずに深いコピーを返す。`ignoredPaths` は `['tasks.*.metadata']` のようなドット表記で除外を指定できる。\n- 処理フロー:\n  1. `getSecretList()` で環境変数ベースのシークレットを取得し、`[REDACTED_${name}]` への置換テーブルを構築。\n  2. 追加で以下のパターンを検出する正規表現を用意し、ヒットした文字列は `[REDACTED_PATTERN]` に置換する。  \n     - 長さ 20 文字以上の英数字+`-_` 混在トークン (`/[A-Za-z0-9_-]{20,}/g`)  \n     - メールアドレス (`/[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,}/g`)  \n     - `Bearer <token>` / `token=` 形式 (`/(Bearer|token=)[\\w\\-.]+/gi`)\n  3. 走査は DFS で実装し、`WeakSet` で循環参照を検出して二度処理しない。配列は同じく再帰し、プリミティブ以外は `Object.prototype.toString` で plain object のみを対象にする。\n  4. 文字列に対しては上記パターンとシークレット値を順次 `replaceAll` し、オブジェクト／配列はフィールド単位で再帰結果を集約する。\n- 戻り値は元の構造を維持した `sanitized` コピー。元のオブジェクトは変更せず、`undefined` や関数はそのまま返す。\n- `IssueAIGenerator.sanitizePayload` はこの `maskObject` の戻り値に対して文字数トリムやタスク数制限を適用し、マスキングと整形の責務を分離する。\n- 追加するユニットテストでは、ネストしたオブジェクトと配列、循環参照、`ignoredPaths` 指定時の除外、メールアドレス置換が期待通り動くことを確認する。\n\n### 7.9 ロギング・モニタリング\n\n- LLM 成功時は DEBUG ログ、再試行数 > 0 の場合は WARN と INFO の両方に出力して追跡可能にする。\n- フォールバック発生時は WARN ログを構造化文字列 (JSON 互換) で出力。`event=FOLLOWUP_LLM_FALLBACK`, `fallback_mode=legacy_template`, `reason=...`。\n- `IssueAIGenerator.generate` 内で `performance.now()` を使い処理時間を計測。\n- ログには機密情報やプロンプト全文を含めない。\n\n### 7.10 テスト設計詳細\n\n| レイヤ | テストケース | 目的 |\n| --- | --- | --- |\n| Unit (`issue-ai-generator.test.ts`) | タスク数制限・文字列トリム・ターゲットファイル上限を検証 | サニタイズ仕様の担保 |\n|  | JSON 以外の応答で `IssueAIValidationError` を投げる | バリデーション |\n|  | 必須セクション欠落、タイトル長不正、HTMLタグ混入で失敗する | FR-1/FR-2 |\n|  | 1回目失敗→2回目成功のリトライ時に最終成功 | リトライ制御 |\n|  | `SecretMasker` により API キーがプロンプトに残らない | セキュリティ |\n| Unit (`secret-masker.test.ts`) | `maskObject` がネスト構造・配列・循環参照を安全にマスキングする | サニタイズ機構の信頼性 |\n|  | `ignoredPaths` 指定時に該当フィールドをスキップしつつ他をマスクする | 柔軟な除外設定 |\n| Unit (`issue-client.test.ts`) | LLM 成功時に Octokit へ LLM 出力が渡る | フロー検証 |\n|  | 例外発生時に WARN ログとフォールバックタイトル/本文が使用される | FR-3 |\n| Integration (`followup-issue-llm.test.ts`) | CLI -> PhaseContext -> GitHubClient -> IssueClient のオプション伝搬 | 設定連携 |\n|  | LLM が無効化されている場合に既存挙動が維持される | 後方互換 |\n|  | `FOLLOWUP_LLM_E2E=1` 時のみ実APIを使い、成功時タイトル/本文が要件を満たすか検証 (失敗時はテストをスキップ) | 実API検証 |\n\n### 7.11 要件トレーサビリティ\n\n","exit_code":0,"status":"completed"}}
{"type":"item.started","item":{"id":"item_24","type":"command_execution","command":"bash -lc \"sed -n '80,120p' design.md\"","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_24","type":"command_execution","command":"bash -lc \"sed -n '80,120p' design.md\"","aggregated_output":"- 既存 `issue-client` テストに LLM 成功/失敗パスを追加する必要がある (既存テストの拡張)。\n- `IssueAIGenerator` 用の専用ユニットテストが新規に必要となる (新規テスト作成)。\n\n---\n\n## 5. 影響範囲分析\n\n### 5.1 既存コードへの影響\n- `src/core/github/issue-client.ts`: 依存注入、LLM 分岐、本文生成をメソッド化、WARN/DEBUG ログ拡張。\n- `src/core/github-client.ts`: `IssueAIGenerator` の初期化と委譲。`createIssueFromEvaluation` にオプションパラメータ追加。\n- `src/core/phase-factory.ts`: `PhaseContext` へ追加した `issueGenerationOptions` を全 Phase に渡す初期化処理を拡張。\n- `src/phases/base-phase.ts`: Phase インスタンスが `issueGenerationOptions` を受け取り `this.context` へ保持できるようにする。\n- `src/phases/evaluation.ts`: `GitHubClient.createIssueFromEvaluation` 呼び出しに LLM オプションを渡す。\n- `src/core/secret-masker.ts`: `maskObject` を追加してネストした残タスクオブジェクトを一括マスキングできるようにする。\n- `src/commands/execute.ts` / `src/commands/execute/options-parser.ts`: CLI オプション解析に Follow-up LLM 設定を追加し `PhaseContext` へ渡す。\n- `src/types.ts`: `IssueGenerationOptions` や LLM 結果の型を追加。\n- `src/types/commands.ts`: `PhaseContext` に `issueGenerationOptions` プロパティを追加。\n- `src/core/config.ts`: LLM 設定用ゲッターを実装。\n- 既存テスト (`tests/unit/github/issue-client*.ts`, `tests/integration/github-client-facade.test.ts`, `tests/unit/secret-masker.test.ts`) を LLM 統合ケースとシークレットマスキング強化に合わせて更新。\n\n### 5.2 依存関係の変更\n- 追加パッケージは想定なし。既存 `openai`, `@anthropic-ai/claude-agent-sdk` を再利用。\n- Jest モックは既存 `jest-mock-extended` や手動モックを活用。\n\n### 5.3 マイグレーション要否\n- データマイグレーションは不要。\n- `.env.example` が存在する場合は Follow-up LLM 用環境変数を追加。\n- `ARCHITECTURE.md`, `CLAUDE.md`, `README.md` を更新して設定手順とフォールバック説明を追記。\n\n---\n\n## 6. 変更・追加ファイルリスト\n\n- **新規作成**\n  - `src/core/github/issue-ai-generator.ts`\n  - `tests/unit/github/issue-ai-generator.test.ts`\n  - `tests/integration/followup-issue-llm.test.ts` (Octokit モック中心)\n- **既存修正**\n  - `src/core/github/issue-client.ts`\n  - `src/core/github-client.ts`\n  - `src/core/phase-factory.ts`\n","exit_code":0,"status":"completed"}}
{"type":"item.started","item":{"id":"item_25","type":"command_execution","command":"bash -lc \"sed -n '120,160p' design.md\"","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_25","type":"command_execution","command":"bash -lc \"sed -n '120,160p' design.md\"","aggregated_output":"  - `src/core/phase-factory.ts`\n  - `src/phases/base-phase.ts`\n  - `src/phases/evaluation.ts`\n  - `src/core/secret-masker.ts`\n  - `src/commands/execute.ts`\n  - `src/commands/execute/options-parser.ts`\n  - `src/types.ts`\n  - `src/types/commands.ts`\n  - `src/core/config.ts`\n  - `tests/unit/github/issue-client.test.ts`\n  - `tests/unit/github/issue-client-followup.test.ts`\n  - `tests/unit/secret-masker.test.ts`\n  - `tests/integration/github-client-facade.test.ts`\n  - ドキュメント (`ARCHITECTURE.md`, `CLAUDE.md`, `README.md`, `.env.example`)\n- **削除予定**: なし\n\n---\n\n## 7. 詳細設計\n\n### 7.1 IssueGenerationOptions / IssueAIGenerationResult\n\n```ts\nexport interface IssueGenerationOptions {\n  enabled: boolean;\n  provider: 'auto' | 'openai' | 'claude';\n  model?: string;\n  temperature?: number;          // default 0.2\n  maxOutputTokens?: number;      // default 1500\n  timeoutMs?: number;            // default 25000\n  maxRetries?: number;           // default 3\n  maxTasks?: number;             // default 5\n  appendMetadata?: boolean;      // default false\n}\n\nexport interface IssueAIGenerationResult {\n  title: string;\n  body: string;\n  metadata: {\n    provider: 'openai' | 'claude';\n    model: string;\n","exit_code":0,"status":"completed"}}
{"type":"item.updated","item":{"id":"item_9","type":"todo_list","items":[{"text":"Review current design.md and reviewer feedback to understand required updates.","completed":true},{"text":"Update design.md to document SecretMasker extension and align file lists with actual change set.","completed":true},{"text":"Double-check revised sections for consistency and prepare response to user.","completed":true}]}}
{"type":"item.started","item":{"id":"item_26","type":"command_execution","command":"bash -lc \"nl -ba design.md | sed -n '90,200p'\"","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_26","type":"command_execution","command":"bash -lc \"nl -ba design.md | sed -n '90,200p'\"","aggregated_output":"    90\t- `src/core/phase-factory.ts`: `PhaseContext` へ追加した `issueGenerationOptions` を全 Phase に渡す初期化処理を拡張。\n    91\t- `src/phases/base-phase.ts`: Phase インスタンスが `issueGenerationOptions` を受け取り `this.context` へ保持できるようにする。\n    92\t- `src/phases/evaluation.ts`: `GitHubClient.createIssueFromEvaluation` 呼び出しに LLM オプションを渡す。\n    93\t- `src/core/secret-masker.ts`: `maskObject` を追加してネストした残タスクオブジェクトを一括マスキングできるようにする。\n    94\t- `src/commands/execute.ts` / `src/commands/execute/options-parser.ts`: CLI オプション解析に Follow-up LLM 設定を追加し `PhaseContext` へ渡す。\n    95\t- `src/types.ts`: `IssueGenerationOptions` や LLM 結果の型を追加。\n    96\t- `src/types/commands.ts`: `PhaseContext` に `issueGenerationOptions` プロパティを追加。\n    97\t- `src/core/config.ts`: LLM 設定用ゲッターを実装。\n    98\t- 既存テスト (`tests/unit/github/issue-client*.ts`, `tests/integration/github-client-facade.test.ts`, `tests/unit/secret-masker.test.ts`) を LLM 統合ケースとシークレットマスキング強化に合わせて更新。\n    99\t\n   100\t### 5.2 依存関係の変更\n   101\t- 追加パッケージは想定なし。既存 `openai`, `@anthropic-ai/claude-agent-sdk` を再利用。\n   102\t- Jest モックは既存 `jest-mock-extended` や手動モックを活用。\n   103\t\n   104\t### 5.3 マイグレーション要否\n   105\t- データマイグレーションは不要。\n   106\t- `.env.example` が存在する場合は Follow-up LLM 用環境変数を追加。\n   107\t- `ARCHITECTURE.md`, `CLAUDE.md`, `README.md` を更新して設定手順とフォールバック説明を追記。\n   108\t\n   109\t---\n   110\t\n   111\t## 6. 変更・追加ファイルリスト\n   112\t\n   113\t- **新規作成**\n   114\t  - `src/core/github/issue-ai-generator.ts`\n   115\t  - `tests/unit/github/issue-ai-generator.test.ts`\n   116\t  - `tests/integration/followup-issue-llm.test.ts` (Octokit モック中心)\n   117\t- **既存修正**\n   118\t  - `src/core/github/issue-client.ts`\n   119\t  - `src/core/github-client.ts`\n   120\t  - `src/core/phase-factory.ts`\n   121\t  - `src/phases/base-phase.ts`\n   122\t  - `src/phases/evaluation.ts`\n   123\t  - `src/core/secret-masker.ts`\n   124\t  - `src/commands/execute.ts`\n   125\t  - `src/commands/execute/options-parser.ts`\n   126\t  - `src/types.ts`\n   127\t  - `src/types/commands.ts`\n   128\t  - `src/core/config.ts`\n   129\t  - `tests/unit/github/issue-client.test.ts`\n   130\t  - `tests/unit/github/issue-client-followup.test.ts`\n   131\t  - `tests/unit/secret-masker.test.ts`\n   132\t  - `tests/integration/github-client-facade.test.ts`\n   133\t  - ドキュメント (`ARCHITECTURE.md`, `CLAUDE.md`, `README.md`, `.env.example`)\n   134\t- **削除予定**: なし\n   135\t\n   136\t---\n   137\t\n   138\t## 7. 詳細設計\n   139\t\n   140\t### 7.1 IssueGenerationOptions / IssueAIGenerationResult\n   141\t\n   142\t```ts\n   143\texport interface IssueGenerationOptions {\n   144\t  enabled: boolean;\n   145\t  provider: 'auto' | 'openai' | 'claude';\n   146\t  model?: string;\n   147\t  temperature?: number;          // default 0.2\n   148\t  maxOutputTokens?: number;      // default 1500\n   149\t  timeoutMs?: number;            // default 25000\n   150\t  maxRetries?: number;           // default 3\n   151\t  maxTasks?: number;             // default 5\n   152\t  appendMetadata?: boolean;      // default false\n   153\t}\n   154\t\n   155\texport interface IssueAIGenerationResult {\n   156\t  title: string;\n   157\t  body: string;\n   158\t  metadata: {\n   159\t    provider: 'openai' | 'claude';\n   160\t    model: string;\n   161\t    durationMs: number;\n   162\t    retryCount: number;\n   163\t    inputTokens?: number;\n   164\t    outputTokens?: number;\n   165\t    omittedTasks?: number;\n   166\t  };\n   167\t}\n   168\t```\n   169\t\n   170\t- `config` でデフォルトを構築し、CLI/環境変数で上書き可能にする。\n   171\t- `PhaseContext` に `issueGenerationOptions` を追加し、省略時は `{ enabled: false, provider: 'auto' }` を適用。\n   172\t\n   173\t### 7.2 IssueAIGenerator クラス (新規)\n   174\t\n   175\t- コンストラクタ: `(providers: Record<'openai' | 'claude', LlmProviderAdapter>, secretMasker = new SecretMasker())`。\n   176\t- 補助的なエラー型:\n   177\t  - `IssueAIUnavailableError` (credentials 不足など)\n   178\t  - `IssueAIValidationError` (出力検証失敗)\n   179\t- 公開メソッド:\n   180\t  - `isAvailable(options: IssueGenerationOptions): boolean`  \n   181\t    - `options.enabled` が true かつ選択された provider（`auto` の場合は利用可能なもの）が `hasCredentials()` を満たす。\n   182\t  - `generate(tasks, context, issueNumber, options): Promise<IssueAIGenerationResult>`  \n   183\t    1. `sanitizePayload(tasks, context, options.maxTasks ?? 5)`  \n   184\t       - `RemainingTask` を優先度順 (High→Medium→Low) に並べ、上位 `maxTasks` を採用。超過分は `omittedTasks` としてメタに記録。  \n   185\t       - 各文字列フィールドは 512 文字にトリム。`targetFiles` は 10 件、`steps` / `acceptanceCriteria` は各 8 件まで。  \n   186\t       - `SecretMasker.maskObject` で既知のシークレット値・トークン・メールアドレスを `[REDACTED_x]` に置換。\n   187\t    2. `buildPrompt(issueNumber, sanitizedPayload, context, options)`  \n   188\t       - JSON 文字列化し、テンプレートへ埋め込む。\n   189\t    3. `invokeProvider(prompt, options)`  \n   190\t       - 選択された provider の `complete()` を呼び出す。  \n   191\t       - レート制限時は指数バックオフ (2000ms, 4000ms, 8000ms) とし、回数は `options.maxRetries`。\n   192\t    4. `parseAndValidate(responseText)`  \n   193\t       - JSON パース → タイトル長 50〜80 文字 → 必須セクションを順番に確認 → `実行内容` セクションが番号付きリスト (`1.` 形式) とテスト手順 (`テスト` or `検証`) を含むか検証 → HTML タグを禁止。  \n   194\t       - 失敗時は `IssueAIValidationError`。\n   195\t    5. 成功時に metadata (provider, model, duration, retryCount, input/output tokens, omittedTasks) 付きで返却。\n   196\t\n   197\t### 7.3 LlmProviderAdapter\n   198\t\n   199\t```ts\n   200\tinterface LlmProviderAdapter {\n","exit_code":0,"status":"completed"}}
{"type":"item.started","item":{"id":"item_27","type":"command_execution","command":"bash -lc \"nl -ba design.md | sed -n '300,360p'\"","aggregated_output":"","exit_code":null,"status":"in_progress"}}
{"type":"item.completed","item":{"id":"item_27","type":"command_execution","command":"bash -lc \"nl -ba design.md | sed -n '300,360p'\"","aggregated_output":"   300\t  );\n   301\t  ```\n   302\t- `PhaseFactory` / `BasePhase` で `PhaseContext.issueGenerationOptions` を新たに受け渡す。\n   303\t\n   304\t### 7.7 CLI / Config 拡張\n   305\t\n   306\t- `ExecuteCommandOptions` に以下フィールドを追加:\n   307\t  - `followupLlmMode?: 'auto' | 'openai' | 'claude' | 'off'`\n   308\t  - `followupLlmModel?: string`\n   309\t  - `followupLlmTimeout?: number`\n   310\t  - `followupLlmMaxRetries?: number`\n   311\t  - `followupLlmAppendMetadata?: boolean`\n   312\t- `options-parser.ts` でバリデーション:\n   313\t  - `off` → `enabled` false。\n   314\t  - timeout/retries は正の整数 (0 許容)。\n   315\t  - provider 指定が `openai` なのに OpenAI APIキー不在の場合は警告ログを出して `enabled=false`。\n   316\t- `config.ts` で環境変数ゲッターを追加 (`FOLLOWUP_LLM_MODE`, `FOLLOWUP_LLM_MODEL`, `FOLLOWUP_LLM_TIMEOUT_MS`, `FOLLOWUP_LLM_MAX_RETRIES`, `FOLLOWUP_LLM_APPEND_METADATA`)。\n   317\t- CLI 例:  \n   318\t  `ai-workflow execute --issue 119 --phase evaluation --followup-llm-mode auto --followup-llm-model claude-3-sonnet-20240229`.\n   319\t\n   320\t### 7.8 SecretMasker 拡張\n   321\t\n   322\t- 新規メソッド `maskObject<T>(input: T, options?: { ignoredPaths?: string[] }): T` を追加し、入力オブジェクトを破壊せずに深いコピーを返す。`ignoredPaths` は `['tasks.*.metadata']` のようなドット表記で除外を指定できる。\n   323\t- 処理フロー:\n   324\t  1. `getSecretList()` で環境変数ベースのシークレットを取得し、`[REDACTED_${name}]` への置換テーブルを構築。\n   325\t  2. 追加で以下のパターンを検出する正規表現を用意し、ヒットした文字列は `[REDACTED_PATTERN]` に置換する。  \n   326\t     - 長さ 20 文字以上の英数字+`-_` 混在トークン (`/[A-Za-z0-9_-]{20,}/g`)  \n   327\t     - メールアドレス (`/[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,}/g`)  \n   328\t     - `Bearer <token>` / `token=` 形式 (`/(Bearer|token=)[\\w\\-.]+/gi`)\n   329\t  3. 走査は DFS で実装し、`WeakSet` で循環参照を検出して二度処理しない。配列は同じく再帰し、プリミティブ以外は `Object.prototype.toString` で plain object のみを対象にする。\n   330\t  4. 文字列に対しては上記パターンとシークレット値を順次 `replaceAll` し、オブジェクト／配列はフィールド単位で再帰結果を集約する。\n   331\t- 戻り値は元の構造を維持した `sanitized` コピー。元のオブジェクトは変更せず、`undefined` や関数はそのまま返す。\n   332\t- `IssueAIGenerator.sanitizePayload` はこの `maskObject` の戻り値に対して文字数トリムやタスク数制限を適用し、マスキングと整形の責務を分離する。\n   333\t- 追加するユニットテストでは、ネストしたオブジェクトと配列、循環参照、`ignoredPaths` 指定時の除外、メールアドレス置換が期待通り動くことを確認する。\n   334\t\n   335\t### 7.9 ロギング・モニタリング\n   336\t\n   337\t- LLM 成功時は DEBUG ログ、再試行数 > 0 の場合は WARN と INFO の両方に出力して追跡可能にする。\n   338\t- フォールバック発生時は WARN ログを構造化文字列 (JSON 互換) で出力。`event=FOLLOWUP_LLM_FALLBACK`, `fallback_mode=legacy_template`, `reason=...`。\n   339\t- `IssueAIGenerator.generate` 内で `performance.now()` を使い処理時間を計測。\n   340\t- ログには機密情報やプロンプト全文を含めない。\n   341\t\n   342\t### 7.10 テスト設計詳細\n   343\t\n   344\t| レイヤ | テストケース | 目的 |\n   345\t| --- | --- | --- |\n   346\t| Unit (`issue-ai-generator.test.ts`) | タスク数制限・文字列トリム・ターゲットファイル上限を検証 | サニタイズ仕様の担保 |\n   347\t|  | JSON 以外の応答で `IssueAIValidationError` を投げる | バリデーション |\n   348\t|  | 必須セクション欠落、タイトル長不正、HTMLタグ混入で失敗する | FR-1/FR-2 |\n   349\t|  | 1回目失敗→2回目成功のリトライ時に最終成功 | リトライ制御 |\n   350\t|  | `SecretMasker` により API キーがプロンプトに残らない | セキュリティ |\n   351\t| Unit (`secret-masker.test.ts`) | `maskObject` がネスト構造・配列・循環参照を安全にマスキングする | サニタイズ機構の信頼性 |\n   352\t|  | `ignoredPaths` 指定時に該当フィールドをスキップしつつ他をマスクする | 柔軟な除外設定 |\n   353\t| Unit (`issue-client.test.ts`) | LLM 成功時に Octokit へ LLM 出力が渡る | フロー検証 |\n   354\t|  | 例外発生時に WARN ログとフォールバックタイトル/本文が使用される | FR-3 |\n   355\t| Integration (`followup-issue-llm.test.ts`) | CLI -> PhaseContext -> GitHubClient -> IssueClient のオプション伝搬 | 設定連携 |\n   356\t|  | LLM が無効化されている場合に既存挙動が維持される | 後方互換 |\n   357\t|  | `FOLLOWUP_LLM_E2E=1` 時のみ実APIを使い、成功時タイトル/本文が要件を満たすか検証 (失敗時はテストをスキップ) | 実API検証 |\n   358\t\n   359\t### 7.11 要件トレーサビリティ\n   360\t\n","exit_code":0,"status":"completed"}}
{"type":"item.completed","item":{"id":"item_28","type":"agent_message","text":"**Design Updates**\n- Expanded the impact analysis to cover `src/core/phase-factory.ts`, `src/phases/base-phase.ts`, and the mandatory `src/core/secret-masker.ts` changes, plus aligned test touchpoints so implementers know every file that must be edited (.ai-workflow/issue-119/02_design/output/design.md:90-98).\n- Updated the change list to explicitly include the new and modified files for PhaseContext propagation and SecretMasker work, keeping the implementation to-do list complete (.ai-workflow/issue-119/02_design/output/design.md:118-133).\n- Added a dedicated “SecretMasker 拡張” subsection that specifies the new `maskObject` API, recursion, regex rules, and circular-reference handling, and tied in the supporting unit tests to ensure the design is directly actionable (.ai-workflow/issue-119/02_design/output/design.md:320-353).\n\nNext step: review the refreshed design to confirm it now satisfies the quality gate before moving to test design."}}
{"type":"item.completed","item":{"id":"item_9","type":"todo_list","items":[{"text":"Review current design.md and reviewer feedback to understand required updates.","completed":true},{"text":"Update design.md to document SecretMasker extension and align file lists with actual change set.","completed":true},{"text":"Double-check revised sections for consistency and prepare response to user.","completed":true}]}}
{"type":"turn.completed","usage":{"input_tokens":737032,"cached_input_tokens":700032,"output_tokens":9551}}